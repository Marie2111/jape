\documentclass[11pt]{book}
\usepackage{graphicx}
\DeclareGraphicsRule{.tiff}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tiff`.png}

\usepackage{amsmath,amssymb}
\usepackage{times}
\usepackage{epstopdf}
\usepackage[ligature,reserved]{semantic}
\usepackage[center,tight]{subfigure}
\usepackage{proof}

\usepackage{color}

\definecolor{red}{rgb}{1,0,0}
\definecolor{magenta}{cmyk}{0,1,0,0}
\definecolor{halfgrey}{gray}{0.5}

\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\newcommand{\textGamma}{$\Gamma$}
\newcommand{\textDelta}{$\Delta$}
\DeclareUnicodeCharacter {8870}{$|-$}

\textwidth = 6.5 in
\textheight = 9 in
\oddsidemargin = 0.0 in
\evensidemargin = 0.0 in
\topmargin = 0.0 in
%\headheight = 0.0 in
%\headsep = 0.0 in
\parskip = 3pt
\parindent = 0.0in

%no indent on footnotes
\makeatletter
\renewcommand{\@makefntext}[1]{\setlength{\parindent}{0pt}%
\begin{list}{}{\setlength{\labelwidth}{1em}%
  \setlength{\leftmargin}{\labelwidth}%
  \setlength{\labelsep}{3pt}\setlength{\itemsep}{0pt}%
  \setlength{\parsep}{0pt}\setlength{\topsep}{0pt}%
  \footnotesize}\item[\hfill\@makefnmark]#1%
\end{list}}
\makeatother

%\newtheorem{theorem}{Theorem}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{definition}{Definition}

\title{\huge Roll your own Jape logic\\
             Encoding logics for the Jape proof calculator}
\author{Richard Bornat (richard@bornat.me.uk)%\\
        %Bernard Sufrin (sufrin@comlab.ox.ac.uk)
       }

\mathlig{->}{\rightarrow}
\mathlig{|-}{\vdash}
\mathlig{|=}{\vDash}
\mathlig{|*}{\exists}
\mathlig{|}{\lor}
\mathlig{!}{\neg}
\mathlig{@*}{\forall}
\mathlig{@}{\land}

\reservestyle{\word}{\operatorname}
\word{actual}

\reservestyle{\var}{\mathit}
\var{j1,j2}

\newcommand{\eqnref}[1]{(\ref{eqn:#1})}
\newcommand{\figref}[1]{figure \ref{fig:#1}}
\newcommand{\Figref}[1]{Figure \ref{fig:#1}}
\newcommand{\secref}[1]{section \ref{sec:#1}}
\newcommand{\Secref}[1]{Section \ref{sec:#1}}
\newcommand{\chapref}[1]{chapter \ref{chap:#1}}
\newcommand{\Chapref}[1]{Chapter \ref{chap:#1}}
                                                                                                    
\newcommand{\tab}{\hspace{5mm}}

\newcommand{\reason}[1]{\scalebox{0.85}{#1}}

\newcommand {\cols}[1][*{50}{l}]{\begin{array}{#1}}
\newcommand {\sloc}{\end{array}}

\begin{document}
\maketitle

\chapter*{Preface}

Jape is a lightweight, uncommitted, transparent proof calculator. It's designed to present an excellent graphical interface and a very short and shallow `learning curve' to all its users, whether novices learning how to make formal proofs or experts -- logicians, teachers, sofware engineers, practitioners of any kind -- describing inference systems. This manual is directed at people who have experimented with one or more of the inference systems distributed with Jape and now want to develop something of their own, or those who just want to understand what it is that Bernard Sufrin and I have done in our own encodings.


The chapters of this manual describe by example how to encode several interesting logics in Jape. They are intended to be read in sequence, as the earlier chapters give most description of the early stages of the encoding, and later chapters concentrate on more esoteric features.


A manual which described a task only by example would be inadequate, and I therefore include a complete description of the various internal `languages' of Jape:

\begin{itemize}
\item the \emph{term} or \emph{formula} or \emph{sequent} language, in which problems are stated, and which appears on-screen when a proof is displayed -- described in appendix A;
\item the \emph{tactic} language, which includes the statement of the inference rules of a logic, and which allows the user to control the course of a proof -- described in appendix B;
\item the \emph{paragraph} language, which is the notation used to describe a logic and its associated tactics and stuff to Jape -- described in appendix A;
\item the \emph{dialogue} language, which is the notation in which the graphical interface sends commands to the main proof engine, and in which you can type as text in a graphical interface window -- described in appendix C.
\end{itemize}


This manual doesn't discuss how to use Jape -- that's covered in other manuals.

This manual describes the state of the system in September 1997 (version v3.2f of the proof engine and version 3.2e of the logic encodings). The graphical illustrations are taken from the then current MacOS graphical interface (version 3.2b).

\section*{Improvements since 3.0}

Since version 3.0 I have implemented proper sequent syntax (Γs and Δs and that sort of thing), plus \emph{autoAdditive} variables for those who want to be able to state rules and theorems natural-deduction style. There is an option to allow interpretation of predicate notation, and I now automatically insert essential but invisible provisos into the statement of some rules and theorems. We've included a drag-and-drop gesture to support multiplicative rules and certain kinds of weakening rules.

\section*{Outstanding problems still awaiting a fix}

Some of the examples in this manual reveal deficiences with the current Jape system. If we stopped writing in order to improve the system each time we described one of its warts we would never finish. But any experimental system will always, at its frontier, have features which you might wish it didn't. What we list here are the things that we more or less understand how to fix. By putting the statement of problems here, we avoid repetitive apologies in the body of the manual.

\begin{itemize}
\item Jape doesn't check the proof store when you redefine a rule or theorem, and re-run all the proofs that depend on it (though it does now guard against circularities in proofs).
\item Jape can't handle sequents in which a side is an optional single formula.
\item Jape has no treatment of definitional equality (syntactic equivalence), so you have to handle it with additional rules.
\item You can't prove derived rules with antecedents, despite the fact that a theorem is just a kind of derived rule in Jape.
\end{itemize}

\section*{Serious problems which won't be fixed soon}

There are things about Jape which are wrong, but which we can't fix in a reasonable time.
\begin{itemize}
\item Jape cannot distinguish between classes of formulae in problem sequents, except for variables, constants, numbers and strings.
\item Jape has a long-standing problem in that it can't encode `families of rules'. We have used some ingenuity to allow you to encode such families by finite collections of slightly different rules, but the problem is very unlikely to be fixed without a large research project.
\item Jape's parser generator ought to make it possible to distinguish between lots of user-defined syntactic categories. It isn't clear how a parser generator can be both simple enough and powerful enough. We intend to find out, but once again it would have to be part of a large research project.
\end{itemize}


\section*{Future developments}

The field of logical systems is huge and growing. Jape doesn't cover it all, and no doubt people can invent logics faster than we can devise ways of encoding them. Nevertheless, we understand how to make Jape do much more than it can at present, and we are developing it constantly. At the time of writing, projects on the immediate horizon include modal logic, linear logic and improved support for equational reasoning as well as work to improve the graphical interface still further.

We are keen to hear from our users about the things that they want Jape to do, so that we can continue to develop it in practically useful directions.

\tableofcontents


\chapter{Basic Principles}


Jape works by applying inference rules to sequents in proof trees. Its fundamental mechanism is unification, laced with a pragmatic treatment of explicit substitution forms. Put like that, it may seem rather complicated, but it's really very simple. We decided on unification rather than one-way pattern-matching because it allows us to use Jape as a Prolog-style calculator, solving problems such as


$\lambda x.\lambda y.x\;y:\_T$

which would be completely intractable, or pointless, in a one-way-matching engine.\\
Tactics in Jape organise the application of other tactics. The simplest tactic is an inference rule.


On top of its basic proof mechanism Jape provides you with the opportunity to organise the graphical user interface by programming its response to the basic gestures of pointing and clicking, and by defining what is included in the menus and panels shown to the user.


\textbf{{\large 1.1\tab Flexible syntax}}


Jape has a built-in collection of syntactic forms, which you can customise and to which you can add the particular details which are appropriate to your particular logic. It recognises numbers, strings, identifiers, unknowns, bracketed formulae, tuples, substitutions, juxtapositions, and formulae made by using user-defined prefix, postfix and infix operators, with user-defined priorities and associativity. In addition you can invent various new kinds of brackets and punctuation.\\
Identifiers -- names like \textit{A}, \textit{x} or \textit{F} in conjectures, theorems and rules -- rarely stand for themselves. For the most part they stand for some arbitrary formula, variable or predicate which can appear in an instance of the conjecture, theorem or rule in which they are used. When you define the syntax of identifiers in your logic you say which are schematic identifiers and which are constants. At the same time you can define the syntactic category of the identifiers you use.


The flexible syntax mechanism is illustrated in every chapter, and detailed in appendix A.


\textbf{{\large 1.2\tab Backward proof}}


Jape always, always, always works backwards, even when its display mechanism tries to produce the illusion that it is working forwards. It always works with trees -- Gentzen trees -- of sequents, even when its display mechanism is trying to produce the illusion that it is working with Fitch boxes, or something else\footnote{Currently we have a box display which approximates Fitch boxes. We have the beginnings of a more attractive treatment of equational chaining proofs (see, for example, chapter 5) and we dream of a kind of Fitchery for linear logic, and more.}. If you haven't seen a Gentzen tree, you can learn how Jape handles them if you use one of the distributed logics that uses tree display mode, or you can switch to tree display mode in one of the distributed logics that allows it -- for example the single-conclusion sequent calculus encoding.


\textbf{{\large 1.3\tab Inference rule matching: instantiation and unification}}


Consider this example rule of the single-conclusion sequent calculus:


$\infer[\reason{$| |- $}]
       {\Gamma,A|B |- C}
       {\Gamma,A |- C\quad \Gamma,B |- C}$

Its rendition in Japeish (see the file SCS\_rules.j) is a straightforward linearisation of the original\footnote{Earlier versions of Jape required that the segment variable symbol \ensuremath{\Gamma} be omitted. Now it may optionally be omitted if every rule is `additive' in the linear logic sense: for examples see chapter 4.}

RULE "∧⊦" FROM Γ,A ⊦ C AND Γ,B ⊦ C INFER Γ,A∧B ⊦ C


Our interpretation of the rule is that it describes a node in a proof tree by pattern: the consequent at that node has a collection of formulae on its left-hand side, one of which matches $A|B$ for some pair of formulae \textit{A} and \textit{B} and the rest of which are taken as \ensuremath{\Gamma}, and a single right-hand side formula which matches \textit{C}. The node has two antecedents, each of which contains a sequent with the same right-hand side formula \textit{C}. The left-hand antecedent will have a sequent whose left-hand side is \ensuremath{\Gamma} together with the formula \textit{A}; the right-hand antecedent's left-hand side which is \ensuremath{\Gamma} together with \textit{B}.


Jape makes proofs by replacing tips of the tree with nodes generated from instances of rules, or sometimes with subtrees generated by instances of several rules. Given a rule and a tip (leaf node) in a Gentzen tree, Jape first \textit{instantiates} the rule, generating a version in which the schematic names -- in the rule above they are \ensuremath{\Gamma}, \textit{A}, \textit{B} and \textit{C} -- are replaced by fresh unknowns; then it \textit{unifies} the consequent of the newly-instantiated rule with the sequent at the tip. Typically a rule might unify in more than one way -- there might be more than one left-hand side formula, for example, which could unify with $A|B$ -- and in that case Jape requires the user to decide between the possibilities, either by selecting a preferred principal formula\footnote{A \textit{principal formula} (sometimes \textit{principal term}) in a rule in a sequent calculus is the one which the rule consumes, or works on. That's the formula which matches $A|B$ in this example.} beforehand, or by choosing from a menu of possibilities afterwards.


In the rule above there are various symbols of the logic as well as the schematic identifiers \ensuremath{\Gamma}, \textit{A}, \textit{B} and \textit{C}: there is the connective \ensuremath{|} and there are the punctuation marks ⊦ and comma. Although \ensuremath{|} is in a sense an identifier, it plays a fixed syntactic r\^{o}le in the logic and in the rule; it would be wrong to instantiate it with an unknown. Some other identifiers might be non-schematic: there might be constant identifiers \textit{true} and \textit{false}, for example. As logic describer you have control over the matter, which you exercise by organising identifiers into syntactic categories. This not only allows you to distinguish between constant and other identifiers, but it also allows you to distinguish, for example, between names like \textit{A} which might be taken to stand for some arbitrary formula, and names like \textit{x} which you might wish to stand only for variables.


\textit{Parameters of rules}


In simple cases the fact that Jape uses unification rather than one-way pattern matching doesn't have a visible effect on the course of a proof. But if a rule doesn't have the subformula property -- if there are names in its antecedents that don't appear in its consequent, as for example in


$\infer[\reason{$!-I$}]
       {\Gamma  |- !A}
       {\Gamma,A |- B@!B}$

-- then unknowns, generated during the instantiation step, may appear in the proof\footnote{This is a \textit{strength} of Jape, not a weakness: we don't require the user to decide prematurely on the identity of those unknowns.}.


In these and other circumstances it can be useful to allow the user to provide an argument formula which modifies the instantiation step. You do that by writing the rule definition with a parameter. The rule above is written in Japeish as

RULE "¬-I"(B) IS FROM Γ,A ⊦ B∧¬B INFER Γ ⊦ ¬A


Given a problem sequent $X,Y->!X |- !Y$, Jape unifies \_\ensuremath{\Gamma} with $X,Y->!X$ and \_\textit{A} with \textit{Y}; then it generates the antecedent $X,Y->!X,Y |- \_B@!\_B$ . If it is given the argument formula \textit{X} to use instead of \_\textit{B}, it will generate the antecedent $X,Y->!X,Y |- X@!X$ . In many cases an argument supplied to the application of a rule can prevent a startling proliferation of unknowns in a proof.\\
The parameter of a rule may in some circumstances be decorated with the word \textsc{object}. That indicates that in the absence of a user-supplied argument, the instantiation step is to generate a freshly-minted identifier in its place rather than a fresh unknown. Frequently this is because the rule expresses a generalisation step in the logic and it is natural for Jape to mint a fresh name. For example, the rule


$\infer[\reason{$(\;c,\;c\;\;|*x.A)\;\;|*-E$}]
       {\Gamma |- C}
       {\Gamma  |-|*x.A\quad \Gamma,A[x\backslash c] |- C}$

is written as

RULE "∃-E"(OBJECT c) WHERE FRESH c AND c NOTIN ∃x.A IS \\
\tab FROM Γ ⊦ ∃x.A AND Γ,A[x{\textbackslash}c] ⊦ C INFER Γ⊦C


\textsc{Object} parameters are used in other circumstances -- in particular, see the discussion of substitution unification below.


\textbf{{\large 1.4\tab Explicit provisos}}


Jape's provisos at present are \textsc{notin} and \textsc{unifieswith}, plus three macro-relatives of \textsc{notin}: \textsc{fresh, hypfresh} and \textsc{concfresh}.


Provisos are either satisfied or violated, and they constrain the application of rules. If an attempted application would violate a proviso, whether one contained in the rule itself or one left over from an earlier stage of the proof, then the attempt fails. If it is impossible to determine the status of a proviso, because it contains unknowns and/or substitution forms, then it is stored, displayed as part of the proof, and carried forward in the expectation that its status will become clearer.


The proviso \textit{x} \textsc{notin} \textit{E} is satisfied if \textit{x} doesn't appear free in \textit{E}\footnote{Strictly if it \textit{cannot} appear free, no matter what future unifications may happen and no matter how the schematic identifiers of the conjecture being proved are instantiated. The proviso \textit{x} \textsc{notin} \textit{y} is not automatically nor trivially satisfied.} and violated if it does. \textsc{notin} provisos are either included in the statement of a rule or generated from \textsc{fresh, hypfresh} or \textsc{concfresh} provisos: \textsc{fresh} \textit{x} generates a proviso \textit{x} \textsc{notin} \textit{E} for every left- and right-hand side formula \textit{E} of the sequent matching the rule; \textsc{hypfresh} \textit{x} generates \textsc{notin} provisos only for the left-hand side formulae and \textsc{concfresh} for the right-hand side formulae.


The proviso \textit{E1} \textsc{unifieswith} \textit{\textsc{E2}} is internally generated. It allows Jape to defer difficult unifications where it can't find a most-general unifier. This can arise because of difficulties in unifying substitution forms, or when using multiplicative (context-splitting) rules.


\textbf{{\large 1.5\tab Conjectures and theorems}}


We allow the user to state a conjecture using the \textsc{theorem} directive\footnote{Conjecture, theorem, which do we mean? There is no split personality here, but there are two Jape authors. One wants to emphasise that it's a conjecture till it's proved; the other wants to emphasise that it is theorems, after all, that you are trying to prove.}. A proved conjecture becomes a theorem and can then be applied as a kind of derived rule; if the state variable \textit{applyconjectures} is set to \textit{true} then unproved conjectures can be applied as if they were proved.


The \textsc{theorem} directive gives the name of a conjecture and its sequent, and it may also include provisos which will be enforced both during the proof of the conjecture and whenever the theorem is applied. It is possible to define a theorem without giving a name, in which case the sequent itself is used as the name. The \textsc{theorems} directive allows you to state a collection of conjectures, and will give each its own sequent as a name. For example, the SCS.jt file defines a conjecture called \textit{contradiction}

THEOREM contradiction IS A, ¬A ⊦ B


and the sequent\_problems.j file includes a large collection of conjectures named by their sequent, some of which are as follows:

THEOREMS PropositionalProblems ARE\\
\tab P→(Q→R) ⊦ (P→Q)→(P→R)\\
AND\tab P→(Q→R), Q ⊦ P→R\\
\tab ....\\
AND\tab WHERE x NOTIN P INFER P ∧ ¬P, ∀x.P→Q, ∀x. ¬P→Q ⊦ ∀x.Q \\
AND\tab R ∧ ¬R, ∀x.R→S, ∀x. ¬R→S ⊦ ∀x.S\\
....\\
AND\tab ∃y.P ⊦ ∀y.P\\
END


The conjectures in this illustration are called ``P→(Q→R){\nobreakspace}⊦{\nobreakspace}(P→Q)→(P→R)'', ``P→(Q→R),{\nobreakspace}Q{\nobreakspace}⊦{\nobreakspace}P→R'', ``P∧¬P,{\nobreakspace}∀x.P→Q,{\nobreakspace}∀x.¬P→Q{\nobreakspace}⊦{\nobreakspace}∀x.Q'' (the provisos aren't part of the name), ``R∧{\nobreakspace}R,{\nobreakspace}∀x.R→S,{\nobreakspace}∀x.¬R→S{\nobreakspace}⊦{\nobreakspace}∀x.S'' and ``∃y.P{\nobreakspace}⊦{\nobreakspace}∀y.P''.


\textit{Proving a conjecture -- substitutions and provisos}


A proof of a conjecture begins with a tree which consists of the base sequent of the conjecture, together with any provisos which were included in the statement of the conjecture\footnote{Jape sometimes adds invisible provisos which it deduces from the binding structure of the formulae in the conjecture. Those provisos can be made visible: see `invisible provisos' below, and also appendix C.}. The proof is then developed by application of rules and tactics.


One important feature of the proof is Jape's treatment of the identifiers and unknowns that appear in the base sequent of the conjecture, and its treatment of other identifiers that may be introduced during the proof process. Jape's theorems are theorem schemata, not particular theorem formulae; they may therefore be instantiated in the same way as a rule, replacing identifiers in the theorem sequent by unknowns or arbitrary formulae. Identifiers in the conjecture's sequent can't, therefore, be treated as standing for themselves during the proof.


In practice this means that substitution forms involving those identifiers may not be simplifiable: if, for example, identifiers \textit{A} and \textit{x} appears in the conjectured sequent then $A[x\backslash E]$ can't be replaced by \textit{A} unless it is certain that there will never be an instance of the theorem in which the formula which instantiates \textit{A} has a free occurrence of the variable which instantiates \textit{x}. But if \textit{x} is a name introduced during the proof -- for example, by application of a rule which has an \textsc{object} parameter -- and if there are no unknowns in the base sequent of the proof, so that \textit{x} cannot be smuggled into the statement of the theorem we are proving, then we reason that whatever argument formula instantiates \textit{A}, we could choose \textit{x} within the proof to be distinct from all the names in \textit{A}, and therefore $A[x\backslash E]$ can be replaced by \textit{A}. In other circumstances the assurance that \textit{x} can't occur free in \textit{A} can come from a \textsc{notin} proviso, or from meta-theoretical reasoning about the relationships of names in the conjectured sequent.


Provisos that are introduced during proof of a conjecture, by application of rules or other theorems or conjectures, and which aren't evidently satisfied or violated are retained as part of the theorem and checked whenever the theorem is applied.\\
The effect of our care with substitutions and provisos is that the proof tree which establishes the validity of a conjecture stands for all the proof trees of all the instances of that conjecture, and Jape is justified in using such a conjecture as a derived rule.


\textit{Applying a theorem: the r\^{o}le of structural rules}


A theorem is, in principle, a rule with no antecedents. So Jape can instantiate it as a rule and match it to a problem sequent just as a rule is matched. There are, however, a couple of interesting points.


The first is that in many cases a theorem won't have enough left-hand or right-hand side formulae to completely match a problem sequent. The theorem ``P→(Q→R){\nobreakspace}⊦{\nobreakspace}(P→Q)→(P→R)'', for example, matches only sequents with exactly one formula on the left of the turnstile and one on the right. Often a logic will include so-called `weakening' rules which enable you to delete a formula from the left- or the right-hand side or both. If you include such rules and declare their r\^{o}le to Jape, it will allow you to apply a theorem even though it does not completely match a problem sequent.


The second difficulty is that sometimes a theorem matches on the right-hand side, but not on the left. In such a case it is often convenient to prove it `by resolution': that is, to generate an antecedent for each of the left-hand side formulae and to set about proving them. That step is justified if the logic contains a `cut' rule which enables you to move formulae from left- to right-hand side. Jape will make a resolution step for you if you declare the appropriate structural rules in your logic, declare their r\^{o}les, and also set the \textit{tryresolution} variable (see appendix C) or use one of the \textsc{applyorresolve} or \textsc{resolve} tacticals (see appendix B).


\textbf{{\large 1.6\tab Substitution forms and unification}}


Jape uses explicit substitution forms -- $A[x\backslash c]$, $B[x,y,z\backslash E,F,G]$ -- where some logics use predicate notation -- $P(c)$, $Q(E,F,G)$ . Substitutions are more powerful than predicates because they are more general; for the same reason they are trickier to handle. Jape's internal mechanisms are based on substitution forms, but there is now a mechanism which allows you to write rules and theorems in terms of predicate formulae. Jape will translate into substitution notation, and construct automatically the additional parameters and fussy \textsc{notin} provisos that it needs -- see `interpreting predicates' below.


Explicit substitution forms are semantically scandalous, a notorious trap for novices, and an expert will ask ``what does a substitution form in a rule or theorem \textit{mean}?''. It's difficult to give a simple answer. It is never necessary to include special rules to treat substitution forms -- their treatment is a fundamental mechanism of Jape, and Jape tries to eliminate substitution forms from the proof whereever and whenever they appear. Therefore we can say that Jape treats a substitution form as equivalent to the result of carrying out the subsitution. But in some situations it can be persuaded to treat a substitution form as a structural pattern and will unify one unreduced substitution form with another, even though such unifications don't give the most general answer.


A substitution form is introduced into a proof, and if possible immediately eliminated, whenever the antecedent of a rule contains one. Consider, for example, the problem sequent $x>y |-|*z.z>y$ . If we apply the rule


$\infer[|-\exists] {\Gamma|-|*x.A,\Delta} {\Gamma|-A[x\backslash E],\Delta}$

then we generate a single antecedent $x>y |- (z>y)[z\backslash \_E]$, which immediately simplifies to $x>y |- \_E>y$ provided that we know that \textit{z} and \textit{y} are necessarily distinct\footnote{They might not be if, for example, they both appear in the base sequent of the conjecture being proved. They may be if, for example, one or the other has been generated during the development of the proof, or if there is an explicit proviso which makes it clear that they are distinct.}.


Much more interesting is what happens when a rule contains an explicit substitution form such as $A[x\backslash E]$ in its \textit{consequent}. When the rule is applied Jape must unify that substitution form -- or rather, its instantiated form which in general will be $\_{}A[\_{}x\backslash \_{}E]$ -- with some formula \textit{B} in the problem sequent. That sort of unification is notoriously difficult, and Jape uses a number of ad-hoc strategies to help.


i\tab It simplifies substitution forms whenever possible, in order to avoid the problem.


ii\tab It defers the unification of an irreducible substitution form for as long as possible, so that the results of other unifications can be used to simplify it.


iii\tab If the user provides an argument formula \textit{F} in place of parameter \textit{E}, the instantiated form will be $\_{}A[\_{}x\backslash F]$ ; when Jape can no longer avoid unifying that form with \textit{B} it will search for all instances of \textit{F} inside \textit{B} and try to construct a substitution form $B' [\_{}x\backslash F]$ which simplifies to \textit{B} in presence of the proviso \_\textit{x}{\nobreakspace}\textsc{notin{\nobreakspace}}\textit{\textsc{B}}; if successful it will unify \_\textit{A} with $B' $ in a context that records the proviso. The process is far more effective if the parameter \textit{x} is decorated with the word \textsc{object}, so that the instantiated form becomes $\_{}A[z\backslash F]$ where \textit{z} is a fresh variable; the formula $B' [z\backslash F]$ is easier to construct and to simplify, and the proviso \textit{z}{\nobreakspace}\textsc{notin}{\nobreakspace}\textit{B} is easier to check\footnote{In fact, because \textit{z} is a fresh variable, the proviso is usually obviously satisfied. But a proviso is necesssary to constrain the future course of the proof if there are unknowns in \textit{B}. In those and in some other circumstances Jape may also produce \textsc{unifieswith} provisos to cater with the process of abstraction in the nasty bits of \textit{B}.}.


iv\tab If the user text-selects instances of a sub-formula \textit{F} of \textit{B}, then the logic encoding can employ the \textsc{withsubstsel} tactical -- see chapter 5 and appendix B -- to calculate $B' $ by replacing just those instances of \textit{F} by a fresh unknown \_\textit{y}; $B' [\_{}y\backslash F]$ necessarily simplifies to \textit{B} given the proviso \_\textit{y}{\nobreakspace}\textsc{notin}{\nobreakspace}\textit{B}; then Jape will unify \_\textit{A} with $B' $, \_\textit{x} with \_\textit{y} and \_\textit{E} with \textit{F} in a context which records the proviso. If the parameter \textit{x} is decorated with the word \textsc{object} then \_\textit{x} is replaced by \textit{z} and the proviso becomes \textit{z}{\nobreakspace}\textsc{notin}{\nobreakspace}\textit{B}, which is once again easier to check.


v\tab If all else fails, Jape can generate a proviso $\_{}A[\_{}x\backslash \_{}E]$ \textsc{unifieswith} \textit{B}, and await developments.


If Jape has to unify two substitution forms which have identical variable lists then it unifies the base formulae and the substituted formulae. For example, it can unify $A[x,y\backslash A1,A2]$ with $B[x,y\backslash B1,B2]$ by unifying \textit{A} with \textit{B}, \textit{A1} with \textit{B1}, \textit{A2} with \textit{B2}. This happens rarely and sometimes it might not be the best thing to do, but pragmatically it seems to work rather well almost every time it is used.\\
If Jape has to unify substitution forms with different variable lists then it extends one or the other: for example, if it has to unify $A[x\backslash A1]$ with $B[x,y\backslash B1,B2]$ it will try to construct $A' $ such that $A[y\backslash B2]$ simplifies to \textit{A}, and then unify $A[x,y\backslash A1,B2]$ with $B[x,y\backslash B1,B2]$ . In certain circumstances it will even do a bit of \ensuremath{\alpha}-conversion -- but enough! this explanation is sufficiently complicated already.


The message is that Jape's unification of substitution forms is usefully pragmatic. It does not always generate a most-general unifier but it can, in practice, often generate just the unifier that the user is looking for, especially when the encoding uses the \textsc{letsubstsel/withsubstsel} mechanism (see chapter 5 and appendix B) to allow the user to describe the unification to Jape. It most often breaks down when it has to deal with substitutions using variables which also appear in the base sequent of the theorem being proved. That breakdown is, we think, inevitable, though we continue to search for ways round the difficulty.


\textit{Invisible provisos}


Consider the conjectures $\lambda x.\lambda y.x:T1->T2->T1$ and $@*x.|*y.P(x)=P(y)$ . Clearly, in each case, any instance of the conjecture would have to use two distinct variables. Nothing else would give the right binding structure: $\lambda z.\lambda z.z:\operatorname{int} ->\operatorname{real}->\operatorname{int} $ isn't an instance of the first conjecture, nor $@*z.|*z.Q(z)=Q(z)$ of the second\footnote{Strictly speaking, this second \textit{might} be an instance of the the conjecture, if there are no instances of \textit{z} in \textit{Q}. These are deep waters...}. But Jape's mechanisms of rule and theorem instantiation don't automatically ensure this: instead, there has to be a proviso such as \textit{x} \textsc{notin} \textit{y} in each case. Such provisos are fussy, have to do with the internal mechanisms of Jape, and are difficult to explain to Jape's users. Therefore Jape generates them automatically, from an analysis of the binding structure of every rule and conjecture, and then makes them invisible. You can see the invisible provisos in a proof by setting the \textit{showallprovisos} variable to \textit{true}.


\textit{Interpreting predicate notation}


Some of our users prefer predicate notation to substitution, and in certain ways it concisely conveys more information. In the formula $@*x.P(x)$ it is implicit that the predicate formula \textit{P} doesn't contain any instances of \textit{x}; in the corresponding formula $@*x.P\left[ v\backslash x\right] $ no such inference can be drawn, and the statement of a theorem which contained such a formula would require a proviso \textit{x} \textsc{notin} \textit{P} to say as much as the predicate version. Fussy provisos get substitution notation a bad name, so we have implemented a mechanism which interprets predicate notation, translating it into substitution notation. When you apply a rule which contains

$@*x.P(x)$, for example, Jape translates it into $@*x.P\left[ v\backslash x\right] $, automatically inserting the necessary proviso. When you begin a proof which contains $@*x.P(x)$, Jape doesn't translate it, but it does insert the same proviso, making it invisible.


If you set the variable \textit{interpretpredicates} to \textit{true}, Jape treats every juxtaposition as if it were a predicate application. If \textit{interpretpredicates} is \textit{false} (the default), Jape only interprets those juxtapositions in which the first formula is an \textsc{abstraction} parameter name. See chapters 4 and 5 for examples.


In one respect Jape's interpretation of predicate notation is pragmatically helpful rather than careful. Consider, for example, the sequent $|*x.@*y.P(x,y) |- @*y.|*x.P(x,y)$ . Jape translates this to $|*x.@*y.P\left[ u,v\backslash x,y\right]  |- @*y.|*x.P\left[ u,v\backslash x,y\right] $, and automatically includes provisos \textit{x} \textsc{notin} \textit{P} and \textit{y} \textsc{notin} \textit{P}, as it should. Jape also includes \textit{x} \textsc{notin} \textit{y}, which isn't essential in order to preserve the binding structure, because it is not required that either \textit{x} or \textit{y} must appear free in a predicate $P(x,y)$ . The effect is that certain instances of the theorem are excluded. In practice it seems that our users prefer it this way.


\textbf{{\large 1.7\tab Binding forms: unification, \ensuremath{\alpha}-conversion and substitution}}


Suppose that $@*var.formula$ has been defined to be a binding form: then Jape will proceed as follows:


{\textbullet}\tab it will unify $@*x.A$ with $@*x.B$ by unifying \textit{A} with \textit{B};\\
{\textbullet}\tab it will unify $@*x.A$ with $@*\/\_{}y.B$ by unifying \textit{x} with \_\textit{y} and \textit{A} with \textit{B};


{\textbullet}\tab it will unify $@*x.A$ with $@*y.B$ by unifying $@*z.A[x\backslash z]$ with $@*z.B[y\backslash z]$, where \textit{z} is a fresh variable, together with the provisos \textit{z} \textsc{notin} \textit{A} and \textit{z} \textsc{notin} \textit{B}.


Jape respects binding forms when carrying out substitutions. Thus, for example, if $@*var.formula$ has been defined to be a binding form and \textit{x} and \textit{y} are guaranteed distinct then $(@*x.A)[x\backslash E]$ always simplifies to $@*x.A$ and, provided that \textit{x} doesn't appear free in \textit{F}, $(@*x.A)[y\backslash F]$ will simplify to $@*x.(A[y\backslash F])$ ; in other circumstances it will simplify to by \ensuremath{\alpha}-conversion to $@*z.(A[x,y\backslash z,F])$ together with the proviso \textit{z} \textsc{notin} \textit{A}, where \textit{z} is a fresh variable.


\textbf{{\large 1.8\tab The tactic language}}


Although Jape's basic operation is the application of rules to tips of a proof tree, that is by no means the whole story. You will often find it necessary to organise the application of rules by writing programs in the tactic language.


The simplest tactics are inference rules. You can apply tactics sequentially (\textsc{seq}), or try one after another (\textsc{alt, when}), you can call tactics with arguments, you can repeat tactics (\textsc{do}); there is a notion of the `current goal' sequent in the tree which is used when tactics are applied in sequence. It is possible, under very severe constraints, to transform formulae within the goal sequent (\textsc{find, flatten, withsubstsel}).


Most of the language has to do with the interpretation of gestures and selection of an appropriate response.\\
Appendix B gives a complete list of all the verbs of the tactic language. The chapters of this manual give examples of their use.


\textbf{{\large 1.9\tab Gestures, menus and panels}}


The user can make certain `gestures' at the Jape graphical interface. The way in which the gestures are made -- which buttons and keys are pressed and how the mouse is moved -- varies between the interfaces, and is not discussed here.


{\textbullet}\tab A user can \textit{select} a formula in a sequent. If a rule is then applied, Jape requires that the selected formula is a principal formula in the rule. Thus, for example, if you select the hypothesis

$X|Y$ in the sequent $U|V,\;X|Y,\;U->X |- U@X$ and then apply the rule


$\infer[\reason{$| |- $}]
       {\Gamma,A|B |- C}
       {\Gamma,A |- C\quad \Gamma,B |- C}$

\tab you ensure that $A|B$ in the rule matches $X|Y$ in the sequent, \ensuremath{\Gamma} matches $U|V,\;U->X$ and, of course, \textit{C} matches $U@X$ . If a tactic is applied it can test for formula selection, discover the formula selected, and modify its behaviour accordingly


{\textbullet}\tab A user can double-click (`hit') on a formula, causing the application of a tactic chosen by the logic description.


{\textbullet}\tab A user can double-click on the `reason' or `justification' of a proof step. If there is hidden detail behind that step then it will be revealed, or if it has been revealed by an earlier double-click, it will be hidden again.


{\textbullet}\tab A user can drag a formula. If there is a \textsc{unifieswith} proviso, generated as a result of context-splitting in a multiplicative rule, some of the other formulae mentioned in that proviso -- unknown segment variables like \_\ensuremath{\Gamma} or \_Δ1 -- will highlight as the formula is dragged across them.


{\textbullet}\tab A user can \textit{text-select} part -- typically, a sub-formula -- of a formula in a sequent. If a rule is applied, the text selection is provided as an argument to the application. If a tactic is applied, it can test for text selection, discover the text selected, and modify its behaviour accordingly.


{\textbullet}\tab A user can select an entry in a menu, and Jape will carry out the corresponding command. Most entries correspond to the command \textit{apply T} for some tactic \textit{T}, but a menu can contain any of the commands listed in appendix C. A good deal of your user-interface design activity will go into deciding what goes in which menus, fixing on labels for each entry and choosing just the right commands.\\
{\textbullet}\tab A user can press a button in a panel, with or without first choosing an entry from the list of entries in the same panel. Many panels list conjectures, and their buttons allow users to prove the chosen conjecture, apply it as a theorem and so on. Other panels may be like menus. The designer controls what is in the entries and what is on the buttons, and whether or not a particular button sends just a command, or a command modified by the selected entry.


{\textbullet}\tab A user can scroll the proof horizontally and/or vertically.


And that's it. Jape uses a very impoverished vocabulary of gesture: we have chosen to make it so, in an attempt to make Jape as straightforward to use as any other application in a modern GUI environments.


\textbf{{\large 1.10\tab Proof display: trees, boxes and hiding}}


The Gentzen tree is the basic proof structure on which Jape works. Behind the scenes, whatever is on the screen, is a Gentzen tree. Tactics can be used to hide selected antecedents of a proof step and alter the `reason' or `justification' displayed with the step; the hidden detail can be revealed to a user who double-clicks appropriate parts of the proof.


Gentzen trees are notoriously wasteful of space, and Fitch boxes famously less so. Jape can display a proof in an approximation to Fitch box style. The display is a transcription -- not a translation -- of the tree, and it can be applied to any kind of logic, not simply natural deduction:


{\textbullet}\tab the assumptions -- left-hand side formulae -- of the base sequent are written on the first line and the conclusion(s) -- right-hand side formula(e) -- on the last line;\\
{\textbullet}\tab if a line is the conclusion of a proof step then the lines representing the trees of its antecedents are written out before it, working left to right through the antecedents;


{\textbullet}\tab the justification of a line which is the conclusion of a proof step references the assumption line(s) to describe any left-hand side principal formulae, as well as the lines which contain the conclusions of its antecedents;


{\textbullet}\tab if a line is the conclusion of a tip then a line of dots is written before it;


{\textbullet}\tab if an antecedent introduces any hypotheses then its lines are written in a box, whose first line is those hypotheses and whose last line is the right-hand side formula(e) of the antecedent.


That makes a fairly compact description, in which hypotheses are written only once but conclusions may be written more often, especially when a left-hand side rule is used. It is made still more compact by hiding applications of \textsc{identity} (\textit{axiom, hypothesis}) rules, and it is made to support some forms of forward reasoning (see chapter 4) by hiding, under the right circumstances, applications of a \textsc{cut} rule.


If you select a conclusion formula in a box display, the effect is just as if you had selected the corresponding conclusion formula in the underlying Gentzen tree. If you select a hypothesis formula the effect can't be so simple, because a hypothesis formula is written only once even though it may occur in many sequents: Jape finds the set of sequents that you could be pointing to and disambiguates the choice using any conclusion selection that you might have made.


It doesn't make sense to use box display with a multiple-conclusion calculus for various reasons, and Jape's gesturing mechanisms therefore haven't been adapted to this use.


Our box display isn't a proper Fitch box display because you can't necessarily use the proof which ends on line \textit{j} when making a proof step on a subsequent line \textit{k}, even though the box structure would allow it. The reason is that line \textit{j} may be part of the proof of some cousin of \textit{k}, not part of the proof of \textit{k} -- that is, parts of the proof which are sequentially related in the box display aren't necessarily hierarchically related in the underlying Gentzen tree. We are working on the problem. For the moment we provide some assistance by making the underlying tree structure more evident when the user selects an assumption or a conclusion: Jape will `grey out' lines in the box display which are irrelevant because they are not hierarchically related in the underlying tree.


\textbf{{\large 1.11\tab Using Jape interactively}}


Jape normally starts up `empty', with no theory loaded, although it is possible to save a version of Jape into which a theory has been loaded (using the saveengine command of appendix C: for details of its use see the technical documentation about your version of Jape).


You can load a new theory into Jape by using a command from the File menu (Load New Theory, or something like that). At any time you can add additional bits of Japeish to the brew, by using another of the commands on the File menu (Open Logic file, or something like that). Jape works, like LISP or ML, by maintaining a store of definitions, and it is always possible to add to those definitions. The effects may be strange, especially if you try to add a new theory without getting rid of the old one first!



\chapter{Encoding the Sequent Calculus}


Jape is, at bottom, a backwards-reasoning proof editor working on a tree of sequents. It is therefore no surprise that it is exceptionally straightforward to encode the sequent calculus in Jape. We describe in this chapter the encoding of the multiple-conclusion sequent calculus (distributed with Jape in the file MCS.jt and the files it references).


In the distributed files we have described the syntactic r\^{o}le of the \ensuremath{\equiv} connective and included inference rules and conjectures which make use of it, inherited from MacLogic. We haven't included that connective in this discussion.


\textbf{{\large 2.1\tab The inference rules of the (multiple-conclusion) Sequent Calculus}}


We have encoded a fairly standard version of the sequent calculus.
By making our left- and right-hand sides \textit{bags} (aka multisets) of formulae we have avoided the need for exchange rules; by allowing the axiom rule to ignore unnecessary hypotheses and conclusions we have avoided the need to use weakening rules in almost every case and/or to describe context-splitting rules. See chapter 3 for an alternative treatment of quantifiers and variables and for Jape's treatment of context-splitting (multiplicative) rules.


\textit{axiom\\
}

\begin{tabular}{|p{1.389in}|p{0.069in}|}
\hline
% ROW 1
{\raggedright 
$\infer[\reason{$axiom$}]
       {\Gamma,A |- A,\Delta }
       {}$
}\\
\hline
\end{tabular}


\textit{Introduction to the right of the turnstile (⊦... rules)\\
}

\begin{tabular}{llllllll}
\hline
% ROW 1
\multicolumn{1}{|p{1.098in}|}
{\raggedright

$\infer[\reason{$ |- @$}]
       {\Gamma  |- A@B,\Delta }
       {\Gamma  |- A,\Delta \quad \Gamma  |- B,\Delta }$
} & 
\multicolumn{1}{p{1.098in}|}
{\raggedright

$\infer[\reason{$
\; |- ->$}]
       {\Gamma  |- A->B,\Delta }
       {\Gamma,A |- B,\Delta }$
} & 
\multicolumn{1}{p{1.098in}|}
{\raggedright

$\infer[\reason{$ |- |$}]
       {\Gamma  |- A|B,\Delta }
       {\Gamma  |- A,B,\Delta }$
} & 
\multicolumn{1}{p{1.038in}|}
{\raggedright

$\infer[\reason{$ |- !$}]
       {\Gamma  |- !A,\Delta }
       {\Gamma,A |- \Delta }$
}\\
\hline
% ROW 2
\multicolumn{1}{p{0.042in}|}
{\raggedright

$\infer[\reason{$(m)\; |- @*$}]
       {\Gamma  |- @*x.A\left(
x\right),\Delta }
       {\Gamma  |- A\left( m\right),\Delta }$
} & 
\multicolumn{1}{p{0.042in}|}
{\raggedright

$\infer[\reason{$ |-|*$}]
       {\Gamma  |-|*x.A\left(
x\right),\Delta }
       {\Gamma  |- A\left( B\right),\Delta }$
}\\
\hline
\end{tabular}


\textit{Introduction to the left of the turnstile (...⊦ rules)\\
}

\begin{tabular}{llllllll}
\hline
% ROW 1
\multicolumn{1}{|p{0.852in}|}
{\raggedright

$\infer[\reason{$@|- $}]
       {\Gamma,A@B |- \Delta }
       {\Gamma,A,B |- \Delta }$
} & 
\multicolumn{1}{p{1.432in}|}
{\raggedright

$\infer[\reason{$->|- $}]
       {\Gamma,A->
B |- \Delta }
       {\Gamma  |- A,\Delta \quad \Gamma,B |- \Delta }$
} & 
\multicolumn{1}{p{1.099in}|}
{\raggedright

$\infer[\reason{$| |- $}]
       {\Gamma,A|
B |- \Delta }
       {\Gamma,A |- \Delta \quad \Gamma,B |- \Delta }$
} & 
\multicolumn{1}{p{0.946in}|}
{\raggedright

$\infer[\reason{$!|- $}]
       {\Gamma,!A |- \Delta }
       {\Gamma  |- A,\Delta }$
}\\
\hline
% ROW 2
\multicolumn{1}{p{0.043in}|}
{\raggedright

$\infer[\reason{$@*|- $}]
       {\Gamma,@*x.A\left(
x\right)  |- \Delta }
       {\Gamma,A\left( B\right)  |- \Delta }$

$\infer[\reason{$@*L$}]
       {\Gamma,@*x.A |- C}
       {\Gamma,A[x\backslash E] |- C}$

$\infer[\reason{$(m)\;|*|- $}]
       {\Gamma,|*x.A\left(
x\right)  |- \Delta }
       {\Gamma,A\left( m\right)  |- \Delta }$
}\\
\hline
\end{tabular}


\textit{Structural rules\\
}

\begin{tabular}{llllll}
\hline
% ROW 1
\multicolumn{1}{|p{1.466in}|}
{\raggedright

$\infer[\reason{$
\;cut$}]
       {\Gamma  |- \Delta }
       {\Gamma  |- B,\Delta \quad \Gamma,B |- \Delta }$
} & 
\multicolumn{1}{p{1.523in}|}
{\raggedright

$\infer[\reason{$weaken |- $}]
       {\Gamma,A |- \Delta }
       {\Gamma  |- \Delta }$
} & 
\multicolumn{1}{p{1.341in}|}
{\raggedright

$\infer[\reason{$ |- weaken$}]
       {\Gamma  |- A,\Delta }
       {\Gamma  |- \Delta }$
}
$\infer[\reason{$left\;contra$}]
       {\Gamma,A |- \Delta }
       {\Gamma,A,A |- \Delta }$\\
\hline
% ROW 2
\multicolumn{1}{p{1.341in}|}
{\raggedright
} & 
\multicolumn{1}{p{0.057in}|}
{\raggedright

$\infer[\reason{$contract |- $}]
       {\Gamma,A |- \Delta }
       {\Gamma,A,A |- \Delta }$
} & 
\multicolumn{1}{p{0.057in}|}
{\raggedright

$\infer[\reason{$ |- contract$}]
       {\Gamma  |- A,\Delta }
       {\Gamma  |- A,A,\Delta }$
}\\
\hline
\end{tabular}


The ⊦∧, →⊦, ∧⊦ and \textit{cut} rules don't split their left- or right-hand side contexts -- they are additive rather than multiplicative. Context-splitting rules are harder to use in a backwards reasoning tool, because either the tool must force the user to decide how to split the context before the rule is applied or else it must provide machinery to allow the decision to be deferred (see chapter 3, however, for a discussion of Jape's treatment of context-splitting rules). In practice, the fact that the \textit{axiom} rule ignores unnecessary hypothesis and conclusion formulae makes context-splitting on either side unnecessary.


Because Jape interprets predicate notation as shorthand for substitution, the \textit{actual} quantifier rules use substitution. These are the rules which Jape employs, translating those above on input:\\


\begin{tabular}{|p{2.220in}|p{2.194in}|p{0.043in}|p{0.043in}|}
\hline
% ROW 1
{\raggedright 
$\infer[\reason{$(m)\; |- @*$}]
       {\Gamma  |- \forall
x.A,\Delta }
       {\Gamma  |- A\left[ x\backslash m\right],\Delta }$
} & 
{\raggedright 
$\infer[\reason{$ |-|*$}]
       {\Gamma  |- \exists
x.A,\Delta }
       {\Gamma  |- A\left[ x\backslash B\right],\Delta }$
}\\
\hline
% ROW 2
{\raggedright 
$\infer[\reason{$@*|- $}]
       {\Gamma,\forall
x.A |- \Delta }
       {\Gamma,A\left[ x\backslash B\right]  |- \Delta }$

$\infer[\reason{$@*L$}]
       {\Gamma,@*x.A |- C}
       {\Gamma,A[x\backslash E] |- C}$

$\infer[\reason{$(m)\;|*|- $}]
       {\Gamma,\exists
x.A |- \Delta }
       {\Gamma,A\left[ x\backslash m\right]  |- \Delta }$
}\\
\hline
\end{tabular}


The difference need hardly detain us: there are no additional provisos, and no substitution-matching is required. In this logic at least, it's easy to believe that Jape manipulates predicate notation directly.


\textbf{{\large 2.2\tab Preliminaries -- fonts and syntax}}


Our presentation uses the Konstanz font encoding, due to Roy Dyckhoff. We use names starting with A, B, C, D, P, Q, R and S in rules and conjectures to stand for any formula; we use names starting with u, v, w, x, y, z. m or n to stand for any variable. Names starting with \ensuremath{\Gamma} or Δ stand for bags (multisets) of formulae\footnote{Note that now there are no commas in these lists of identifier prefixes: in general we have eliminated use of comma as a separator in the paragraph language.}.

FONTS "Konstanz"

CLASS BAG Γ Δ\\
CLASS FORMULA A B C D P Q R S\\
CLASS VARIABLE u v w x y z m n


These directives also cover unknowns: an unknown which starts \_\textit{A} will unify with any formula, but one which starts \_\textit{z} will only unify with a variable, a name which stands for a variable, or a similar unknown.


The syntax of sequent calculus formulae is defined as follows:

LEFTFIX\tab 20\tab ∀.\\
LEFTFIX\tab 20\tab ∃.

INFIX\tab 100 L\tab ≡\\
INFIX\tab 110 R\tab →\\
INFIX\tab 150 L\tab ∧\\
INFIX\tab 160 L\tab ∧

PREFIX\tab 200\tab ¬

JUXTFIX\tab 300\\
SUBSTFIX\tab 400 


Working from the bottom, this defines substitution forms as the most binding, then juxtaposition. Next comes ¬ defined as a prefix operator, then the binary connectives (all but → are defined to be left-associative, while → is right-associative). Finally two special bracketed forms are defined, with the lowest syntactic priority. These definitions allow us to write:


{\textbullet}\tab ¬ \textit{prim}, where \textit{prim} is an atomic formula, a substitution or a juxtaposition (see appendix A);


{\textbullet}\tab \textit{f1} \ensuremath{|} \textit{f2}, \textit{f1} \ensuremath{@} \textit{f2} or \textit{f1} \ensuremath{->} \textit{f2} with the interpretation that \ensuremath{|} `operators' have priority over \ensuremath{@}, and both have priority over \ensuremath{->};


{\textbullet}\tab \ensuremath{\forall} \textit{f1}. \textit{f2} and \ensuremath{\exists} \textit{f1} . \textit{f2}.


Note that the leftfix patterns don't constrain you to write \ensuremath{\forall} \textit{variable}. \textit{formula}: it is only by defining binding structures and by using variable identifiers in the right way in rule definitions that you can be sure to constrain the use of these structures.


Because there is no closing bracket, formulae constructed with \textsc{leftfix} bracketing are liable to have a visually ambiguous interpretation, so Jape demands that \textsc{leftfix}-brackets aren't used like ordinary brackets: that is, you can't write things like $f1@@*x.f2@f3$ : you have to write instead either $f1@\left( @*x.f2@f3\right) $ or $f1@\left( @*x.f2\right) @f3$ .


The binding structures are given by pattern:

BIND x SCOPE P IN ∃x. P\\
BIND x SCOPE P IN ∀x. P


Any formula which matches one of these patterns is recognised as a binding formula -- any variable in place of \textit{x}, any formula, including another binding formula, in place of \textit{P}. Near matches aren't allowed, so the constraint to write \ensuremath{\forall} \textit{variable}. \textit{formula} is enforced.


Note that this defines only single-variable bindings. Jape has no means at present of defining families of binding structures, except by exhaustively listing them -- for example, you might give \textsc{bind} directives which describe the structure of \ensuremath{\forall}\textit{x},y.\textit{E}, \ensuremath{\forall}\textit{x},\textit{y},\textit{z}.\textit{E} and so on as we do in later chapters. But then you would find that Jape has no means of defining families of inference rules which work across the different kinds of bindings you can define, and you would have to separately define the rules -- one for \ensuremath{\forall}\textit{x}.\textit{E}, another for \ensuremath{\forall}\textit{x},y.\textit{E}, another for \ensuremath{\forall}\textit{x},\textit{y},\textit{z}.\textit{E} and so on.


Our sequents have bags of formulae on either side:

SEQUENT IS BAG ⊦ BAG


\textbf{{\large 2.3\tab Encoding the inference rules}}


Jape is designed to make the encoding of inference rules as transparent and straightforward as possible. In principle all you have to do is to linearise the normal description of a rule, giving its name, its provisos, its antecedents and its consequent. Writing \{... \} for optional inclusion and \{... \}* for repeated optional inclusion, the syntax of a \textsc{rule} directive is

\textsc{rule}\tab \{ \textit{name} \}\tab -- \textit{rule name}\\
\tab \{ (\textit{parameter} \{, \textit{parameter} \}*) \}\tab -- \textit{parameters}\\
\tab \{ \textsc{where} \textit{proviso} \{\textsc{and} \textit{proviso}\}* \}\tab -- \textit{provisos}\\
\tab \{ \textsc{is} \}\\
\tab \{ \textsc{from} \textit{sequent} \{\textsc{and} \textit{sequent}\}* \}\tab -- \textit{antecedents}\\
\tab \textsc{infer} \textit{sequent}\tab -- \textit{consequent}


Nearly everything is optional, but you have to put in enough reserved words to make it clear where each section begins and ends. If you leave the name out, the name is taken to be the consequent itself. Where the name of a rule isn't an identifier -- if it is ⊦∧, for example -- it is necessary to enclose it in quotation marks. The \textit{parameters} are each an identifier or the word \textsc{object} followed by an identifier. Parameters in a rule definition control the process of instantiation and the treatment of argument formulae provided via text-selection and/or tactics.


Because we want to write our rules, and prove our conjectures, using predicate notation, we set a global parameter\footnote{The syntactic form we use is that of an assignment to a variable. This particular variable can only be altered when the store of rules and variables is empty, so in practice it behaves as a parameter..}

INITIALISE interpretpredicates true


With that setting, the rules can be defined directly:

RULE\tab axiom(A)\tab INFER Γ,A ⊦ A,Δ

RULE\tab "⊦∧"\tab FROM Γ ⊦ A,Δ AND Γ ⊦ B,Δ \tab INFER Γ ⊦ A∧B,Δ\\
RULE\tab "∧⊦"\tab FROM Γ,A, B ⊦ Δ \tab INFER Γ,A∧B ⊦ Δ\\
RULE\tab "⊦∧"\tab FROM Γ ⊦ A,B,Δ \tab INFER Γ ⊦ A∧B,Δ\\
RULE\tab "∧⊦"\tab FROM Γ,A ⊦ Δ AND Γ,B ⊦ Δ\tab INFER Γ,A∧B ⊦ Δ\\
RULE\tab "⊦¬"\tab FROM Γ,A ⊦ Δ\tab INFER Γ ⊦ ¬A,Δ\\
RULE\tab "¬⊦"\tab FROM Γ ⊦ A,Δ \tab INFER Γ,¬A ⊦ Δ\\
RULE\tab "⊦→"\tab FROM Γ,A ⊦ B,Δ \tab INFER Γ ⊦ A→B,Δ\\
RULE\tab "→⊦"\tab FROM Γ ⊦ A,Δ AND Γ,B ⊦ Δ\tab INFER Γ,A→B ⊦ Δ\\
RULE\tab "⊦	"\tab FROM Γ ⊦ A→B,Δ AND Γ ⊦ B→A,Δ\tab INFER Γ ⊦ A≡B,Δ\\
RULE\tab "≡⊦"\tab FROM Γ, A→B, B→A ⊦ Δ\tab INFER Γ,A≡B ⊦ Δ\\
RULE\tab "⊦∀"(OBJECT m) WHERE FRESH m\\
\tab \tab FROM Γ ⊦ A(m),Δ\tab INFER Γ ⊦ ∀x.A(x),Δ\\
RULE\tab "∀⊦"(B)\tab FROM Γ, A(B) ⊦ Δ\tab INFER Γ,∀x.A(x) ⊦ Δ\\
RULE\tab "⊦∃"(B)\tab FROM Γ ⊦ A(B),Δ\tab INFER Γ ⊦ ∃x.A(x),Δ\\
RULE\tab "∃⊦"(OBJECT m) WHERE FRESH m\\
\tab \tab FROM Γ,A(m) ⊦ Δ\tab INFER Γ, ∃x.A(x) ⊦ Δ

RULE\tab cut(A)\tab FROM Γ ⊦ A,Δ AND Γ,A ⊦ Δ\tab INFER Γ ⊦ Δ\\
RULE\tab "weaken⊦"(A)\tab FROM Γ ⊦ Δ\tab INFER Γ,A ⊦ Δ\\
RULE\tab "⊦weaken"(A)\tab FROM Γ ⊦ Δ\tab INFER Γ ⊦ A,Δ\\
RULE\tab "contract⊦"(A)\tab FROM Γ, A, A ⊦ Δ\tab INFER Γ, A ⊦ Δ\\
RULE\tab "⊦contract"(A)\tab FROM Γ ⊦ A,A,Δ\tab INFER Γ ⊦ A,Δ


The structural rules are declared to Jape with their proper r\^{o}les:

CUT\tab cut\\
LEFTWEAKEN\tab "weaken⊦"\\
RIGHTWEAKEN\tab "⊦weaken"


\textbf{{\large 2.4\tab Automatic application of rules}}


It is possible to require Jape to try to apply a tactic at the end of each proof step -- that is, after producing the effects demanded by the user. You can make it apply the tactic in one of two ways: the \textsc{automatch} directive requires that the tactic works without introducing or eliminating any unknowns from the proof tree, and without introducing or eliminating any provisos; the \textsc{autounify} directive doesn't have any of those constraints. With either directive, a rule within the tactic is not applied if there is more than one distinct possible result.


In the sequent calculus it is reasonable to apply \textit{axiom} whenever possible, but because it would always be applicable whenever a conclusion or a hypothesis was a single unknown, it's prudent to restrict ourselves to applications which succeed by identical match, and we therefore include

AUTOMATCH axiom


\textbf{{\large 2.5\tab Automatic selection of rules}}


When the user double-clicks on, or `hits', a formula, the logic designer can provide that a tactic is automatically applied. The choice of tactic is made by pattern-matching and depends on whether it is a hypothesis or a conclusion that is hit. If there isn't an applicable tactic, Jape puts up an error alert.


Description of a `hit' and what to do about it is given by one of the directives

\textsc{conchit\tab }\textit{pattern} \textsc{is} \textit{tactic}\\
\textsc{hyphit\tab }\textit{pattern} \textsc{is} \textit{tactic}


The pattern is matched -- by one-way matching, not unification -- to the formulae which have been selected and hit. It can be as follows:


{\textbullet}\tab \textit{hypothesis} \texttt{<}entails\texttt{>} \textit{conclusion}, in which case the user must select (click) one of the two and hit (double-click) the other;\\
{\textbullet}\tab \textit{hypothesis} \texttt{<}entails\texttt{>} -- only in \textsc{hyphit} -- in which case the user must hit a hypothesis without selecting a conclusion;\\
{\textbullet}\tab \textit{conclusion} or \texttt{<}entails\texttt{>} \textit{conclusion} -- only in \textsc{conchit} -- in which case the user must hit a conclusion without selecting a hypothesis.


In the sequent calculus we can automatically invoke a tactic when any formula is hit. First, we can invoke a right rule when any conclusion is hit, provided that the user hasn't confused the issue by selecting a hypothesis as well:

CONCHIT\tab B∧C\tab IS "⊦∧"\\
CONCHIT\tab B∧C\tab IS "⊦∧"\\
CONCHIT\tab B→C\tab IS "⊦→"\\
CONCHIT\tab ¬B\tab IS "⊦¬"\\
CONCHIT\tab ∀x.B\tab IS "⊦∀"\\
CONCHIT\tab ∃x.B\tab IS "⊦∃"


We can automatically invoke \textit{axiom} if the user hits a hypothesis having selected an identical conclusion:

HYPHIT\tab A ⊦ A\tab IS axiom


We can automatically invoke a left rule if the user hits a hypothesis without having selected a conclusion:

HYPHIT\tab A→B ⊦\tab IS "→⊦"\\
HYPHIT\tab A∧B ⊦\tab IS "∧⊦"\\
HYPHIT\tab A∧B ⊦ \tab IS "∧⊦"\\
HYPHIT\tab ¬A ⊦\tab IS "¬⊦"\\
HYPHIT\tab ∀x.A ⊦\tab IS "∀⊦"\\
HYPHIT\tab ∃x.A ⊦\tab IS "∃⊦"


\textbf{{\large 2.6\tab Menus}}


Jape automatically provides some system menus, whose content varies between graphical interfaces and is therefore not described here. All other menus and panels are produced under the control of the encoder.


\textit{The Rules menu}


To describe a menu you give its title and its contents. Each entry in the menu has a label -- which the user sees -- and a Jape tactic -- which is transmitted to the Jape engine when the entry is selected. A rule name is the simplest form of Jape tactic, and in this logic that is all that we need:

MENU Rules IS\\
\tab ENTRY axiom\\
\tab SEPARATOR

\tab ENTRY "∧⊦"\\
\tab ENTRY "∧⊦"\\
\tab ENTRY "→⊦"\\
\tab ENTRY "¬⊦"\\
\tab ENTRY "∀⊦"\\
\tab ENTRY "∃⊦"

\tab SEPARATOR

\tab ENTRY "⊦∧"\\
\tab ENTRY "⊦∧"\\
\tab ENTRY "⊦→"\\
\tab ENTRY "⊦¬"\\
\tab ENTRY "⊦∀"\\
\tab ENTRY "⊦∃"

\tab SEPARATOR

\tab ENTRY cut\\
\tab ENTRY ``weaken⊦''\\
\tab ENTRY ``⊦weaken''\\
\tab ENTRY ``contract⊦''\\
\tab ENTRY ``⊦contract''

END


This produces a menu in which every label is the name of a rule, 
and every command a tactic of the same name. Jape allows us to 
save effort by defining the rules within the menu description. 
If we had written

MENU Rules IS\\
\tab RULE axiom\tab INFER A ⊦ A\\
\tab SEPARATOR\\
\tab RULE "⊦∧"\tab FROM ⊦ A AND ⊦ B\tab INFER ⊦ A∧B\\
\tab ...

END


then it would have produced exactly the same menu.


\textbf{{\large 2.7\tab Conjectures}}


The primary object of using Jape is to prove theorems. You can 
state conjectures in text commands composed from the keyboard 
(after pressing the New\dots  button on a conjectures panel), but 
it is more normal to state them in a logic encoding file.


A conjecture can be stated in a \textsc{theorem} directive which gives 
its name, its parameter identifiers and provisos if any, and 
the sequent which is the theorem itself. The effect is to put 
a conjecture with that name into the `tactic store', from which 
it can be retrieved in order to prove it, to apply it during 
a proof, or to review its proof.


In the distributed version of the multiple-conclusion sequent 
calculus, two conjectures are stated in this way:

THEOREM\tab modusponens\tab IS A, A→B ⊦ B\\
THEOREM\tab contradiction\tab IS A, ¬A ⊦


Note that because this logic includes both a left and a right 
weakening rule, the contradiction theorem can be applied, once 
proved, to any sequent which has a formula and its negation in 
its hypotheses. It could even be applied automatically via \textsc{automatch}, 
though we haven't done that in this encoding.


Interpretation of parameter identifiers and provisos in a \textsc{theorem} 
directive is the same as for inference rules.\\
The \textsc{theorems} directive allows you to state a collection of 
conjectures, each of which will be named by its sequent, in a 
very economical way. Part of the \textsc{theorems} directive in MCS+SCS\_problems.j 
is:

THEOREMS PropositionalProblems ARE\\
\tab P→(Q→R)\tab ⊦ (P→Q)→(P→R)\\
AND\tab P→(Q→R), Q \tab ⊦ P→R\\
AND\tab R→S\tab ⊦ (P→R) → (P→S)\\
AND\tab P→(P→Q)\tab ⊦ P→Q

\tab ...

\tab AND\tab ∀x.¬Q(x), P→(∀x.Q(x))\tab ⊦ ¬P\\
AND WHERE x NOTIN P INFER \\
\tab P∧¬P, ∀x.P→Q(x), ∀x. ¬P→Q(x) \tab ⊦ ∀x.Q(x)\\
AND\tab R∧¬R, ∀x.R→S(x), ∀x. ¬R→S(x)\tab ⊦ 
∀x.S(x)\\
AND\tab ∀x.P(x)→Q(x), ∀x.Q(x)→R(x) \tab ⊦ ∀x.P(x)→R(x)\\
AND\tab ∀x.P(x)→R(x), ∀x.Q(x)→ ¬R(x) \tab ⊦ ∀x.(P(x)→¬Q(x)) 
∧ (Q(x)→¬P(x))\\
AND\tab S(m,n), ∀x.P(x) → ¬S(x,n) \tab ⊦ ¬P(m)

\tab ...


The first section adds a number of propositional theorems to the tactic store, each under the name of its sequent. The second section adds theorems which include quantified formulae, some of which need individual provisos (we included two versions of some theorems, just to show how the necessary provisos are generated during the proof if you don't add them beforehand).


\textbf{{\large 2.8\tab The Conjectures panel}}


Panels in Jape have lists of entries and buttons. A \textsc{conjecturepanel} automatically includes buttons labelled New\dots, Prove and Show Proof, and has a default Apply button if the user defines no buttons at all. In the case of the sequent calculus we can use a straightforward \textsc{conjecturepanel} with a default Apply button to hold all the problems which we want to display to the user. The distributed version goes as follows. In MCS.jt we have:

CONJECTUREPANEL "Conjectures" \\
THEOREM\tab modusponens\tab IS A, A→B ⊦ B \\
THEOREM\tab contradiction\tab IS A, ¬A ⊦ B\\
END


and in sequent\_problems.j we have

CONJECTUREPANEL "Conjectures" \\
THEOREMS PropositionalProblems ARE \\
P→(Q→R)\tab ⊦ (P→Q)→(P→R) \\
AND P→(Q→R), Q \tab ⊦ P→R \\
AND R→S\tab ⊦ (P→R) → (P→S)

...

 AND ∃y.P \tab ⊦ ∀y.P \\
END\\
END


Note that additions to a panel or a menu can be made in several lumps: that is, panels and menus can be built up in by disjoint declarations.


\textbf{{\large 2.9\tab Global variable settings}}


Jape has a number of variables which control parts of its operation -- for a complete list see appendix C. In our encoding of the sequent calculus we have decided not to allow conjectures to be applied as theorems, not to allow theorems to be applied `resolution' style, generating antecedents if all their hypotheses don't match, and to display our proofs as Gentzen trees. The initialisations are:

INITIALISE applyconjectures false\\
INITIALISE tryresolution false\\
INITIALISE displaystyle tree


\textbf{{\large 2.10\tab A very small example}}


Here is the progress of a proof of Pierce's law in this encoding. As intuitionists, we offer no explanation of the pheonemon. Those who believe, believe.\\


\begin{tabular}{|p{2.347in}|}
\hline
% ROW 1
{\raggedright }\\
\hline
% ROW 2
{\raggedright }\\
\hline
% ROW 3
{\raggedright }\\
\hline
% ROW 4
{\raggedright }\\
\hline
\end{tabular}



\chapter{Variations on the Sequent Calculus}


The sequent calculus of chapter 2 is only one of very many possible variants. In this chapter we discuss the way in which we can encode an LF-style treatment of variables in the quantifier introduction and elimination rules, how Jape deals with non-additive rules, and two versions of the intuitionistic sequent calculus -- multiple and single conclusion.


\textbf{{\large 3.1\tab LF-style variables in quantifier rules}}


Jape allows redefinition of any rule, theorem or conjecture\footnote{And it allows it \textit{at any time}!! It ought to check, whenever a rule or theorem is redefined, every proof that relies upon it. It doesn't at the time of writing, but it will do so Real Soon Now.}. The file MSC\_LF.j redefines the quantifier rules to allow a more careful treatment of variables\footnote{Explanation for non-expert logicians: the effect is to make it much more careful about the treatment of possibly-empty domains of quantification. It is impossible, for example, to prove {\small ∀x.P(x) ⊦ ∃x.P(x)}, because the proof would require that there be some \textit{m} such that \textit{P}(\textit{m}).}. The new rules are\\


\begin{tabular}{|p{2.216in}|p{2.198in}|p{0.043in}|p{0.043in}|}
\hline
% ROW 1
{\raggedright 
$\frac{\Gamma,\operatorname{var} \;m |- A\left( m\right),\Delta }{\Gamma |- @*x.A\left( x\right),\Delta } \;(m)\; |- @*$
} & 
{\raggedright 
$\frac{\Gamma  |- A\left( B\right),\Delta \quad \Gamma |- B\;\operatorname{inscope}}{\Gamma  |-|*x.A\left( x\right) ,\Delta } \; |-|*$
}\\
\hline
% ROW 2
{\raggedright 
$\frac{\Gamma,A\left( B\right)  |- \Delta \quad \Gamma |- B\;\operatorname{inscope}}{\Gamma,@*x.A\left( x\right) |- \Delta } \;@*|- $

$\infer[\reason{$@*L$}]
       {\Gamma,@*x.A |- C}
       {\Gamma,A[x\backslash E] |- C}$

$\frac{\Gamma,\operatorname{var} \;m,A\left( m\right)  |- \Delta }{\Gamma ,|*x.A\left( x\right)  |- \Delta } \;(m)\;|*|- $
}\\
\hline
\end{tabular}


The intention is that a variable \textit{c} is `inscope' if there is an assumption var \textit{c}; a formula is inscope if its free components are inscope. Note that there is nothing in Jape which demands that we use these words nor this technique: it's up to the logic decoder.


The file sequent\_scoping.j defines two low priority prefix operators:

PREFIX\tab 10\tab var\\
POSTFIX\tab 10\tab inscope


and a structural induction to handle formulae\footnote{This induction is unnecessary: in the sequent calculus we never need anything more complicated than a variable. But we wanted to see if we could do something more general, and we have left it in.}, automatically applied whenever there is an open tip:

RULES "inscope" ARE\\
\tab Γ, var x ⊦ x inscope\\
AND\tab FROM Γ ⊦ A inscope AND Γ ⊦ B inscope INFER Γ ⊦ 
A→B inscope\\
AND\tab FROM Γ ⊦ A inscope AND Γ ⊦ B inscope INFER Γ ⊦ 
A∧B inscope\\
AND\tab FROM Γ ⊦ A inscope AND Γ ⊦ B inscope INFER Γ ⊦ 
A∧B inscope\\
AND\tab FROM Γ ⊦ A inscope INFER Γ ⊦ ¬A inscope\\
AND\tab FROM Γ, var x ⊦ A inscope INFER Γ ⊦ ∀x.A inscope\\
AND\tab FROM Γ, var x ⊦ A inscope INFER Γ ⊦ ∃x.A 
inscope \\
END

AUTOMATCH "inscope"


Encoding of the rules is then straightforward:

RULE\tab "⊦∀"(OBJECT m) WHERE FRESH m\\
\tab \tab FROM Γ, var m ⊦ A(m),Δ\tab INFER Γ ⊦ ∀x.A(x),Δ\\
RULE\tab "∀⊦"(B)\tab FROM Γ, A(B) ⊦ Δ AND 
Γ ⊦ B inscope\tab INFER Γ,∀x.A(x) ⊦ Δ\\
RULE\tab "⊦∃"(B)\tab FROM Γ ⊦ A(B),Δ 
AND Γ ⊦ B inscope\tab INFER Γ ⊦ ∃x.A(x),Δ\\
RULE\tab "∃⊦"(OBJECT m) WHERE FRESH m\\
\tab \tab FROM Γ, var m, A(m) ⊦ Δ\tab INFER Γ, ∃x.A(x) 
⊦ Δ


We would like inscope judgements to behave like side conditions, displayed when they are a problem and hidden when they are satisfied. But they aren't provisos, because they relate a particular context and a particular formula\footnote{I guess they could be provisos one day.}.


In order to make these judgements side condidtions we use Jape's \textsc{layout} tactical: it allows us to run a tactic and to decide which subtrees of the resulting proof tree should be displayed and what should be written as the justification of the step. (Subtrees which contain open problem sequents are always displayed, so that nothing which might accidentally be important is hidden.) In the case of the ⊦∀ and ∃⊦ rules we would like to display the first antecedent proof (numbered 0) and hide the second (numbered 1); in either case we want to give the name of the rule as the justification of the step. The tactics are

TACTIC "∀⊦ with side condition hidden" IS LAYOUT 
"∀⊦" (0) (WITHSELECTIONS "∀⊦")\\
TACTIC "⊦∃ with side condition hidden" 
IS LAYOUT "⊦∃" (0) (WITHSELECTIONS "⊦∃")


which we put into the menu

MENU Rules IS\\
\tab ENTRY "∀⊦" IS "∀⊦ with side condition 
hidden"\\
\tab ENTRY "⊦∃" IS "⊦∃ with 
side condition hidden"\\
END


and into the list of double-click actions

HYPHIT\tab ∀x.A ⊦\tab IS "∀⊦ with side condition hidden"\\
CONCHIT\tab ⊦ ∃x.B\tab IS "⊦∃ with side condition 
hidden"


We get all this machinery simply by loading MCS.jt, to get the multiple-conclusion sequent calculus, and then adding MCS\_LF.j, to get the extra rules and syntax.


Under this encoding, we can show the progress of a proof in which the variable rules are obeyed:\\


\begin{tabular}{|p{3.292in}|}
\hline
% ROW 1
{\raggedright }\\
\hline
% ROW 2
{\raggedright }\\
\hline
% ROW 3
{\raggedright }\\
\hline
\end{tabular}


Note that one antecedent of the final step isn't shown. We can see the full display by double-clicking on the justification of that step:

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=5.222in, height=1.375in]{oldpics/Roll_your_own_v3_2+Fig8}
\caption{Fig8}
\end{center}
\end{figure}


Clearly it is an advantage to hide the side-proof whenever possible; it makes sense to hide it when it is closed, as in this case. The rest of the proof is straightforward.


Next, the progress of an attempt to prove ∀x.P(x){\nobreakspace}⊦{\nobreakspace}∃x.P(x), which isn't a theorem in this logic (though it is one in the logic of chapter 2):\\


\begin{tabular}{|p{4.500in}|}
\hline
% ROW 1
{\raggedright }\\
\hline
% ROW 2
{\raggedright }\\
\hline
% ROW 3
{\raggedright }\\
\hline
% ROW 4
{\raggedright }\\
\hline
\end{tabular}


It doesn't matter what we unify with \_\textit{B}: the side conditions won't go away, and we don't have a theorem.


\textit{Caveat}


A deficiency of Jape at present is that it has only one class of formula, but the contexts which will be built up in this encoding include logical formulae and extra-logical remarks like var \textit{c}. That would permit you, if you were actively incautious, to try to prove nonsense like var \textit{m} \ensuremath{@} var \textit{n}. We'll fix the problem as soon as possible, but don't hold your breath...


\textbf{{\large 3.2\tab The intuitionistic multiple-conclusion sequent calculus}}


The rules of the intuitionistic multiple-conclusion sequent calculus aren't simply additive, but they use little more than specialised weakening. The calculus is just that of chapter 2, with different definitions of a few rules:\\


\begin{tabular}{|p{2.207in}|p{2.207in}|p{0.043in}|p{0.043in}|}
\hline
% ROW 1
{\raggedright 
$\infer[\reason{$ |- !$}]
       {\Gamma  |- !A,\Delta }
       {\Gamma,A |- }$
} & 
{\raggedright 
$\infer[\reason{$ |- ->
$}]
       {\Gamma  |- A->B,\Delta }
       {\Gamma,A |- B}$
}\\
\hline
% ROW 2
{\raggedright 
$\infer[\reason{$!|- $}]
       {\Gamma,!A |- \Delta }
       {\Gamma  |- A}$
} & 
{\raggedright 
$\infer[\reason{$->|- $}]
       {\Gamma,A-> B |- \Delta }
       {\Gamma  |- A\quad \Gamma,B |- \Delta }$
}\\
\hline
\end{tabular}


These are defined directly in the file IMCS.j, which you can load after MCS.jt (and before or after MCS\_LF.j, if you wish):

RULE\tab "⊦¬"\tab FROM Γ,A ⊦ \tab INFER Γ ⊦ 
¬A,Δ\\
RULE\tab "¬⊦"\tab FROM Γ ⊦ A\tab INFER Γ,¬A 
⊦ Δ\\
RULE\tab "⊦→"\tab FROM Γ,A ⊦ B\tab INFER Γ ⊦ A→B,Δ\\
RULE\tab "→⊦"\tab FROM Γ ⊦ A AND Γ,B ⊦ Δ\tab INFER 
Γ,A→B ⊦ Δ


These definitions make it impossible to prove Pierce's law, for which intuitionists may thank goodness:\\


\begin{tabular}{|p{1.778in}|}
\hline
% ROW 1
{\raggedright }\\
\hline
% ROW 2
{\raggedright }\\
\hline
% ROW 3
{\raggedright }\\
\hline
\end{tabular}


\textbf{{\large 3.3\tab A multiple-conclusion sequent calculus with multiplicative rules}}


The logic is just the normal multiple-conclusion calculus, with all of the branching rules written in multiplicative style; we have chosen at the same time to use an axiom rule which doesn't ignore unmatched conclusions:\\


\begin{tabular}{|p{1.457in}|p{1.457in}|p{1.457in}|p{0.043in}|p{0.043in}|p{0.043in}|}
\hline
% ROW 1
{\raggedright 
$\infer[\reason{$axiom$}]
       {A |- A}
       {}$
} & 
{\raggedright } & 
{\raggedright }\\
\hline
% ROW 2
{\raggedright 
$\infer[\reason{$ |- @$}]
       {\Gamma,\Gamma ' |- A@B,\Delta,\Delta ' }
       {\Gamma  |- A,\Delta \quad \Gamma '  |- B,\Delta ' }$
} & 
{\raggedright 
$\infer[\reason{$| |- $}]
       {\Gamma,\Gamma ' ,A|B |- \Delta,\Delta ' }
       {\Gamma,A |- \Delta \quad \Gamma ',B |- \Delta ' }$
} & 
{\raggedright 
$\infer[\reason{$->|- $}]
       {\Gamma,\Gamma ' ,A->B |- \Delta,\Delta ' }
       {\Gamma  |- A,\Delta \quad \Gamma ',B |- \Delta ' }$
}\\
\hline
% ROW 3
{\raggedright 
$\infer[\reason{$cut$}]
       {\Gamma,\Gamma ' |- \Delta,\Delta ' }
       {\Gamma  |- B,\Delta \quad \Gamma ',B |- \Delta ' }$
} & 
{\raggedright } & 
{\raggedright }\\
\hline
\end{tabular}


These rules are defined in MMCS.j, ready to be loaded after MCS.jt:

RULE\tab axiom(A)\tab INFER A ⊦ A\\
RULE\tab "⊦∧"\tab FROM Γ ⊦ A,Δ AND Γ' 
⊦ B,Δ' \tab INFER Γ,Γ' ⊦ A∧B,Δ,Δ'\\
RULE\tab "∧⊦"\tab FROM Γ,A ⊦ Δ AND Γ',B 
⊦ Δ'\tab INFER Γ,Γ',A∧B ⊦ Δ,Δ'\\
RULE\tab "→⊦"\tab FROM Γ ⊦ A,Δ AND Γ',B 
⊦ Δ'\tab INFER Γ,Γ',A→B ⊦ Δ,Δ'

RULE\tab cut(A)\tab FROM Γ ⊦ A,Δ AND Γ',A ⊦ Δ'\tab INFER 
Γ,Γ' ⊦ Δ,Δ'


Since we have redefined cut, we have to redeclare its r\^{o}le to Jape:

CUT\tab cut


When we use a multiplicative rule, the left and right contexts split. Jape automatically records this fact in a \textsc{unifieswith} proviso:\\


\begin{tabular}{|p{3.278in}|}
\hline
% ROW 1
{\raggedright }\\
\hline
% ROW 2
{\raggedright }\\
\hline
% ROW 3
{\raggedright  }\\
\hline
\end{tabular}


In this simple example we have to decide whether to send \textit{P} and \textit{Q} into Γ1 or Γ2, \textit{R} into Δ1 or Δ2. The axiom rule of this encoding was designed to help: we can select \textit{P} in the left antecedent and apply axiom:

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=1.625in, height=1.375in]{oldpics/Roll_your_own_v3_2+Fig19}
\caption{Fig19}
\end{center}
\end{figure}


All the problems are resolved, for the moment, and the rest of the proof can be completed in the same way.


\textit{Resolving context-splits with drag-and-drop}


Consider the following example:

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=2.333in, height=2.000in]{oldpics/Roll_your_own_v3_2+Fig20}
\caption{Fig20}
\end{center}
\end{figure}


To make progress, we need to send one of the conclusions \textit{P}\ensuremath{@}\textit{Q}, \textit{P}\ensuremath{@}\textit{R} into \_Δ1 and the other into \_Δ2. Jape has a drag-and-drop gesture, designed for this purpose. Dragging \textit{P}\ensuremath{@}\textit{Q} in the MacOS implementation produces this kind of visual feedback, highlighting the dragged formula, the mouse position and potential destinations:

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=3.458in, height=3.222in]{oldpics/Roll_your_own_v3_2+Fig21}
\caption{Fig21}
\end{center}
\end{figure}


If the mouse is released at the point illustrated, the proof is redrawn and the provisos simplified to match:

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=2.764in, height=2.000in]{oldpics/Roll_your_own_v3_2+Fig22}
\caption{Fig22}
\end{center}
\end{figure}


A similar technique can be used with rules that involve explicit weakening.


\textbf{{\large 3.4\tab Modal logic}}


It is our intention to enhance Jape so that it can use modal operators, and to further develop this encoding to cover all of linear logic. Most of the code is written and included in Jape, but is lying dormant, so it should be quite soon.


\textbf{{\large 3.5\tab Single-conclusion sequent calculus (the intuitionistic fragment)}}


The rules of this logic are very similar to those of chapter 2. In our encoding the right-hand side of a sequent contains exactly one formula -- Jape can't yet handle sequents with at most one formula on the right-hand side -- and we give rules for negation -- Jape can't yet handle definitional equality. The encoding is in the file SCS.jt.


\textit{Inference rules}


Apart from the treatment of negation, these are a pretty ordinary selection. As with the multiple-conclusion calculus, we have chosen to use a hypothesis rule which ignores additional hypotheses, we have avoided context-splitting rules, and we have made the left-hand side of a sequent a bag of formulae.


Negation is normally described by defining it to be equivalent to implication of absurdity: $!x$ is just a way of writing $x->\bot $ . Jape can't handle definitional equality of formulae yet, and therefore we give rules which implement that equality. With that exception, the rules are more or less the rules of the sequent calculus with the symbol Δ deleted.


\textit{hypothesis\\
}

\begin{tabular}{|p{1.028in}|p{0.069in}|}
\hline
% ROW 1
{\raggedright 
$\infer[\reason{$hyp$}]
       {\Gamma,A |- A}
       {}$
}\\
\hline
\end{tabular}


\textit{Introduction to the right of the turnstile (⊦... rules)\\
}

\begin{tabular}{llllllllll}
\hline
% ROW 1
\multicolumn{1}{|p{0.857in}|}
{\raggedright

$\infer[\reason{$
\; |- @$}]
       {\Gamma  |-  |- A@B}
       {\Gamma  |- A\quad \Gamma  |- B}$
} & 
\multicolumn{1}{p{0.857in}|}
{\raggedright

$\infer[\reason{$ |- ->$}]
       {\Gamma  |- A->B}
       {\Gamma,A |- B}$
} & 
\multicolumn{1}{p{0.857in}|}
{\raggedright

$\infer[\reason{$ |- |_{L} $}]
       {\Gamma  |- A|B}
       {\Gamma  |- A}$
} & 
\multicolumn{1}{p{0.857in}|}
{\raggedright

$\infer[\reason{$ |- |_{R} $}]
       {\Gamma  |- A|B}
       {\Gamma  |- B}$
} & 
\multicolumn{1}{p{0.857in}|}
{\raggedright

$\infer[\reason{$ |- !$}]
       {\Gamma  |- !A}
       {\Gamma  |- A->|- }$
}\\
\hline
% ROW 2
\multicolumn{1}{p{0.043in}|}
{\raggedright

$\infer[\reason{$(m)\; |- @*$}]
       {\Gamma  |- @*x.P\left( x\right) }
       {\Gamma  |- P\left( m\right) }$
} & 
\multicolumn{1}{p{0.043in}|}
{\raggedright

$\infer[\reason{$ |-|*$}]
       {\Gamma  |-|*x.P\left( x\right) }
       {\Gamma  |- P\left( B\right) }$
} & 
\multicolumn{1}{p{0.043in}|}
{\raggedright
}\\
\hline
\end{tabular}


\textit{Introduction to the left of the turnstile (...⊦ rules)\\
}

\begin{tabular}{|p{0.799in}|p{1.280in}|p{1.271in}|p{0.979in}|p{0.043in}|p{0.043in}|p{0.043in}|p{0.043in}|}
\hline
% ROW 1
{\raggedright 
$\infer[\reason{$@|- $}]
       {\Gamma,A@B |- C}
       {\Gamma,A,B |- C}$
} & 
{\raggedright 
$\infer[\reason{$
\;->|- $}]
       {\Gamma,A->B |- C}
       {\Gamma  |- A\quad \Gamma,B |- C}$
} & 
{\raggedright 
$\infer[\reason{$|
 |- $}]
       {\Gamma,A|B |- C}
       {\Gamma,A |- C\quad \Gamma,B |- C}$
} & 
{\raggedright 
$\infer[\reason{$!|- $}]
       {\Gamma,!A |- B}
       {\Gamma,A->|- \,B}$
}\\
\hline
% ROW 2
{\raggedright 
$\infer[\reason{$ |- $}]
       {\Gamma, |- \,A}
       {}$
} & 
{\raggedright 
$\infer[\reason{$@*|- $}]
       {\Gamma,@*x.P\left( x\right) |- C}
       {\Gamma,P\left( B\right)  |- C}$
} & 
{\raggedright 
$\infer[\reason{$(m)\;|*|- $}]
       {\Gamma,|*x.P\left( x\right) |- C}
       {\Gamma,P\left( m\right)  |- C}$

$\infer[\reason{$@*L$}]
       {\Gamma,@*x.A |- C}
       {\Gamma,A[x\backslash E] |- C}$
}\\
\hline
\end{tabular}


\textit{structural rules\\
}

\begin{tabular}{|p{1.435in}|p{1.435in}|p{1.435in}|p{0.065in}|p{0.065in}|p{0.065in}|}
\hline
% ROW 1
{\raggedright 
$\infer[\reason{$cut$}]
       {\Gamma  |- C}
       {\Gamma  |- B\quad \Gamma,B |- C}$
} & 
{\raggedright 
$\infer[\reason{$weaken$}]
       {\Gamma,A |- C}
       {\Gamma  |- C}$
} & 
{\raggedright 
$\infer[\reason{$contract$}]
       {\Gamma,A |- C}
       {\Gamma,A,A |- C}$
}\\
\hline
\end{tabular}


\textit{LF-style variables}


We haven't encoded a multiplicative single-conclusion calculus, but there is an encoding of an LF-style treatment of variables in the file SCS\_LF.j. It's identical to the treatment of variables in the multiple-conclusion calculus, with the Δ symbol deleted.


\textit{Syntax}


Formula syntax, and use of names, is exactly as in the multiple-conclusion sequent calculus.


Jape can't at present be configured to handle sequents with an optional formula on the right-hand side, but can easily be configured to handle those with exactly one. We therefore state

SEQUENT IS BAG ⊦ FORMULA


\textit{Menus and panels}


The Rules menu is almost the same as that in the multiple-conclusion sequent calculus. The Conjectures panel is identical: the two encodings share the file sequent\_problems.j.


\textit{Global variable settings}


Just as in the case of the multiple-conclusion sequent calculus, we don't want to allow the application of conjectures as if they were proved theorems and we don't want to allow the application of theorems if their hypotheses don't match\footnote{These are pragmatic choices, driven by our expected audience of novices learning about logic. There is, of course, nothing about the logic which forces either choice.}. We therefore include

INITIALISE applyconjectures false\\
INITIALISE tryresolution false


We do, however, want to allow the user to switch display modes. In place of an \textsc{initialise} directive for the \textit{displaystyle} variable, we include menu entries which control it, by inserting a radio button into the Edit menu -- one of the system menus of the Jape graphical interface. A radio button in a graphical interface is a control which has a number of mutually-exclusive settings. In a menu this appears is a number of entries, one of which is ticked.

MENU "Edit"\\
\tab RADIOBUTTON displaystyle IS\\
\tab \tab "Box display" \tab IS box\\
\tab AND\tab "Tree display" \tab IS tree\\
\tab INITIALLY tree\\
\tab END\\
END


\textbf{{\large 3.6\tab Box display mode and the \textit{hyp} rule}}


Unlike the multiple-conclusion sequent calculus, the single-conclusion calculus can reasonably be used in the `box display' mode, simply as a screen-space saving device. Proofs such as

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=6.958in, height=2.792in]{oldpics/Roll_your_own_v3_2+Fig23}
\caption{Fig23}
\end{center}
\end{figure}


are over-large because the hypotheses are written out many times, once in each sequent which they occur.


Box display of the same proof is much more economical of screen space:

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=3.847in, height=4.042in]{oldpics/Roll_your_own_v3_2+Fig24}
\caption{Fig24}
\end{center}
\end{figure}


and the gain is of course more dramatic in the case of larger proofs.


Part of the gain is produced by hiding applications of \textit{hyp}. A reference to a line proved by \textit{hyp} can be replaced by a reference to the hypothesis used in the \textit{hyp} step -- this happens, for example, on lines 4, 5, 9 and 10 of the box display above. All that is necessary is to declare the \textit{hyp} rule and its structural r\^{o}le to Jape, which we do as follows:

RULE hyp(A) INFER A ⊦ A

STRUCTURERULE IDENTITY\tab hyp



\chapter{Encoding natural deduction}


The sequent calculus encodings above are each straightforward encodings of a logic, with a few directives to arrange the elements of the user interface. Natural deduction challenges us to allow forward reasoning. The challenger isn't finished yet: we can only imitate some kinds of forward step, and some features of the background tree are still traceable in the box display.


This encoding has been used in a first-year course at QMW for three years, with increasing user satisfaction as our encoding has more nearly approached the treatment used by the course lecturer. That lecturer chose the rules we encoded and, in particular, he chose to use a particular classical treatment of negation, not at all the one which we would have chosen for ourselves nor even the particular classical encoding which we would have preferred.


\textbf{{\large 4.1\tab Inference rules}}


The rules of natural deduction are not normally stated in terms of sequents, but in a notation which is silent about the hypotheses. In fact the rules were presented to us in Fitch box form and we immediately, almost without thought, transcribed them into a sequent presentation. The rules that we were asked to encode were as follows (plus reiteration, which we don't list).\\


\begin{tabular}{llllllllllllllll}
\hline
% ROW 1
\multicolumn{2}{|p{1.220in}|}
{\raggedright

$
\begin{array}{lll}
i: & A & ... \\
& ... &  \\
j: & A->B & ... \\
& ... &  \\
k: & B & ->-E\ i,j
\end{array}
$
} & 
\multicolumn{2}{p{1.009in}|}
{\raggedright

$
\begin{array}{lll}
i: & A@B & ... \\
& ... &  \\
j: & A & @-E(L)\ i
\end{array}
$
} & 
\multicolumn{2}{p{1.228in}|}
{\raggedright

$
\begin{array}{lll}
i: & A@B & ... \\
& ... &  \\
j: & B & @-E(R)\ i
\end{array}
$
} & 
\multicolumn{3}{p{0.875in}|}
{\raggedright

$
\begin{array}{lll}
i: & !!A & ... \\
& ... &  \\
j: & A & !-E\ i
\end{array}
$
}\\
\hline
% ROW 2
\multicolumn{2}{p{0.042in}|}
{\raggedright

$
\begin{array}{lll}
i: & A|B & ... \\
& ... &  \\
\begin{array}{l}
j: \\
\\
k:
\end{array}
& 
\begin{array}{|l|}
\hline
A \\
... \\
C \\
\hline
\end{array}
& 
\begin{array}{l}
\operatorname{assumption} \\
\\
...
\end{array}
\\
& ... &  \\
\begin{array}{l}
l: \\
\\
m:
\end{array}
& 
\begin{array}{|l|}
\hline
B \\
... \\
C \\
\hline
\end{array}
& 
\begin{array}{l}
\operatorname{assumption} \\
\\
...
\end{array}
\\
& ... &  \\
n: & C & |-E\ i,j..k,l..m
\end{array}
$
} & 
\multicolumn{2}{p{0.042in}|}
{\raggedright

$
\begin{array}{lll}
i: & @*x.P(x) & ... \\
& ... &  \\
j: & P(c) & @*-E\ i
\end{array}
$
} & 
\multicolumn{2}{p{0.042in}|}
{\raggedright

$
\begin{array}{lll}
i: &|*x.P(x) & ... \\
& ... &  \\
\begin{array}{l}
j: \\
\\
k:
\end{array}
& c
\begin{array}{|c|}
\hline
P(c) \\
... \\
A \\
\hline
\end{array}
& 
\begin{array}{l}
\operatorname{assumption} \\
\\
...
\end{array}
\\
& ... &  \\
l: & A &|*-E\ i,j..k
\end{array}
$
} & 
\multicolumn{1}{p{0.042in}|}
{\raggedright
}\\
\hline
% ROW 3
\multicolumn{2}{|p{1.220in}|}
{\raggedright

$
\begin{array}{lll}
\begin{array}{|l|}
\hline
\\
\hline
\end{array}
&  & ... \\
& k: & A->B \\
->-I\ i..j & 
\end{array}
$
} & 
\multicolumn{2}{p{1.009in}|}
{\raggedright

$
\begin{array}{lll}
i: & A & ... \\
& ... &  \\
j: & B & ... \\
& ... &  \\
k: & A@B & @-I\ i,j
\end{array}
$
} & 
\multicolumn{2}{p{1.228in}|}
{\raggedright

$
\begin{array}{lll}
\begin{array}{l}
i: \\
\\
j:
\end{array}
& 
\begin{array}{|l|}
\hline
A \\
... \\
B@!B \\
\hline
\end{array}
& 
\begin{array}{l}
\operatorname{assumption} \\
\\
...
\end{array}
\\
& ... &  \\
k: & !A & !-I\ i..j
\end{array}
$
} & 
\multicolumn{3}{p{0.875in}|}
{\raggedright
}\\
\hline
% ROW 4
\multicolumn{2}{p{0.042in}|}
{\raggedright

$
\begin{array}{lll}
i: & A & ... \\
& ... &  \\
j: & A|B & |-I(L)\ i
\end{array}
$
} & 
\multicolumn{2}{p{0.042in}|}
{\raggedright

$
\begin{array}{lll}
i: & B & ... \\
& ... &  \\
j: & A|B & |-I(R)\ i
\end{array}
$
} & 
\multicolumn{2}{p{0.042in}|}
{\raggedright

$
\begin{array}{lll}
c
\begin{array}{|l|}
\hline
\\
\hline
\end{array}
&  & ... \\
& j: & @*x.P(x) \\
->-@*-I\ i & 
\end{array}
$
} & 
\multicolumn{1}{p{0.042in}|}
{\raggedright

$
\begin{array}{lll}
i: & P(c) & ... \\
& ... &  \\
j: &|*x.P(x) &|*-I\ i
\end{array}
$
}\\
\hline
\end{tabular}


Themarginal \textit{c} in the ∃-\textit{E} and ∀-\textit{I} rules indicates a proviso that the name \textit{c} should not appear free outside the `scope box' which it labels; there's a corresponding condition on ∃-\textit{I} and ∀-\textit{E} that variable \textit{c} should be `well scoped' -- that is, lines \textit{i} to \textit{j} have to be inside a scope box for variable \textit{c}.


These rules have well-known tree equivalents, where reiteration is replaced by a hypothesis rule, the provisos are made explicit and the ∃-\textit{I} and ∀-\textit{E} rules have an explicit side-condition.



$\infer[\reason{$hyp$}]
       {A}
       {}$

\begin{tabular}{lllllllllllll}
\hline
% ROW 1
\multicolumn{1}{|p{0.861in}|}
{\raggedright

$\infer[\reason{$->-E$}]
       {B}
       {\begin{array}{l} \thinspace \thinspace \vdots \quad \quad \ \vdots  \ A\quad A->B \end{array}}$
} & 
\multicolumn{1}{p{0.749in}|}
{\raggedright

$\infer[\reason{$@-E(L)$}]
       {A}
       {\begin{array}{l} \thinspace \thinspace \ \ \thinspace \vdots  \ A@B \end{array}}$
} & 
\multicolumn{1}{p{0.848in}|}
{\raggedright

$\infer[\reason{$@-E(R)$}]
       {B}
       {\begin{array}{l} \thinspace \thinspace \ \ \thinspace \vdots  \ A@B \end{array}}$
} & 
\multicolumn{1}{p{0.968in}|}
{\raggedright

$\infer[\reason{$|E$}]
       {C}
       {\begin{array}{l} \ \ \ \ \ \ \ \ \ \ \thinspace [A]\ \ [B] \ \thinspace \thinspace \thinspace \thinspace \thinspace \ \vdots \ \thinspace \thinspace \thinspace \thinspace \ \ \ \ \ \vdots \ \ \ \ \ \vdots \ A|B\quad C\quad C \end{array}}$
} & 
\multicolumn{2}{p{0.861in}|}
{\raggedright

$\infer[\reason{$\;!-E$}]
       {A}
       {\begin{array}{l} \thinspace \thinspace \thinspace \thinspace \thinspace \thinspace \thinspace \vdots  \ !!A \end{array}}$
}\\
\hline
% ROW 2
\multicolumn{2}{p{0.042in}|}
{\raggedright

$\infer[\reason{$@*-E$}]
       {P(c)}
       {\begin{array}{l} \vdots \quad \quad \quad \quad \vdots \ \ \  \ @*x.P(x)\quad c\ \operatorname{inscope} \end{array}}$
} & 
\multicolumn{2}{p{0.042in}|}
{\raggedright

$\infer[\reason{$(\operatorname{FRESH}\;c,\;c\;\operatorname{NOTIN}\;\exists x.P(x))\;\;|*-E$}]
       {A}
       {\begin{array}{l} \ \quad \ \ \ \ \ \ \ [\operatorname{var} \ c,P(c)] \ \ \ \ \ \ \ \thinspace \vdots \ \ \quad \quad \quad \vdots  \ \exists x.P(x)\quad \quad A \end{array}}$
}\\
\hline
% ROW 3
\multicolumn{1}{p{0.042in}|}
{\raggedright

$\infer[\reason{$->-I$}]
       {A->B}
       {\begin{array}{l} [A] \ \ \thinspace \vdots  \ \thinspace B \end{array}}$
} & 
\multicolumn{1}{p{0.042in}|}
{\raggedright

$\infer[\reason{$@-I$}]
       {A@B}
       {\begin{array}{l} \ \vdots \quad \ \thinspace \vdots  \ A\quad B \end{array}}$
} & 
\multicolumn{1}{p{0.042in}|}
{\raggedright

$\infer[\reason{$|-I(L)$}]
       {A|B}
       {\begin{array}{l} \thinspace \thinspace \vdots  \ A \end{array}}$
} & 
\multicolumn{2}{|p{1.611in}|}
{\raggedright

$\infer[\reason{$|-I(R)$}]
       {A|B}
       {\begin{array}{l} \thinspace \thinspace \vdots  \ B \end{array}}$
} & 
\multicolumn{3}{p{2.670in}|}
{\raggedright

$\infer[\reason{$!-I$}]
       {!A}
       {\begin{array}{l} \ \ [A] \ \ \ \ \ \vdots  \ \thinspace B@!B \end{array}}$
}\\
\hline
% ROW 4
\multicolumn{2}{p{0.042in}|}
{\raggedright

$\infer[\reason{$(\;c)\;\;@*-I$}]
       {@*x.P(x)}
       {\begin{array}{l} [\operatorname{var} \ c] \ \thinspace \thinspace \ \ \thinspace \vdots  \ P(c) \end{array}}$
} & 
\multicolumn{6}{p{0.176in}|}
{\raggedright

$\infer[\reason{$|*-I$}]
       {|*x.P(x)}
       {\begin{array}{l} \thinspace \thinspace \ \thinspace \thinspace \vdots \quad \quad \quad \ \ \vdots  \ P(c)\quad c\ \operatorname{inscope} \end{array}}$
}\\
\hline
\end{tabular}


The provisos on ∃-\textit{E} and ∀-\textit{I} implement the provisos on the box rules reasonably accurately. They aren't quite the same, because there could be other scopes in the proof where the same name is used; in practice, because our implementation of these rules makes them introduce names new to the proof, the distinction is unnoticeable. To implement the condition on ∃-\textit{I} and ∀-\textit{E} we have used pseudo-predicates var and inscope; \textit{c} inscope is a side condition that var \textit{c} must occur in the hypotheses.


We then recast these rules into sequent notation.



$\infer[\reason{$hyp$}]
       {\Gamma,A |- A}
       {}$

\begin{tabular}{llllllllllllllllll}
\hline
% ROW 1
\multicolumn{2}{|p{1.094in}|}
{\raggedright

$\infer[\reason{$
\;->-E$}]
       {\Gamma  |- B}
       {\Gamma  |- A\quad \Gamma  |- A->B}$
} & 
\multicolumn{2}{p{0.839in}|}
{\raggedright

$\infer[\reason{$@-E(L)$}]
       {\Gamma  |- A}
       {\Gamma  |- A@B}$
} & 
\multicolumn{2}{p{0.822in}|}
{\raggedright

$\infer[\reason{$@-E(R)$}]
       {\Gamma  |- B}
       {\Gamma  |- A@B}$
} & 
\multicolumn{2}{p{1.484in}|}
{\raggedright

$\infer[\reason{$|E$}]
       {\Gamma
 |- C}
       {\Gamma  |- A|B\quad \Gamma,A |- C\quad \Gamma,B |- C}$
}\\
\hline
% ROW 2
\multicolumn{1}{p{0.042in}|}
{\raggedright

$\infer[\reason{$\;!-E$}]
       {\Gamma  |- A}
       {\Gamma  |- !!A}$
} & 
\multicolumn{2}{p{0.042in}|}
{\raggedright

$\frac{\Gamma  |- @*x.A\left( x\right) \quad \Gamma |- c\;\operatorname{inscope}}{\Gamma  |- A\left( c\right) } \;\;\forall -E$
} & 
\multicolumn{2}{p{0.042in}|}
{\raggedright
}\\
\hline
% ROW 3
\multicolumn{5}{p{0.134in}|}
{\raggedright

$\frac{\Gamma  |-|*x.A\left( x\right) \quad \Gamma ,\operatorname{var} \;c,A\left( c\right)  |- B}{\Gamma  |- B} \;(\;c,\;c\;\;|*x.A)\;\;|*-E$
} & 
\multicolumn{2}{|p{1.094in}|}
{\raggedright
}\\
\hline
% ROW 4
\multicolumn{4}{p{1.662in}|}
{\raggedright

$\infer[\reason{$\;->-I$}]
       {\Gamma  |- A->B}
       {\Gamma,A |- B}$
} & 
\multicolumn{2}{p{1.484in}|}
{\raggedright

$\infer[\reason{$\;@-I$}]
       {\Gamma  |- A@B}
       {\Gamma  |- A\quad \Gamma  |- B}$
} & 
\multicolumn{1}{p{0.042in}|}
{\raggedright

$\infer[\reason{$\;|-I(L)$}]
       {\Gamma  |- A|B}
       {\Gamma  |- A}$
} & 
\multicolumn{2}{p{0.042in}|}
{\raggedright

$\infer[\reason{$\;|-I(R)$}]
       {\Gamma  |- A|B}
       {\Gamma  |- B}$
} & 
\multicolumn{7}{p{0.176in}|}
{\raggedright

$\infer[\reason{$\;!-I$}]
       {\Gamma  |- !A}
       {\Gamma,A |- B@!B}$
}\\
\hline
% ROW 5
\multicolumn{6}{|p{2.755in}|}
{\raggedright

$\frac{\Gamma,\operatorname{var} \;c |- A\left( c\right) }{\Gamma |- @*x.A\left( x\right) } \;\;(\;c)\;\;@*-I$
} & 
\multicolumn{2}{p{1.484in}|}
{\raggedright

$\frac{\Gamma  |- A\left( c\right) \quad c\;\operatorname{inscope}}{\Gamma |-|*x.A\left( x\right) } \;\;|*-I$
}\\
\hline
\end{tabular}


Plainly it is a difficulty, in a backwards-reasoning tool, that each of these is a right-hand rule. Yet if we are to be faithful to our customer's intention, these are the rules that we must encode. In order to understand how to do that, it is necessary to understand how they are intended to be used.


\textbf{{\large 4.2\tab Syntax}}


The description of the syntax is straightforward, but differs from that used in the sequent calculus encoding of the previous chapter. The QMW course lecturer wanted quantification to affect the \textit{smallest} following formula, while in the previous chapter quantification was made to affect the \textit{largest} following formula. That is, in this encoding $@*x.A->B$ should parse as $\left( @*x.A\right) ->B$ whereas in the sequent calculus encoding it parses as $@*x.\left( A->B\right) $ . We solve the problem by making the priority of quantification just larger than that of negation\footnote{Our customer also wanted no punctuation between bound variable and body: we can't yet do that.}; at the same time we've corrected an error in an earlier release and made the priority of \ensuremath{|} less than that of \ensuremath{@}:

PREFIX\tab 10\tab var\\
POSTFIX\tab 10\tab inscope

INFIX\tab 100R\tab →\\
INFIX\tab 120L\tab ∧\\
INFIX\tab 140L\tab ∧

LEFTFIX\tab 180\tab ∀.\\
LEFTFIX\tab 180\tab ∃.

PREFIX\tab 200\tab ¬\\
JUXTFIX\tab 300\\
SUBSTFIX\tab 400 

BIND x SCOPE P IN ∀x. P\\
BIND x SCOPE P IN ∃x. P

SEQUENT IS BAG ⊦ FORMULA


We set two variables (really they are parameters, because they can only be altered when the rule and theorem store is empty):

INITIALISE autoAdditiveLeft\tab true \\
INITIALISE interpretpredicates\tab true


The first of these allows us to define rules without mentioning a left context, automatically inserting a context variable \ensuremath{\Gamma} into every sequent in a rule definition (that is, allowing rule definition in the style of natural deduction and earlier versions of Jape). The second directs Jape to interpret every juxtaposition -- everything that looks like a predicate application -- as a predicate application, to translate where necessary into substitution notation and to include additional rule parameters and invisible provisos to support the translation.


\textbf{{\large 4.3\tab Variable settings}}


In the definition file (ItL.jt in the distribution) we set a number of variables in Jape's environment. We don't want to apply a conjecture until it is proved, and we don't want to use a resolution step unless a tactic commands it:

INITIALISE applyconjectures false\\
INITIALISE tryresolution false


The display style should be box-and-line, and we want to control the naming of assumptions: the outermost assumption should be ``premise'' and assumptions introduced during the proof should be ``premises'':

INITIALISE displaystyle box

INITIALISE outerassumptionword premise\\
INITIALISE outerassumptionplural premises\\
INITIALISE innerassumptionword assumption\\
INITIALISE innerassumptionplural assumptions


\textbf{{\large 4.4\tab Forward reasoning}}


The sort of step that a natural-deduction reasoner might want to make is best illustrated by example. Consider the problem of proving P → Q, Q → R, P ⊦ R (the second problem in the Conjectures panel defined in the file ItL\_problems.j). In box display mode this is shown as

\begin{figure}[htbp] \begin{center} \includegraphics[width=1.944in, height=0.722in]{oldpics/Roll_your_own_v3_2+Fig25} \caption{Fig25} \end{center} \end{figure}


To anyone used to forward reasoning, the first step is clear: on line 1 there is P and there is also P → Q; use the →-E rule to conclude Q. In the ItL.jt encoding of natural deduction that step can be made by first selecting P → Q on line 1

\begin{figure}[htbp] \begin{center} \includegraphics[width=1.944in, height=0.722in]{oldpics/Roll_your_own_v3_2+Fig26} \caption{Fig26} \end{center} \end{figure}


and then applying →-E from the Rules menu

\begin{figure}[htbp] \begin{center} \includegraphics[width=2.097in, height=0.972in]{oldpics/Roll_your_own_v3_2+Fig27} \caption{Fig27} \end{center} \end{figure}


It looks like a forward step, and it quacks like a forward step: now you can select Q → R on line 1

\begin{figure}[htbp] \begin{center} \includegraphics[width=2.097in, height=0.972in]{oldpics/Roll_your_own_v3_2+Fig28} \caption{Fig28} \end{center} \end{figure}


and apply →-E again

\begin{figure}[htbp] \begin{center} \includegraphics[width=2.097in, height=0.819in]{oldpics/Roll_your_own_v3_2+Fig29} \caption{Fig29} \end{center} \end{figure}


The proof is complete, and has apparently used forward reasoning. Yet in fact it was all done with right-hand side rules and backward reasoning. (It is also possible to start by eliminating the arrow in Q→R, but this isn't the manual for that discussion: see ``Using ItL Jape'' which you can get from the MacOS Web site at QMW.)


\textit{Cut and forward reasoning}


There is a well-known and obvious correspondence between a proof which uses forward reasoning in natural deduction and one which uses \textit{cut} -- between
$ \begin{array}{l} \vdots  \\
B \\
\vdots  \\
C \end{array} $, on the one hand, and $\infer{C}{\cols\vdots\\B\sloc & \cols \![B]\\ \vdots\\ C\sloc}$ or $\infer{\Gamma  |- C}
       {\Gamma  |- B\quad \Gamma,B |- C}$ on the other. The proof above is based on a similar correspondence between $ \begin{array}{l} \frac{ \begin{array}{l} \thinspace \vdots  \ P\quad P->Q \end{array} }{Q} \;->-E \\
\quad \quad \,\vdots  \\
\quad \;\;\;R \end{array} $ and


$\infer[\reason{$cut$}]
       {P->Q,Q->R,P |- R}
       {\infer[\reason{$->-E$}]
              {P->Q,Q->R,P |- Q}
              {P->Q,Q->R,P |- P &
               \infer[\reason{$hyp$}]
                     {P->Q,Q->R,P |- P->Q} {}} &
        P->Q,Q->R,P,Q |- R}$

In the sequent proof, reading downwards, the \textit{hyp} step moves \textit{P}\ensuremath{->}\textit{Q} from right to left; the \ensuremath{->}-\textit{E} step generates \textit{Q}, and the \textit{cut} step moves \textit{Q} from right to left, making it available as an hypothesis for use in the rest of the proof. The sequence ``\textit{hyp}; rule; \textit{cut}'' must be reversed in a backwards reasoning engine like Jape, but in principle that is all there is to forward reasoning in Jape at present, together with box display mechanisms which hide both \textit{hyp} and \textit{cut} steps.


In order to program this mechanism in Jape's tactic language, we proceed step by step. We include a \textit{hyp} rule, we declare it so that its application is hidden in box display, and we automatically apply it at the end of every proof step (all this could be done anyway, and has nothing essential to do with the forward reasoning mechanism):

RULE hyp(A) IS INFER A ⊦ A\\
STRUCTURERULE IDENTITY hyp\\
AUTOMATCH hyp


Similarly, we include and declare \textit{cut}:

RULE cut(B) IS FROM B AND B ⊦ C INFER C\\
STRUCTURERULE CUT cut


The elimination rules are the ones which are usually used forward. Each rule is defined in the usual way, just as it would be if it were to be used only as a backwards reasoning rule. For example we encode →-E as follows, giving \textit{A} as an argument because it isn't a subformula of the consequent pattern:

RULE "→-E"(A) IS FROM A AND A→B INFER B


When this rule is applied it is necessary to distinguish `backward' from `forward' application. We have done this by testing if a left-hand side formula has been selected -- which we take as a signal for `forward' reasoning -- or not -- which is a signal for `backward' reasoning. The entry for →-E in the Rules menu applies a tactic, giving the name of a tactic and of the rule as arguments:

ENTRY "→-E"\tab IS ForwardOrBackward ForwardCut 1 "→-E"


Here \textit{ForwardOrBackward} is the tactic which detects whether to use a forward or a backward step; \textit{ForwardCut} does the necessary work with \textit{cut}, the rule itself, and \textit{hyp}. It includes a step which selects the antecedent to which \textit{hyp} is to be applied\textit{:}

TACTIC ForwardCut (n,Rule) \\
SEQ cut (WITHARGSEL Rule) (JAPE (SUBGOAL n)) (WITHHYPSEL hyp)


\textsc{Withargsel} applies a tactic taking account of any text-selections which the user might have made -- that is, adding an argument to the rule if the user text-selects an argument; \textsc{jape(subgoal} \textit{n}\textsc{)} selects the \textit{n}th antecedent (they are numbered 0, 1,...) of the last applied rule; \textsc{withhypsel} applies a tactic taking account of any left-hand side selection, and since there will always be one when we call this tactic from \textit{ForwardOrBackward}, the effect is that the user's selected formula is used in the \textit{hyp} step.


\textit{ForwardOrBackward} tests whether a left-hand-side formula is selected or not, and chooses to call its first argument or its second accordingly. Stripped to its bones it is simply:

TACTIC ForwardOrBackward (Forward, n, Rule) IS \\
\tab WHEN\tab (LETHYP \_P (Forward n Rule))\\
\tab \tab (WITHSELECTIONS Rule)


The \textsc{when} tactical takes a number of tactics, each of which except the last must be guarded: it finds and executes the first guarded tactic whose guard succeeds, or executes its last argument otherwise. \textsc{Lethyp} is a guarded tactic whose guard succeeds if the user has selected a left-hand side formula which unifies with its first argument, and fails otherwise. When it succeeds it executes its second argument in the context produced by the successful unification. In this case, since \_\textit{P} will unify with any formula, the effect of the whole tactic is to test whether any left-hand side formula is selected and if so, to execute the tactic corresponding to Forward (in our case \textit{ForwardCut}) or if not, to execute the tactic corresponding to Rule (in our case the rule →-E), taking account of any user gestures, such as argument selection, that may have been made.


In conjunction with \textsc{automatch} \textit{hyp}, which automatically closes tips that can be trivially closed, and hiding of \textit{hyp} and \textit{cut} lines, this mechanism has the effect illustrated in the example proof above. To see how it works, we show what would be seen if the steps of the tactic were carried out one by one, without any special display aids, in both tree and box form (you can do this for yourself by loading the file `displaystyle in Edit menu' from the `useful buttons' example folder, and then removing the ticks from the `hide cut lines' and `hide identity lines' entries). Notice how the unknowns introduced in steps 1 and 2 are all resolved by \textit{hyp} in step 3. That application is on the second antecedent of the →-E, and is constrained to use the originally-selected left-hand side formula, which in this case is P→Q.\\


\begin{tabular}{|p{0.939in}|p{1.123in}|p{2.439in}|}
\hline
% ROW 1
{\raggedright 1. \textit{cut}} & 
{\centering } & 
{\raggedright }\\
\hline
% ROW 2
{\raggedright 2. withargsel ``{\small →-E''}} & 
{\centering } & 
{\raggedright }\\
\hline
% ROW 3
{\raggedright 3.\tab jape(subgoal 1), withhypsel \textit{hyp} } & 
{\centering } & 
{\raggedright }\\
\hline
% ROW 4
{\raggedright 4. automatch \textit{hyp}} & 
{\centering } & 
{\raggedright }\\
\hline
\end{tabular}


Because the effect is produced by a tactic the user doesn't see the intermediate steps of the process, and because box display has been instructed to hide \textit{hyp} and \textit{cut} lines, all the user sees, as the original example shows, is a picture in which lines 2 and 3 have been deleted, with references to them converted to references to assumptions 1.3 and 1.1, and in which the \textit{cut} step has been hidden by overlaying line 5 with line 4 and line 7 with line 6.


The principle, then, is to use \textit{cut} to implement a kind of forward reasoning. Not every `forward' step requires a cut, so we have another auxiliary tactic:

TACTIC ForwardUncut (n,Rule) SEQ (WITHARGSEL Rule) (JAPE (SUBGOAL n)) (WITHHYPSEL hyp)


The complete ForwardOrBackward tactic attempts some error reporting if a rule application fails:

TACTIC ForwardOrBackward (Forward, n, Rule) IS \\
\tab WHEN\tab (LETHYP \_P \\
\tab \tab \tab (ALT\tab (Forward n Rule)\\
\tab \tab \tab \tab (WHEN\tab (LETARGSEL \_Q \\
\tab \tab \tab \tab \tab \tab (FAIL (Rule is not applicable to assumption ' \_P ' with argument ' \_Q '))\\
\tab \tab \tab \tab \tab )\\
\tab \tab \tab \tab \tab (FAIL (Rule is not applicable to assumption ' \_P '))\\
\tab \tab \tab \tab )\\
\tab \tab \tab )\\
\tab \tab )\\
\tab \tab (ALT\tab (WITHSELECTIONS Rule)\\
\tab \tab \tab (WHEN\tab (LETARGSEL \_P\\
\tab \tab \tab \tab \tab (FAIL (Rule is not applicable with argument ' \_P '))\\
\tab \tab \tab \tab )\\
\tab \tab \tab \tab (FAIL (Rule is not applicable))\\
\tab \tab \tab )\\
\tab \tab )


\textsc{alt} is a tactic that tries its arguments in turn until one of them is completely successful; \textsc{fail} \textit{x} is defined by

TACTIC FAIL(x) IS JAPE (fail x)


and simply puts up message \textit{x} as an error alert in the graphical interface.


The rules of the system can now be stated simply. Because we have set the \textit{autoAdditiveLeft} variable to \textit{true}, we can define these rules natural-deduction style, mentioning nothing but the principal formulae, and Jape will automatically prepend a context variable \ensuremath{\Gamma} to the left-hand side of every sequent:

RULE "→-E"(A)\tab IS FROM A AND A→B INFER B\\
RULE "∧-E(L)"(B)\tab IS FROM A ∧ B INFER A\\
RULE "∧-E(R)"(A)\tab IS FROM A ∧ B INFER B\\
RULE "∧-E"(A,B)\tab IS FROM A ∧ B AND A ⊦ C AND B ⊦ C INFER C\\
RULE "¬-E"\tab IS FROM ¬¬A INFER A\\
RULE "∀-E"(B)\tab (unknown char)IS FROM ∀x. A(x) AND B inscope INFER A(B)\\
RULE "∃-E"(OBJECT c) WHERE FRESH c AND c NOTIN ∃x.A(x)\\
\tab IS FROM ∃x.A(x) AND var c, A(c) ⊦ C INFER C\\
RULE "→-I"\tab IS FROM A ⊦ B INFER A→B\\
RULE "∧-I"\tab IS FROM A AND B INFER A ∧ B\\
RULE "∧-I(L)"(B)\tab IS FROM A INFER A ∧ B\\
RULE "∧-I(R)"(A)\tab IS FROM B INFER A ∧ B\\
RULE "¬-I"(B)\tab IS FROM A ⊦ B ∧ ¬B INFER ¬A\\
RULE "∀-I"(OBJECT c) WHERE FRESH c\\
\tab IS FROM var c ⊦ A(c) INFER ∀x.A(x)\\
RULE "∃-I"(B)\tab IS FROM A(B) AND B inscope INFER ∃x.A(x)


It's straightforward to organise them into a menu:

MENU Rules IS\\
\tab ENTRY "→-I"\\
\tab ENTRY "∧-I"\tab \\
\tab ENTRY "∧-I(L)"\tab IS ForwardOrBackward ForwardCut 0 "∧-I(L)"\\
\tab ENTRY "∧-I(R)"\tab IS ForwardOrBackward ForwardCut 0 "∧-I(R)"\\
\tab ENTRY "¬-I"\\
\tab ENTRY "∀-I"\\
\tab ENTRY "∃-I"\tab IS "∃-I with side condition hidden"

\tab SEPARATOR

\tab ENTRY "→-E"\tab IS ForwardOrBackward ForwardCut 1 "→-E" \\
\tab ENTRY "∧-E(L)"\tab IS ForwardOrBackward ForwardCut 0 "∧-E(L)"\\
\tab ENTRY "∧-E(R)" \tab IS ForwardOrBackward ForwardCut 0 "∧-E(R)"\\
\tab ENTRY "∧-E"\tab IS ForwardOrBackward ForwardUncut 0 "∧-E"\tab \\
\tab ENTRY "¬-E"\tab IS ForwardOrBackward ForwardCut 0 "¬-E"\tab \\
\tab ENTRY "∀-E"\tab IS ForwardOrBackward ForwardCut 0 "∀-E with side condition hidden"\\
\tab ENTRY "∃-E"\tab IS ForwardOrBackward ForwardUncut 0 "∃-E"

\tab SEPARATOR

\tab ENTRY hyp\\
END


Two of the entries are given indirectly, because they aren't simply rules :

TACTIC "∀-E with side condition hidden" IS LAYOUT "∀-E" (0) (WITHARGSEL "∀-E")\\
TACTIC "∃-I with side condition hidden" IS LAYOUT "∃-I" (0) (WITHARGSEL "∃-I")


As in chapter 3, we have a rule for the inscope judgement, which is tried at the end of every proof step:

RULES "inscope" IS INFER var x ⊦ x inscope

AUTOMATCH "inscope"


There is also a file ItL\_hits.j, which implements double-clicking: we don't reference this in ItL.jt, because we don't want to provide it by default to our novice students.


\textbf{{\large 4.5\tab The Conjectures panel}}


Since we can apply rules either forward or backward, it would be irksome if we could only apply theorems backward. We define a tactic which can do the job. If a hypothesis has been selected it cuts and applies the theorem, requiring that the selected hypothesis be one of the principal formulae which match the theorem sequent. If no hypothesis is selected it tries in order to apply the theorem to the present problem sequent, to apply it `by resolution' (matching only the right-hand side of the theorem sequent and the problem sequent and generating antecedents for each left-hand side theorem formula: see chapter 1), and finally tries to apply it forwards, one way or the other. All of the steps are made `\textsc{withselections}' -- that is, using any argument selection which the user may have made:

TACTIC TheoremForwardOrBackward(thm) IS\\
\tab WHEN \tab (LETHYP \_P cut (WITHSELECTIONS thm))\\
\tab \tab (ALT\tab (WITHSELECTIONS thm) \\
\tab \tab \tab (RESOLVE (WITHSELECTIONS thm)) \\
\tab \tab \tab (SEQ cut (ALT (WITHSELECTIONS thm) (RESOLVE (WITHSELECTIONS thm)))) \\
\tab \tab )


The overall effect is to allow a prover to introduce a theorem into the proof whenever it is helpful to do so.\\
The Conjectures panel activates this tactic from its Apply button. The panel is defined in the following manner in the file ItL\_problems.j:

CONJECTUREPANEL Conjectures\\
\tab THEOREM INFER P, P → Q ⊦ Q\\
\tab THEOREM INFER P → Q, Q → R, P ⊦ R\\
\tab THEOREM INFER P → (Q → R), P → Q, P ⊦ R

\tab ...

\tab THEOREM "(∀x.P(x)) → (∀x.Q(x)) ⊦ ∀x.(P(x) → Q(x)) NOT" IS ∀x.P(x) → ∀x.Q(x) ⊦ ∀x.(P(x) → Q(x))\\
\tab THEOREM "(∃x.P(x)) ∧ (∃x.Q(x)) ⊦ ∃x.(P(x) ∧ Q(x)) NOT" IS ∃x.P(x) ∧ ∃x.Q(x) ⊦ ∃x.(P(x) ∧ Q(x))

\tab PREFIXBUTTON Apply IS apply TheoremForwardOrBackward\\
\tab END


Most conjectures are named by their sequent, but the last few are specially named because a proof attempt is certain to fail.\\
When the Apply button is pressed with a conjecture \textit{C} selected, the effect is to send the command ``apply TheoremForwardOrBackward \textit{C}'' to theproof engine and then the tactic takes over.


\textbf{{\large 4.6\tab An alternative natural deduction encoding}}


There is an alternative natural deduction encoding, distributed as jnj.jt\footnote{It doesn't work under MacOS yet, because of problems with font encoding.}, and described in ``Using J'n'J in Jape'', available from the Oxford Jape web site. It will be described in a future edition of this manual.



\chapter{Encoding equational reasoning in functional programs}


Previous chapters have dealt with the encoding of logics which are, more or less, variations on the sequent calculus. This chapter describes our treatment of a very different logic. The problem here is to control a large number of equations used to reason about functional-programming formulae, and to present an interface which makes it look as if equational reasoning is taking place, despite the Gentzen tree in the background. The treatment is distributed in the files referenced by the file functions.jt.


\textbf{{\large 5.1\tab Syntax}}


Jape provides juxtaposition as a primitive syntactic construction, and so it is convenient to represent function application as juxtaposition. In the same way we take the syntax of tupling directly from Jape.

FONTS\tab "Konstanz"\\
INITIALISE autoAdditiveLeft true\\
SEQUENT IS BAG ⊦ FORMULA

USE\tab "equality\_rules.j"\\
USE\tab "equality\_menus.j"\\
USE\tab "functions\_rules.j"\\
USE\tab "functions\_menus.j"

AUTOMATCH "= reflexive"


Note that we don't automatically translate predicate notation in this encoding: we use juxtaposition mostly to represent function application. We use the \textsc{abstraction} keyword to label those few parameters of rules which are to be treated as predicates: see below for examples.


The file equality\_rules.j covers more than simple equality, since it is intended to be shared between different encodings. Apart from that, it is pretty straightforward. The syntactic description is:

CLASS VARIABLE x y\\
CLASS FORMULA A B C F G X Y Z\\
CONSTANT \"{Y}

SUBSTFIX\tab 2000 \{ x {\textbackslash} A \}\\
JUXTFIX\tab 1000\\
INFIX\tab 200L\tab = \ensuremath{\geq} \ensuremath{\leq} \ensuremath{\neq} \texttt{<} \texttt{>}\\
INFIX\tab 250L\tab + -\\
INFIX\tab 260L\tab * /\\
INFIX\tab 270L\tab {\textasciicircum}


Reading from the bottom, we define some binary operators, all left-associative, then we define the priority of juxtaposition and substitution. The syntax of substitution is slightly variable in Jape: you can specify the bracketing symbols and the separating symbol as well as defining whether the variables come before the names or vice-versa. The spaces between symbols and names are essential to delimit the various components of the syntactic form. We have chosen to make \textit{formula} \{ \textit{variables} {\textbackslash} \textit{formulae} \} the syntax of a substitution form, because that liberates square brackets for use in their conventional r\^{o}le in functional programming as list brackets\footnote{We would have reversed the order of formulae and variables had the author of the encoding not already hijacked the `/' operator.}.


Then there are some simple definitions, intended to make what follows easier to read:

TACTIC FAIL(x)\tab IS JAPE(fail x)\\
TACTIC FAILREASON(x)\tab IS JAPE (failgivingreason x)


and a perfectly normal definition of an identity rule:

RULE hyp IS A ⊦ A\\
IDENTITY hyp


There follow the basic rules of equality. Because Jape doesn't yet have any treatment of families of rules, we can only give a tuple-equality rule for a fixed finite number of tuple sizes, and here we restrict ourselves to pairs\footnote{But see our treatment of BAN logic in a later chapter: we are beginning to be able to handle some simple families of rules.}:\\


\begin{tabular}{|p{1.584in}|p{1.603in}|p{1.168in}|p{0.048in}|p{0.048in}|p{0.048in}|}
\hline
% ROW 1
{\raggedright 
$\infer[\reason{$=\;\operatorname{reflexive}$}]
       {\Gamma  |- X=X}
       {}$
} & 
{\raggedright 
$\infer[\reason{$
\;=\,\operatorname{transitive}$}]
       {\Gamma  |- X=Z}
       {\Gamma  |- X=Y\quad \Gamma  |- Y=Z}$
} & 
{\raggedright 
$\infer[\reason{$=\,\operatorname{symmetric}$}]
       {\Gamma  |- Y=X}
       {\Gamma  |- X=Y}$
}\\
\hline
% ROW 2
{\raggedright 
$\infer[\reason{$
\;=\,(,)$}]
       {\Gamma  |- (X0,X1)=(Y0,Y1)}
       {\Gamma  |- X0=X1\quad \Gamma  |- Y0=Y1}$
} & 
{\raggedright } & 
{\raggedright }\\
\hline
\end{tabular}


Although most of these rules can be derived from `= reflexive' plus the rewrite rules given below, it is convenient to have them available directly. In any case, Jape doesn't yet have facilities to prove derived rules with antecedents. In Japeish the rules are:

RULE "= reflexive"\tab IS \tab INFER X = X\\
RULE "= transitive"(Y)\tab IS FROM X = Y AND Y = Z \tab INFER X = Z\\
RULE "= symmetric"\tab IS FROM X = Y \tab INFER Y = X\\
RULE "(,)="\tab IS FROM X0=X1 AND Y0=Y1\tab INFER (X0, Y0) = (X1, Y1)


Extensionality rules are straightforward but because each implicitly incorporates a step of generalisation, we are careful to include \textsc{fresh} provisos:\\


\begin{tabular}{|p{2.119in}|p{2.276in}|p{0.052in}|p{0.052in}|}
\hline
% ROW 1
{\raggedright 
$\infer[\reason{$
\;(\,x)\;\operatorname{ext}$}]
       {\Gamma  |- F=G}
       {\Gamma  |- F\left( x\right) =G\left( x\right) }$
} & 
{\raggedright 
$\infer[\reason{$
\;(\,x,y)\;\operatorname{ext}2$}]
       {\Gamma  |- F=G}
       {\Gamma  |- F(x,y)=G(x,y)}$
}\\
\hline
\end{tabular}


In the Japeish version we use \textsc{object} parameters so that the rules, normally used backwards, introduce new identifiers rather than unknowns:

RULE ext (OBJECT x) WHERE FRESH x \tab IS FROM F x = G x\tab INFER F = G\\
RULE ext2(OBJECT x, OBJECT y) WHERE FRESH x, y\\
\tab IS FROM F (x, y) = G (x,y)\tab INFER F = G


That, so far as this encoding is concerned, is where the simple bit ends.


\textbf{{\large 5.2\tab The rewrite rule and user definition of substitutions}}


We base our treatment of equational reasoning on rewrite rules. We can replace occurrences of a sub-formula \textit{X} within a formula \textit{A} by an alternative sub-formula \textit{Y}, provided only that we can prove $X=Y$ . Because an equality can be used to rewrite in either direction we include two rules, whose names are arbitrarily chosen:\\


\begin{tabular}{|p{2.265in}|p{2.132in}|p{0.051in}|p{0.051in}|} \hline
% ROW 1
{\raggedright $\frac{\Gamma  |- X=Y\quad \Gamma  |- A\left\{ x\backslash Y\right\} }{\Gamma |- A\left\{ x\backslash X\right\} } \;\operatorname{rewrite}$ } & {\raggedright $\frac{\Gamma  |- X=Y\quad \Gamma  |- A\left\{ x\backslash X\right\} }{\Gamma |- A\left\{ x\backslash Y\right\} } \;\operatorname{rewritebackwards}$ }\\
\hline \end{tabular}


In Japeish, as by now you must expect, we give the first rule a parameter \textit{X} and the second a parameter \textit{Y}. Just for fun we write the rules in predicate notation, which Jape immediately translates into the rules written above.

RULE rewrite (X,ABSTRACTION AA)\tab IS FROM X=Y AND AA(Y) INFER AA(X)\\
RULE rewritebackwards (Y,ABSTRACTION AA)\tab IS FROM X=Y AND AA(X) INFER AA(Y)


The problem formula which matches \textit{AA}(\textit{X}) or \textit{AA}(\textit{Y}) will itself be an equation in all the conjectures which we shall consider, but we don't need to take account of that in the rewrite rules themselves\footnote{We are beginning to realise how to display linear equational proofs using transitivity in much the same way that forward reasoning steps use cut. Once we have perfected the technique our rewrite rules will have to take a different form.}.


In principle, and in practice, it is possible to use the rewrite rule by providing just the argument corresponding to \textit{X} in the rewrite rule or \textit{Y} in the rewritebackwards rule: Jape will search for instances of that argument on the right-hand side of the problem sequent and, in effect, construct a substitution which it unifies with $\_{}A\left\{ x\backslash \_{}X\right\} $ or $\_{}A\left\{ x\backslash \_{}Y\right\} $ . That process finds every instance of the argument formula in the right-hand side of the problem sequent, and sometimes that is just what is required.


When we want finer control, which we do when working under direct user control rather than via a search controlled by a tactic, we use the \textsc{letsubstsel} and \textsc{withsubstsel} tacticals. The basis of the technique which we use in encoding equational reasoning with functional programs is exemplified by the following fragment

WHEN (LETSUBSTSEL \_A (WITHSUBSTSEL rewrite))


\textsc{Letsubstsel} \textit{pattern} \textit{tactic} \dots  is a guarded tactic whose guard succeeds if:


{\textbullet}\tab the user has made at least one text-selection;


{\textbullet}\tab all text-selections are of identical subformulae \textit{E} within the same formula \textit{F} in the current goal sequent;\\
{\textbullet}\tab it is possible to construct a substitution form $F' \left\{ v\backslash E\right\} $, where \textit{v} is a fresh variable, such that $F' \left\{ v\backslash E\right\} $ reduces to \textit{F} in the presence of the proviso \textit{v} \textsc{notin} \textit{F};\\
{\textbullet}\tab \textit{pattern} unifies with $F' \left\{ v\backslash E\right\} $, without simplifying the substitution unless it is unified with a non-substitution form.


If all four conditions are satisfied, the sequence \textit{tactic} \dots  is executed within the context created by the unification of \textit{pattern} with $F' \left\{ v\backslash E\right\} $ . The substitution form $F' \left\{ v\backslash E\right\} $ is specially marked so that it is not simplified during the unification process unless it is matched with a non-substitution form: the effect is that it will be unified by structure-matching with a substitution form in \textit{pattern}, if one is provided.

$F' \left\{ v\backslash E\right\} $ is equivalent to the original formula \textit{F}, and if it isn't used immediately in a unification it is simplified out of existence: that's the reason that we have to have both \textsc{letsubstsel}, to check if we can make the substitution form at all, and then \textsc{withsubstsel,} to make it again and to use it immediately in a rule application.


\textsc{Withsubstsel} \textit{tactic} \dots is a tactic which requires that the first three of the \textsc{letsubstsel} conditions are satisfied and, if they are, it applies the sequence \textit{tactic} \dots to a copy of the problem sequent in which formula \textit{F} has been replaced by $F' \left\{ \_{}v\backslash E\right\} $ . this time using a fresh unknown \_\textit{v} to facilitate unification with the consequent of a rule which uses a corresponding \textsc{object} parameter. As before, the substitution form $F' \left\{ \_{}v\backslash E\right\} $ is specially marked so that it can be unified component-by-component with a corresponding substitution form in the consequent of a rule, and it's eliminated very easily by simplification, so the first rule of \textit{tactic} \dots  is usually the only one that gets a bite at it.


The effect of all this machinery is that it is possible for a user to specify, simply by text-selecting them, the instances of a subformula \textit{X} which are to be replaced by \textit{Y}, working backwards with the rewrite rule -- or \textit{Y} with \textit{X}, working backwards with rewritebackwards. Based on that bit of magic, a great deal becomes possible.


\textbf{{\large 5.3\tab Hiding parts of proofs: the \textsc{layout} tactical}}


When we use the rewrite rule in this logic-encoding, for the most part we employ straightforward function definitions for the left-hand antecedent $X=Y$ . These definitions -- `facts' like \textit{map{\nobreakspace}f{\nobreakspace}}[]{\nobreakspace}={\nobreakspace}[] -- are supposed to be well-known to the user, and are therefore best kept as marginal notes in the proof. Our eventual goal is to be able to show a linear equational proof like those in Bird and Wadler, in which every step transforms a formula by equality-substitution:

\textit{rev(rev} [])\tab = \textit{rev} []\tab by \textit{rev} [] = []\\
= []\tab by \textit{rev} [] = []\\
= \textit{id} []\tab by \textit{id} \textit{x} = \textit{x}


In this style the definitions used in each step are noted in the justification of an equality, not included as antecedents of an inference step. The facilities of Jape don't quite stretch to linear equational proofs yet, but we're close.


What we can do is to hide some of the antecedent proof trees of a proof step, and to alter the displayed justification of that step to record some of the information which is hidden. Ths is done with the \textsc{layout} tactical, which is given the justification of the step, a description of the antecedents that should remain visible, and a tactic which generates the proof tree itself. One of the tactics we use in our encoding, for example, reads as follows:

TACTIC UnfoldOneSel(x) IS\\
\tab WHEN\tab (LETSUBSTSEL \_A (LAYOUT "Fold \%s" (1) (WITHSUBSTSEL rewrite)) x)\\
\tab \tab (LETARGSEL \_A (FAIL (The formula you selected (\_A) is not a proper subformula)))\\
\tab \tab (FAIL (Please text-select an expression))


\textsc{Letsubstsel} checks that the user has selected some instance or instances of a sub-formula which describe a substitution, and if so \textsc{withsubstsel} applies \textit{rewrite} to the user's selection; finally the argument tactic \textit{x} is applied to the first antecedent of the rewrite (the $X=Y$ antecedent). The \textsc{layout} tactical says in its second argument that only antecedent 1 of the rewrite step -- that is, the right-hand antecedent -- should be shown (antecedents are numbered 0, 1,...); the first argument says that it should be shown with a text which starts with Fold\footnote{A backwards step of unfolding is a folding step when read forwards. Proofs in this encoding are made backwards but read forwards: we have labelled our buttons and named our tactics in the backward sense, but the labels on the proofs, which are inserted by \textsc{layout} and the Fold/Unfold with hypothesis rules, are written in the forward sense.} and continues with a summary of the hidden subtree. The rest of the code tries to explain what has gone wrong if the user mis-applies the tactic\footnote{The attempt to analyse errors in the application of this tactic, using \textsc{letsubstsel} and \textsc{letargsel} to pick out different cases, doesn't really work. To do a proper job, the tactic would to distinguish between at least these possibilities:

{\textbullet}\tab the subformulae you select aren't identical; {\textbullet}\tab they don't all come from the same formula; {\textbullet}\tab one or more of them isn't a proper subformula; {\textbullet}\tab you didn't select anything at all.}

\tab In practice the tactic's error message is often inappropriate, but we show it as it is in order to illustrate the difficulty.


Here is an example proof using our encoding, after two steps:

\begin{figure}[htbp] \begin{center} \includegraphics[width=2.056in, height=1.194in]{oldpics/Roll_your_own_v3_2+Fig38} \caption{Fig38} \end{center} \end{figure}


Lines 1, 2 and 3 can be read as a partly-completed linear equational proof, up the left-hand side and down the right:

(\textit{rev {\textbullet} rev}) \textit{x}\tab = \textit{rev}(\textit{rev} \textit{x})\tab by \textit{(f {\textbullet} g}) \textit{x} = \textit{f}(\textit{g x})\\
= \textit{x}\tab by...\\
= \textit{id x}\tab by \textit{id x} = \textit{x}


Layout only hides antecedents, it doesn't destroy them: by double-clicking on the justification of line 2 or line 3 the hidden detail can be revealed. Here is what you see if you double-click on line 3:

\begin{figure}[htbp] \begin{center} \includegraphics[width=2.861in, height=1.389in]{oldpics/Roll_your_own_v3_2+Fig39} \caption{Fig39} \end{center} \end{figure}


\textbf{5.4\tab Selecting a subformula: lethypfind, letconcfind, assoceq and flatten}


Letsubstsel and withsubstsel don't solve all the problems of rewriting, because Jape has a very simple-minded treatment of subformula selection. It provides only character-sequence selection, and the user can select any sub-sequence of the characters which make up a formula. It is possible to select a section of text which isn't a formula at all -- $a+b)$, for example, in $x+(a+b)$ . Worse, it is possible to select text which is a formula but not a proper subformula -- $x+y$, for example, in $f\;x+y$ . There are well-known user-interface solutions to this problem, exploiting the syntactic structure of a formula to guide selection, but we haven't implemented any of them. The reason is partly lack of effort, but we have our eyes on a higher prize: we want eventually to include a proper treatment of subformula selection in logics which include associative operators: those which, like + and \ensuremath{\times} in school algebra, don't need to be bracketed when they occur in sequence.


The problem begins when a formula is input. In Jape's treatment of syntax, just as in any ordinary programming-language compiler, binary operators have relative priorities (or precedences) and an formula such as $A\times B+C$, where \ensuremath{\times} has higher priority than +, is treated internally just like $(A\times B)+C$ but displayed in its unbracketed form\footnote{Jape tries to keep the user's bracketing structure. If the input is bracketed, so will be the display.}. Since we treat all operators as either binary or unary, Jape has to be told, faced with the formula

$A+B+C$, whether to read it left-associatively as $(A+B)+C$ or right-associatively as $A+(B+C)$ . Whichever you tell it, it will display the result unbracketed as $A+B+C$, and then inevitably some textual segment -- $B+C$ in the left-associative case, $A+B$ in the right-associative -- can be read as a formula even though it is not a structural subformula of the whole.


We might hope to tell Jape that the operator + is neither left- nor right-associative but \textit{associative} in the mathematical sense, so that $A+B+C$ should be read at will as either $(A+B)+C$ or $A+(B+C)$ as circumstances dictate -- and then you can imagine that it ought to be possible to tell it that + is commutative as well, so that $A+B+C$ can be read as $(A+C)+B$ if that is what you wish. We intend that a future version of Jape will incorporate a more seamless syntactic treatment of associative and commutative operators that will allow some of these alternative readings, based on the mechanisms which already underly our treatment of bags and lists in sequents. For the time being we provide support for the explicit manipulation of associative operators in the tactic language.


Our treatment is based on the principle that a formula whose operator is associative can be rewritten in a canonical form, and we provide means to access an internal mechanism of Jape which converts formulae to their canonical form via the built-in judgement assoceq(\textit{formula1}, \textit{formula2}) and the tactic flatten \textit{formula}.


The first problem is to convert a formula so that the selected text is a proper sub-formula. For example, consider the following proof-in-progress of one of the conjectures from functions.jt:

\begin{figure}[htbp] \begin{center} \includegraphics[width=3.472in, height=1.222in]{oldpics/Roll_your_own_v3_2+Fig40} \caption{Fig40} \end{center} \end{figure}


Next we want to use the second assumed equality, to replace $HF$ with $HG$ . But the {\textbullet} operator in this encoding is left-associative, and to make the step we must first change the structure of the conclusion formula on line 2, changing its structure from the left-associative form $(JH)F=G$ into $J(HF)=G$ . The step won't work unless there is a proof that {\textbullet} is associative -- i.e. unless a conjecture with the form $(FG)H=F(GH)$ or one with the form $F(GH)=(FG)H$ exists and is either proved or can be assumed proved because `apply conjectures and theorems' is ticked in the Edit menu.


We text-select $HF$ and apply Find from the Rules menu\footnote{Or from either of the panels -- one of us doesn't think that this is good GUI / HCI practice, but the other one made the encoding.}to alter the structure of the formula:

\begin{figure}[htbp] \begin{center} \includegraphics[width=3.472in, height=1.472in]{oldpics/Roll_your_own_v3_2+Fig41} \caption{Fig41} \end{center} \end{figure}


Now the $HF=HG$ equality can be used:

\begin{figure}[htbp] \begin{center} \includegraphics[width=3.472in, height=1.722in]{oldpics/Roll_your_own_v3_2+Fig42} \caption{Fig42} \end{center} \end{figure}


Now we would like to apply the first assumption again, but $JH$ isn't a textual subformula as the formula is written, so we have first to modify the conclusion. Flatten from the Rules menu does the trick:

\begin{figure}[htbp] \begin{center} \includegraphics[width=3.472in, height=1.972in]{oldpics/Roll_your_own_v3_2+Fig43} \caption{Fig43} \end{center} \end{figure}


The rest of the proof is straightforward. It remains to explain how all this is done.


The lethypfind and letconcfind tacticals allow the user to rebracket a formula. lethypfind (\textit{old},\textit{new}) \textit{tactic... tactic} succeeds if


{\textbullet}\tab the user has made a single text-selection in a hypothesis formula, dividing it in effect into \textit{before}, \textit{middle} and \textit{after} texts;


{\textbullet}\tab the hypothesis formula unifies with the pattern \textit{old};


{\textbullet}\tab \textit{middle} is a valid formula\footnote{Maybe we don't need this condition, but it would be very odd not to impose it.};


{\textbullet}\tab the text \textit{before} ( \textit{middle} ) \textit{after} is a valid formula and unifies with \textit{new};\\
{\textbullet}\tab the sequence \textit{tactic... tactic} succeeds in the context produced by those unifications.


(letconcfind is similar, but demands a selection in a conclusion formula.) The tactical succeeds silently, without running \textit{tactic... tactic}, if \textit{before} ( \textit{middle} ) \textit{after} turns out to be structurally equal to the original unmodified formula -- a test which does not call upon information about associativity. So lethypfind and letconcfind match, and run their argument tactics, if your text selection reorganises the structure of the formula.


In functions\_menus.j an entry is put in the Rules menu, and an associated tactic is defined:

MENU Rules IS\\
\tab ENTRY\tab "Find" \tab IS FindSelection\\
\tab ...

TACTIC FindSelection IS\\
\tab WHEN\tab (LETHYPFIND (\_XOLD=\_YOLD, \_XNEW=\_YNEW)\\
\tab \tab \tab (ALT\tab (LAYOUT "Associativity" (2)\\
\tab \tab \tab \tab \tab (rewriteHypotheticalEquation \_XOLD \_XNEW \_YOLD \_YNEW) \\
\tab \tab \tab \tab \tab EVALUATE EVALUATE\\
\tab \tab \tab \tab )\\
\tab \tab \tab \tab (LETARGSEL \_XSEL (FAIL ("\%s isn't a subterm", \_XSEL)))\\
\tab \tab \tab )\\
\tab \tab )\\
\tab \tab (LETCONCFIND (\_XOLD=\_YOLD, \_XNEW=\_YNEW)\\
\tab \tab \tab (ALT\tab (LAYOUT "Associativity" (2)\\
\tab \tab \tab \tab \tab (rewriteEquation \_XOLD \_XNEW \_YOLD \_YNEW) \\
\tab \tab \tab \tab \tab EVALUATE EVALUATE\\
\tab \tab \tab \tab )\\
\tab \tab \tab \tab (LETARGSEL \_XSEL (FAIL ("\%s isn't a subterm", \_XSEL)))\\
\tab \tab \tab )\\
\tab \tab )


The FindSelection tactic calls either rewriteHypotheticalEquation or rewriteEquation: those rules are\footnote{The fact that FindSelection splits the selected formula into two, and the rules pick up that split, is an artefact of the way that assoceq is currently implemented; we will fix the problem Real Soon Now. The existence of two rewrite rules, rather than a single one plus a tactic that can use cut, is because the encoder doesn't want the kind of ugly trees that result from that kind of simulated forward reasoning.}

RULE rewriteEquation(X, X', Y, Y', OBJECT x) IS\\
\tab FROM ASSOCEQ (X, X') AND ASSOCEQ (Y, Y') AND X'=Y' INFER X=Y\\
RULE rewriteHypotheticalEquation(X, X', Y, Y', OBJECT x) IS\\
\tab FROM ASSOCEQ (X, X') AND ASSOCEQ (Y, Y') AND X'=Y'⊦ P INFER X=Y ⊦ P


The built-in assoceq judgement flattens its arguments, using any relevant theorems / rules about associativity. Each of these rules therefore replaces an equation with a provably equivalent equation. The evaluate tactic interprets the judgement; the use of layout in FindSelection hides this internal working and gives Associativity as the justification for the step.


The reverse operation is provided by the flatten tactic. The menu entry indexes the Flatten tactic (see equality\_menus.j)

TACTIC Flatten IS\\
\tab LAYOUT "Associativity" (0)\\
\tab \tab (WHEN\tab (LETARGSEL \_A (FLATTEN \_A))\\
\tab \tab \tab \tab (LETGOAL (\_X = \_Y) (IF(FLATTEN(\_X))) (IF(FLATTEN(\_Y)))) \\
\tab \tab \tab \tab (LETGOAL \_X (FAIL (Cannot Flatten \_X)))\\
\tab \tab )


This tactic gives the same justification as FindSelection; via flatten it accesses the same machinery. The argument to flatten is used to determine the principal operator of the formula to be flattened; subformulae of which that is the operator alone are flattened\footnote{This is the reason that, at present, the FindSelection mechanism splits the formula to which it is matched. It's a bug in our existing mechanism, which will be fixed.}.


The effect of all this machinery is to enable the user to manipulate formulae which use associative operators without too many uses of associative rewrite laws.


\textbf{5.5\tab Induction in Jape}


Jape makes no special treatment of induction. It is handled in the same way as any other logical generalisation rule, using the fresh proviso. We encode a form of list induction which uses concatenation rather than \textit{cons}\footnote{Definining lists with concatentation rather than \textit{cons} has advantages, in particular the fact that it doesn't favour either end of a list when making a reduction. It has difficulties, but it is valid. The sceptics (Richard is ashamed to admit that he was once one of them!) should note that you can derive this rule from the more familiar \textit{cons} version. As for evaluation strategies, or function definition by concatenation, that's a different story!}:


$\frac{\Gamma  |- A[\,]\quad \Gamma  |- A[x]\quad \Gamma,A\left( xs\right),A\left( ys\right)  |- A\left( xs{}+{}+{}ys\right) }{\Gamma  |- A\left( B\right) } \;(\,x,xs,ys)$

We have collapsed into one step that which usually takes two (by an induction principle prove \ensuremath{\forall}\textit{x}.\textit{A}(\textit{x}); then infer \textit{A}(\textit{B}) by specialisation). There is no need to introduce quantification into equational reasoning, and our one-step rule is perfectly convenient. We encode it directly:

RULE listinduction (B, OBJECT x, OBJECT xs, OBJECT ys, ABSTRACTION A) \\
\tab WHERE FRESH x, xs, ys IS\\
\tab \tab FROM A[ ] AND A[x] AND A xs, A ys ⊦ A(xs++ys) INFER A(B)


Sometimes you will want to make a proof by induction of a proposition which is expressed in terms of some variable or other, and then you would want induction to apply to every instance of that variable. Other times you may want to be more precise in specifying just what instances of what sub-formula are to be the basis of induction, and so we require the user to specify those instances. We could allow both mechanisms, activated by different entries in a menu, but we have instead required our users always to select the particular instances of a subformula which they wish to be the subject of induction. The entry in the menu which gives the user access to the list induction principle connects to a tactic which uses the letsubstsel/withsubstsel mechanism:

TACTIC "list induction tactic" IS \\
\tab WHEN\tab (LETSUBSTSEL \_A (WITHSUBSTSEL listinduction))\\
\tab \tab (FAIL(Please select a sub-formula on which to perform induction))


\textbf{5.6\tab Controlling collections of rules}


One of the problems of reasoning in functional programming, as we have set it up in this encoding, is that each function definition corresponds to a number of individual statements of equality. The definition of \textit{map}, for example, gives three:


$ \begin{array}{l} map\,f\,[]=[] \\
map\,f\,[x]=f\,x \\
map\,f\,(xs{}+{}+{}ys)=map\,f\,xs{}+{}+{}map\,f\,ys \end{array} $

It would be tedious to be required to give a name to each individual equality, and in any case we expect our users to be happy to refer to them as a collection -- `use one of the \textit{map} equalities', rather than `use the \textit{map} equality which applies to singletons'.


The rules directive allows us to make and name collections of rules. If we turn all the function definitions into collections of rules we can use them, with some instantiation of their variables, to close the left-hand antecedent of a \textit{rewrite} rule application or to close a tip of a proof tree in the normal way. The definition of \textit{map}, for example, goes as follows:

RULES map\\
\tab ARE map F [ ]\tab = [ ]\\
\tab AND map F [X]\tab = [F X]\\
\tab AND map F (Xs++Ys)\tab = map F Xs ++ map F Ys\\
END


This generates three rules, called \textit{map'0}, \textit{map'1} and \textit{map'2}, plus a tactic \textit{map}:

TACTIC map IS ALT map'0 map'1 map'2


In addition, for control of searching of our collections of rules, we group them into collections called `theories'. Part of the \textit{List} theory, for example, as it is given in functions\_rules.j is

THEORY List IS\\
\tab RULES length \\
\tab ...\\
\tab RULE\tab none \tab IS none X\tab = [ ]\\
\tab RULE\tab one\tab IS one X\tab = [X]\\
\tab RULE\tab cat\tab IS cat = fold (++) []\\
\tab RULES rev\\
\tab ...\\
\tab RULES ++\\
\tab ...\\
\tab RULES map\\
\tab ...\\
\tab RULE filter IS filter P = cat {\textbullet} map (if P (one, none))\\
\tab RULES zip\\
\tab ...\\
\tab RULES fold \\
\tab ...\\
\tab RULE rev2 IS rev2 = fold rcat [] {\textbullet} map one\\
\tab RULE rcat IS rcat Xs Ys = Ys ++ Xs\\
\tab RULE ":" IS X:Xs = [X] ++ Xs\\
END


The effect of theory is to define all the rules and tactics described by its components, plus a tactic which allows search of those components. In this case the tactic is

TACTIC List IS ALT length none rev (++) map filter zip fold rev2 rcat (:)


We put the rule-collections -- but not the theory-collections -- into a panel of definitions. The panel is described in functions\_menus.j as

TACTICNANEL "Definitions" \\
\tab TACTIC "Use any rule enabled by Searching" IS SearchTactic\\
\tab ENTRY\tab ":"\\
\tab ENTRY\tab "{\textbullet}"\tab  \\
\tab ENTRY\tab "$\times$"\tab  \\
\tab ENTRY\tab "\ensuremath{^a}"\tab  \\
\tab ...\\
\tab BUTTON\tab "Unfold *"\tab IS apply RepeatedlyUnfold\\
\tab PREFIXBUTTON\tab "Unfold"\tab IS apply UnfoldObvious\\
\tab PREFIXBUTTON\tab "Fold"\tab IS apply FoldObvious\\
\tab PREFIXBUTTON\tab "Apply"\tab IS apply\\
\tab BUTTON\tab "Flatten"\tab IS apply Flatten\\
\tab BUTTON\tab "Find"\tab IS apply FindSelection\\
END


The effect, on the Macintosh, is a panel which looks like this:

\begin{figure}[htbp] \begin{center} \includegraphics[width=2.778in, height=6.042in]{oldpics/Roll_your_own_v3_2+Fig44} \caption{Fig44} \end{center} \end{figure}


We discuss the effect of the tactics bound to the buttons and entries below.


\textbf{5.7\tab Searching collections of rules and theorems: the fold and unfold tacticals}


It's quite possible, using the Unfold and Fold buttons on the Definitions panel, plus the Unfold with hypothesis and Fold with hypothesis entries in the Rules menu, to construct proofs entirely by hand -- selecting the subformula to be replaced, the definition or hypothesis to be used, pressing the appropriate button or choosing the appropriate menu entry. But it's also quite easy to program Jape to do a sort of evaluation step. This involves identifying helpful equations (in the form of rules or theorems) which can be used to rewrite part of the conclusion of the problem sequent.


Jape has a number of built-in mechanisms which help with the process. The alt tactical allows an undirected search amongst a number of possibly-applicable tactics, and we have illustrated above how the rules and theory directives automatically construct alts which may be useful in searching for a proof. But in equational reasoning the problem is somewhat different: we are looking for a subformula which is replaceable and a definition or hypothesis which matches it; alt is not sufficient to do the job.


In the future Jape will support such searching by a mechanism based on mapping tactics over a list of subformulae of a formula. For the moment our support is more ad-hoc: although based on the same principles, it is closely adapted to the particular problem of equational rewriting.


Jape's support for search in equational reasoning is at present the fold, unfold, foldhyp and unfoldhyp tacticals. The fold and unfold tacticals take a rewrite rule and an alt tactic, which is treated as a collection of rules. They filter the rules to consider only those whose consequents have a conclusion of the form \textit{L op R} for some formulae \textit{L} and \textit{R} and a binary operator \textit{op}\footnote{The rules -- actually rules and theorems -- are doubly filtered because we eliminate all unproved conjectures unless the applyconjectures variable is set to true.}; they search for subformulae of the conclusion of the problem sequent which match the \textit{R} (fold) or \textit{L} (unfold) of one of the rules, and when they find a coincidence try to apply the rewrite rule followed by the matching filtered rule. Foldhyp and unfoldhyp are similar, except that they take a pattern which allows the user to define \textit{op}, and they search the list of hypotheses rather than a collection of rules.


However ad-hoc, these techniques are fast and they work well. In this encoding our rules are such that automatic folding is little use: too many equalities have right-hand sides which are similar, and searching with alt for a match rarely finds a useful one. But automatic unfolding can often be fruitful: if there is a subformula which matches \textit{map} \textit{F} (\textit{Xs}++\textit{Ys}), for example, then unfolding with the rule \textit{map F} (\textit{Xs}++\textit{Ys}) = \textit{map F Xs}++ \textit{map F Ys} is probably worthwhile.


Our search mechanism, then, is based on the tactic

TACTIC Unfold(x) IS LAYOUT "Fold \%s" (1) (UNFOLD rewrite x)


which is given an alt tactic \textit{x} and which searches for (backwards) unfold actions which it can carry out by rewriting with the rules within \textit{x}.


The magic by no means stops with the unfold tactical, because we also use the collections of theories to control the search. The idea is that you should be able to `turn on and off' the definitions and theorems in particular theories when searching. Because the variable-processing facilities of Japeish are still in their infancy, we have done this in the most naive way possible, using radiobuttons in a special Searching menu\footnote{These controls would have been easier to use if they had been simple checkboxes, but at present Jape can't make much use of the values of variables during tactics. This will be remedied soon.}.


We have grouped the equality rules into three theories: List (illustrated above), Functions and Reflect. We have grouped conjectures into collections, some of which we are prepared to search. Here, for example, is the Listthms collection:

THEOREMS ListThms\\
ARE\tab rev {\textbullet} rev\tab = id\\
AND\tab rev2\tab  = rev\\
AND\tab map F {\textbullet} map G\tab = map (F {\textbullet} G)\\
AND\tab map F {\textbullet} cat\tab = cat {\textbullet} (map (map F))\\
AND\tab none {\textbullet} F\tab = none\\
AND\tab map F {\textbullet} none\tab = none\\
AND\tab map F {\textbullet} one\tab = one {\textbullet} F\\
AND\tab map F {\textbullet} rev\tab = rev {\textbullet} map F\\
AND\tab map id\tab = id\\
AND\tab length{\textbullet}map F\tab = length\\
AND\tab zip {\textbullet} (map F \ensuremath{^a} map G)\tab = map (F\ensuremath{^a}G)\\
AND\tab map F {\textbullet} if P (G,G')\tab = if P (map F {\textbullet} G, map F {\textbullet} G')\\
AND\tab filter P\tab = map fst {\textbullet} filter snd {\textbullet} zip {\textbullet} (id \ensuremath{^a} map P)\\
END


These, once proved, can be searched when automatically unfolding equalities; they can even be searched before they are proved, if applyconjectures is set to true.


Our basic technique at present\footnote{This paragraph reflects a temporary hack to get around the fact that Jape doesn't yet have any analogue of the ML \textit{case} expression, which we can use to direct the activity of a tactic according to the value of a variable. It probably took longer to type this footnote than to implement the mechanism -- but the manual must come first!} is to use variables each of which is set to the name of a theory if we want to search that theory, or to the name of a tactic which is certain to fail, if we don't want to search it. The justfail tactic is

TACTIC JUSTFAIL IS (ALT)


and the Searching menu is

MENU "Searching" IS\\
\tab RADIOBUTTON dohyp IS \\
\tab "Search hypotheses" IS DoHyp\\
\tab AND "Ignore hypotheses" IS JUSTFAIL\\
\tab INITIALLY DoHyp\\
\tab END

\tab RADIOBUTTON list IS \\
\tab "List rules enabled" IS List\\
\tab AND\tab  "List rules disabled" IS JUSTFAIL\\
\tab INITIALLY List\\
\tab END

\tab  END


On the Macintosh this produces a menu

\begin{figure}[htbp] \begin{center} \includegraphics[width=2.958in, height=4.750in]{oldpics/Roll_your_own_v3_2+Fig45} \caption{Fig45} \end{center} \end{figure}


The auto tactic is set up either to unfold or to fold -- though for the reasons given above, we never actually use it for folding -- and is defined as

TACTIC Auto(foldunfold, foldunfoldhyp) IS \\
ALT\tab (dohyp foldunfoldhyp)\\
\tab (foldunfold list) \\
\tab (foldunfold listthms) \\
\tab (foldunfold function) \\
\tab (foldunfold functionthms) \\
\tab (foldunfold reflect ) \\
\tab (foldunfold reflectthms)\\
\tab (FAIL (Cannot find anything to foldunfold) )


It's called from the Unfold * button with the tactic

SEQ\tab (Auto Unfold UnfoldWithAnyHyp) \\
\tab (DO (Auto Unfold UnfoldWithAnyHyp))


-- since do always silently succeeds, we wanted to make the button fail noisily if there was nothing at all that it could do; hence the double invocation of the tactic.


We use the same tactic -- but only singly, without repetition -- if you double-click on a conclusion:

CONCHIT C IS Auto Unfold UnfoldWIthAnyHyp


The remaining parts of this jigsaw are the UnfoldWithAnyHyp tactic

TACTIC UnfoldWithAnyHyp IS UNFOLDHYP "Fold with hypothesis" (\_A=\_B)


and the Fold/Unfold with hypothesis pair of rules:

RULE "Fold with hypothesis" (X, OBJECT x)\tab IS FROM X=Y ⊦ AA[x{\textbackslash}Y] INFER X=Y ⊦ AA[x{\textbackslash}X]\\
RULE "Unfold with hypothesis" (Y,OBJECT x)\tab IS FROM X=Y ⊦ AA[x{\textbackslash}X] INFER X=Y ⊦ AA[x{\textbackslash}Y]


These rules are named for forward reading, so the menu entries which enable them to be used by hand have to be contrariwise.


All of the other techniques that we have used are discussed in earlier chapters.



\chapter{Encoding axiomatic set theory}


The treatment of equational reasoning in the previous chapter introduced the ways in which Jape can hide parts of a proof and use substitution to achieve replacement of subformulae with rewrite rules. This chapter shows how the same techniques can be used to support the encoding of a very naive version of axiomatic set theory, which uses rewriting to support equality-style reasoning in both forward and backward steps. Our treatment was inspired by that of David Schmidt (``Natural Deduction Theorem Proving in Set Theory'', CSR-142-83, Edinburgh).


The encoding presents four distinct things to the user: an encoding of natural deduction, as a menu of commands; an menu of rewrite actions; a menu of set-theoretic inference rules; and a panel of axioms expressed as definitions \textit{formula} \~{} \textit{formula}, equipped with buttons which allow those definitions to be used as left-to-right or right-to-left rewrite rules. In addition there's a menu of conjectures equipped with buttons which allow the user to exploit proved theorems as rewrite rules.\\
This is the most ambitious use of Japeish so far to produce a slick on-screen encoding with a lot of different -- but easy to use -- facilities. We may have gone too far with some of the user interface tricks we have used, and the encoding can hardly be described as `transparent'. The tactic programming is, indeed, at times rather subtle. We expect, as we learn from this and other examples under development, to be able to generalise and therefore simplify it.


\textbf{6.1\tab The natural deduction encoding}


This is contained in the files BnE-Fprime.jt and the files that it invokes; it is derived from the logic $F' $ in ``The Language of First-Order Logic'' by Barwise and Etchemendy. It is very similar to the encoding described in chapter 4 above, with the addition of rules for a bi-implication operator, a falsity constant, equality, and a unique-existence operator:\\


\begin{tabular}{llllll} \hline
% ROW 1
\multicolumn{1}{|p{1.408in}|} {\raggedright

$\infer[\reason{$<->-I$}]
       {\Gamma  |- A<->B}
       {\Gamma,A |- B\quad \Gamma,B |- A}$ } & \multicolumn{1}{p{1.477in}|} {\raggedright

$\infer[\reason{$<->-E(L)$}]
       {\Gamma  |- A}
       {\Gamma  |- B\quad \Gamma  |- A<->B}$ } & \multicolumn{1}{p{1.467in}|} {\raggedright

$\infer[\reason{$<->-E(R)$}]
       {\Gamma  |- B}
       {\Gamma  |- A\quad \Gamma  |- A<->B}$ }\\
\hline
% ROW 2
\multicolumn{1}{p{0.049in}|} {\raggedright

$\infer[\reason{$\bot -I$}]
       {\Gamma  |- \bot }
       {\Gamma  |- P\quad \Gamma  |- !P}$ } & \multicolumn{1}{p{0.049in}|} {\raggedright

$\infer[\reason{$\bot -E$}]
       {\Gamma  |- P}
       {\Gamma  |- \bot }$ } & \multicolumn{1}{p{0.049in}|} {\raggedright

$\infer[\reason{$A=A$}]
       {\Gamma  |- A=A}
       {}$ }\\
\hline
% ROW 3
\multicolumn{1}{|p{1.408in}|} {\raggedright

$\infer[\reason{$(\,c,\;c |- B)\;|*!-E$}]
       {\Gamma  |-|*!x.A}
       {\Gamma  |- A[x\backslash B]\quad \Gamma,A\lbrack x\backslash c] |- B=c}$ } & \multicolumn{1}{p{1.477in}|} {\raggedright

$\infer[\reason{$|*!-E$}]
       {\Gamma  |-|*x.A}
       {\Gamma  |-|*!x.A}$ }\\
\hline \end{tabular}


plus a pair of rewrite rules for each of the bi-implication and equality operators:\\


\begin{tabular}{|p{2.202in}|p{2.202in}|p{0.048in}|p{0.048in}|} \hline
% ROW 1
{\raggedright $\infer[\reason{$rewrite\,<->\,$}]
       {\Gamma  |- P[v\backslash A]}
       {\Gamma  |- A<->B\quad \Gamma  |- P\lbrack v\backslash B]}$ } & {\raggedright $\infer[\reason{$rewrite\,<->\,$}]
       {\Gamma  |- P[v\backslash B]}
       {\Gamma  |- A<->B\quad \Gamma  |- P\lbrack v\backslash A]}$ }\\
\hline
% ROW 2
{\raggedright $\infer[\reason{$rewrite\,=\,$}]
       {\Gamma |- P[v\backslash A]}
       {\Gamma  |- A=B\quad \Gamma  |- P[v\backslash B]}$ } & {\raggedright $\infer[\reason{$rewrite\,=\,$}]
       {\Gamma |- P[v\backslash B]}
       {\Gamma  |- A=B\quad \Gamma  |- P[v\backslash A]}$ }\\
\hline \end{tabular}


These are encoded, completely straightforwardly, in the file BnE-Fprime\_rules.j.


The rules are inserted into the menu as

MENU "System F'" IS\\
\tab ENTRY "→-I"\tab \\
\tab ENTRY "\'{I}-I"\\
\tab ENTRY "∧-I"\tab \\
\tab ENTRY "∧-I(L)" IS FOB ForwardCut "∧-I(L)"\\
\tab ENTRY "∧-I(R)" IS FOB ForwardCut "∧-I(R)"\\
\tab ENTRY "¬-I"\\
\tab ENTRY "\"{Y}-I"\\
\tab ENTRY "∀-I"\\
\tab ENTRY "∃-I"

\tab SEPARATOR

\tab ENTRY "→-E"\tab \tab IS FOB "→-E forward" "→-E" \\
\tab ENTRY "\'{I}-E(L)"\tab IS FOB "\'{I}-E(L) forward" "\'{I}-E(L)" \\
\tab ENTRY "\'{I}-E(R)"\tab IS FOB "\'{I}-E(R) forward" "\'{I}-E(R)" \\
\tab ENTRY "∧-E(L)"\tab IS FOB ForwardCut "∧-E(L)"\\
\tab ENTRY "∧-E(R)" \tab IS FOB ForwardCut "∧-E(R)"\\
\tab ENTRY "∧-E"\tab \tab IS FOB ForwardUncut "∧-E"\tab \\
\tab ENTRY "¬-E"\tab \tab IS FOB ForwardCut "¬-E"\tab \\
\tab ENTRY "\"{Y}-E"\tab \tab IS FOB ForwardCut "\"{Y}-E"\tab \\
\tab ENTRY "∀-E"\tab \tab IS FOBSS ForwardCut "∀-E"\tab \\
\tab ENTRY "∃-E"\tab \tab IS FOB ForwardUncut "∃-E"

\tab SEPARATOR

\tab ENTRY "A=A"\\
\tab ENTRY hyp\\
END


Here fob is essentially the tactic ForwardOrBackward of chapter 4, ForwardCut and ForwardUncut are also as described in chapter 4, and the entries for bi-implication use the tactics

TACTIC "\'{I}-E(L) forward"(Z) IS "\'{I}-E forward" "\'{I}-E(L)"\\
TACTIC "\'{I}-E(R) forward"(Z) IS "\'{I}-E forward" "\'{I}-E(R)"

TACTIC "\'{I}-E forward"(rule) IS\\
\tab WHEN\tab (LETHYP (\_A\'{I}\_B) (ForwardCut2 rule))\\
\tab \tab (LETHYP \_A (ForwardCut rule))\\
\tab \tab (JAPE(fail(what's this in rule forward?)))


Using the rewrite rules is, as we have seen in chapter 5, a little more complicated. The Substitution menu is

MENU "Substitution"\\
\tab ENTRY "A$<->$\dots "\tab IS ForwardSubst "rewrite $<->$ $\ll$" "rewrite $<->$ $\gg$" ($<->$)\\
\tab ENTRY "\dots $<->$B"\tab IS ForwardSubst "rewrite $<->$ $\gg$" "rewrite $<->$ $\ll$" ($<->$)\\
\tab ENTRY "A=\dots "\tab IS ForwardSubst "rewrite = $\ll$" "rewrite = $\gg$" (=)\\
\tab ENTRY "\dots =B"\tab IS ForwardSubst "rewrite = $\gg$" "rewrite = $\ll$" (=)\\
END


The ForwardSubst tactic extends the techniques of chapter 5 to allow rewriting in forward as well as backward reasoning style. We require that the user must text-select some subformula and also may select a hypothesis which is to be used as \textit{A}=\textit{B} or \textit{A}\ensuremath{\leftrightarrow}\textit{B} in the rule. The tactic is rather subtle\footnote{Perhaps, at this point, you might begin to wonder whether the complexity of our tactic programming doesn't undermine the claim that Jape is simple and easy to program. Our answer is twofold: first, this is work in progress, it is much simpler than it used to be, and that we are still working on it. But second, we now realise that while encoding the rules of a logic in Jape and arranging them in menus is straightforward and transparent, the work required to hide parts of proofs or to achieve concise effects by hiding gestures is programming, and programming is always potentially intricate.}: it's given a left-to-right rewrite rule \textit{ruleLR}, a right-to-left rewrite rule \textit{ruleRL}, and a pattern \textit{pat} which it uses in error alerts. Note how the menu entries alternate the use of the rewrite rules to get the correct rewriting effect when working either forward or backwards.

TACTIC ForwardSubst (ruleLR, ruleRL,pat) IS\\
\tab WHEN\tab (LETHYPSUBSTSEL \_P \\
\tab \tab \tab cut\\
\tab \tab \tab ruleRL \\
\tab \tab \tab (WHEN\tab (LETHYP \_Q \\
\tab \tab \tab \tab \tab (ALT\tab (WITHHYPSEL hyp) \\
\tab \tab \tab \tab \tab \tab (FAIL (the hypothesis you formula-selected wasn't a pat formula))))\\
\tab \tab \tab \tab (JAPE (SUBGOAL 1))) \\
\tab \tab \tab (WITHSUBSTSEL hyp))\\
\tab \tab (LETCONCSUBSTSEL \_P\\
\tab \tab \tab (WITHSUBSTSEL ruleLR)\\
\tab \tab \tab (WHEN\tab (LETHYP\_Q \\
\tab \tab \tab \tab \tab (ALT\tab (WITHHYPSEL hyp) \\
\tab \tab \tab \tab \tab \tab (FAIL(the hypothesis you formula-selected wasn't a pat formula))))\\
\tab \tab \tab \tab SKIP))\\
\tab \tab (JAPE (fail(please text-select one or more instances of a sub-formula to replace)))


lethypsubstsel \textit{pattern tactic...} succeeds when the user's text-selections describe a substitution in a hypothesis (left-hand side) formula; letconcsubstsel succeeds when they describe a substitution in a conclusion (right-hand side) formula.\\
Working backwards with letconcsubstsel the tactic is fairly straightforward: it applies ruleLR (one of the argument rewrite rules) on the substution formula that the user has defined, and then, if the user has selected a hypothesis, tries to unify it with the conclusion of the first antecedent of the rewrite.


Working forwards it does a \textit{cut} and then applies ruleRL (the other rewrite rule, which will do its work in the opposite direction to ruleLR) and then either applies the user's selected hypothesis (alt...) or skips the first antecedent (jape(subgoal 1)) and then does withsubstsel \textit{hyp}, which uses the user's original text-selection to construct a substitution in the current problem sequent, and also does an automatic withhypsel on it, so that the \textit{hyp} is bound to make use of that hypothesis\footnote{It seems reasonable that withsubstsel should include an automatic withhyp/withconcsel, because if the newly-constructed hypothesis isn't to be used, why was it constructed?}. The automatic withhypsel enables us, as in this example, to distinguish between two selected hypotheses: the one selected for application as an equality, and the one text-selected for rewriting.


\textbf{6.2\tab Syntax of set operations}


Apart from the various operators, which have been encoded in the obvious way, the only important syntactic feature of this encoding is the treatment of set abstractions. Jape's parser-generator isn't very sophisticated at present, so we have made some drastic simplifications.\\
The form of a set abstraction, in this encoding, is \{ \textit{variable} {\textbar} \textit{formula} \}, and the occurrence of the variable to the left of the bar is a binding occurrence; we also allow \{ \texttt{<}\textit{variable},\textit{variable}\texttt{>} {\textbar} \textit{formula} \}. We include, therefore, in set\_syntax.j

CLASS VARIABLE u v w\\
CONSTANT {\O} \"{Y} U EQ

PREFIX\tab 1000\tab Pow\\
PREFIX\tab 800\tab \^{O}\^{O} flfl\\
POSTFIX\tab 800\tab \={}\\
INFIX\tab 700L\tab \^{O} fl -\\
INFIX\tab 720L\tab {\textbullet}\\
INFIX\tab 740L\tab $\times$\\
INFIX\tab 600L\tab {\ss}\\
INFIX\tab 500L\tab / ¬/\\
OUTFIX \texttt{<} \texttt{>}\\
OUTFIX \{ {\textbar} \}

BIND y SCOPE P IN \{ y {\textbar} P \}\\
BIND x y SCOPE P IN \{ \texttt{<}x,y\texttt{>} {\textbar} P \}


The priority numbers chosen are higher than the priority of any operator in BnE-Fprime\_syntax.j, and otherwise have no particular significance. We misuse the linear logic \={} symbol as our representation of set negation, but we do use it as a postfix operator\footnote{Putting a smiley face here, in Windings font, adds about 300k bytes to the PostScript version of this file. Consider yourself smiled at.}.


Given the outfix and bind directives above, together with the standard interpretation of comma as a zero-priority associative operator, we allow the following as formulae:

\{\}\tab which we interpret as the empty set;\\
\{ \textit{formula} \}\tab which we interpret as a singleton set;\\
\{ \textit{formula},..., \textit{formula} \}\tab which we interpret as a literal description of a set;\\
\{ \textit{variable} {\textbar} \textit{formula} \}\tab which we interpret as a set abstraction;\\
\{ \texttt{<}\textit{variable}, \textit{variable}\texttt{>} {\textbar} \textit{formula} \}\tab which we interpret as a set abstraction, a set of pairs.


Allowing set brackets with and without the vertical bar is a trick of which we are slightly ashamed. In future we hope that these shapes of formulae, and more, will be recognised by a more principled parser.


\textbf{6.3\tab The axiomatic presentation of naive set theory}


We first observe, just to get it out of the way, that this encoding of set theory does not attempt to avoid Russell's paradox. Schmidt's treatment was based on G\"{o}del-Bernays set theory and had a judgement ``Set{\nobreakspace}\textit{A}'', which we have not carried forward into our treatment, principally because our client didn't want us to.


The axioms of comprehension and extension in this naive treatment are


comprehension: $@*P.|*A.x\in A<->P(x)$ \\
extension: $@*A,B.\,A=B<->(@*x.x\in A<->x\in B)$



Of course the axiom of comprehension, stated as above, isn't first order, but that doesn't bother Jape. We haven't yet found a way to incorporate comprehension as a single rule, just because of the existence operator, and so we have followed Schmidt and incorporated it as two rules for each of our set-abstraction forms:\\


\begin{tabular}{|p{0.886in}|p{0.912in}|p{1.249in}|p{1.276in}|p{0.044in}|p{0.044in}|p{0.044in}|p{0.044in}|} \hline
% ROW 1
{\raggedright $\infer
       {\Gamma  |- A\in \left\{ y \mid P\left( y\right) \right\} }
       {\Gamma  |- P\left( A\right) }$ } & 
{\raggedright $\infer
       {\Gamma |- P\left( A\right) }
       {\Gamma  |- A\in \left\{ y|P\left( y\right) \right\} } $ } & 
{\raggedright $\infer
       {\Gamma  |- \left\langle A,B\right\rangle \in \left\{ \left\langle y,z\right\rangle |P\left( y,z\right) \right\} }
       {\Gamma  |- P\left( A,B\right) }$ } & 
{\raggedright $\infer
       {\Gamma  |- P\left( A,B\right) }
       {\Gamma  |- \left\langle A,B\right\rangle \in \left\{ \left\langle y,z\right\rangle |P\left( y,z\right) \right\} }$ }\\
\hline \end{tabular}


The rules are encoded as a couple of alts

RULES "abstraction-I"(A, OBJECT y,OBJECT z) ARE \\
\tab FROM P(A) INFER A/\{ y {\textbar} P(y) \}\\
AND\tab FROM P(A,B) INFER \texttt{<}A,B\texttt{>}/\{ \texttt{<}y,z\texttt{>} {\textbar} P(y,z) \}\\
END\\
RULES "abstraction-E"(A, OBJECT y, OBJECT z) ARE\\
\tab FROM A/\{ y {\textbar} P(y) \} INFER P(A) \\
AND\tab FROM \texttt{<}A,B\texttt{>}/\{ \texttt{<}y,z\texttt{>} {\textbar} P(y,z) \} INFER P(A,B)\\
END


and are incorporated into the SetOps menu in the usual way

ENTRY "abstraction-I" IS FSSOB ForwardCutwithSubstSel "abstraction-I"\\
ENTRY "abstraction-E" IS FOBSS ForwardCut "abstraction-E"


The fobss and fssob tactics are each a variation of the fob tactic, requiring that the user makes a text selection when reasoning backward (fobss) or forward (fssob):

TACTIC FOBSS (Forward, Rule) IS \\
\tab WHEN\tab (LETHYP \_P\\
\tab \tab \tab (ALT\tab (Forward Rule)\\
\tab \tab \tab \tab (WHEN\tab (LETARGSEL \_Q \\
\tab \tab \tab \tab \tab \tab (JAPE(failgivingreason(Rule is not applicable to assumption ' \_P ' \\
\tab \tab \tab \tab \tab \tab \tab \tab \tab \tab with argument ' \_Q '))))\\
\tab \tab \tab \tab \tab (JAPE(failgivingreason(Rule is not applicable to assumption ' \_P ')))))) \\
\tab \tab (LETCONCSUBSTSEL \_P \\
\tab \tab \tab (ALT\tab (WITHSUBSTSEL (WITHHYPSELRule))\\
\tab \tab \tab \tab (LETGOAL \_Q\\
\tab \tab \tab \tab \tab (JAPE(failgivingreason(Rule is not applicable to conclusion ' \_Q '\\
\tab \tab \tab \tab \tab \tab \tab \tab \tab \tab with substitution ' \_P '))))))\\
\tab \tab (ALT\tab (WITHSELECTIONS Rule)\\
\tab \tab \tab (JAPE(failgivingreason(Rule is not applicable to that conclusion))))

TACTIC FSSOB (Forward, Rule) IS \\
\tab WHEN\tab (LETHYPSUBSTSEL \_P (Forward Rule)) \\
\tab \tab (ALT\tab (WITHSELECTIONS Rule)\\
\tab \tab \tab (WHEN\tab (LETARGSEL \_P\\
\tab \tab \tab \tab \tab (JAPE(failgivingreason(Rule is not applicable with argument ' \_P '))))\\
\tab \tab \tab \tab (JAPE(failgivingreason(Rule is not applicable)))))

TACTIC ForwardCutwithSubstSel(Rule) IS\\
\tab SEQ\tab cut \\
\tab \tab (WHEN\tab (LETSUBSTSEL \_A Rule (WITHSUBSTSEL hyp))\\
\tab \tab \tab \tab (JAPE (fail(please text-select one or more instances of a sub-formula))))


We can incorporate extension, however, as an axiomatic definition. We don't include the outer quantification, as our rules are schemata. The rule is


$\infer{A=B |- @*y.y\in A<->y\in B}
       {}$

encoded as\footnote{It's obvious from this example that Jape needs a simple way of expressing rules whose name is just the consequent of the rule. It will have it, one day.}

RULE (OBJECT y) IS INFER A=B \~{} (∀y.y/A$<->$y/B)


When we use this rule we will normally do so with a rewrite: replace some subformula which matches one side or other of the definition, closing the first antecedent of the rewrite with an instance of the axiomatic definition above. But we don't want to see the particular instance of the axiom as part of the proof: just as in the functional programming example, it is best referred to in the justification of the rewrite step, and otherwise hidden from view.


We include the rule as part of a Definitions panel, then, and have two buttons on the panel which allow left-to-right and right-to-left rewriting. As with the Substitution menu, switching the rewrite rules around in the tactics associated with each button allows forward or backward rewriting:

PREFIXBUTTON "A\~{}\dots " IS apply ForwardSubstHiding "rewrite \~{} $\ll$" "rewrite \~{} $\gg$"\\
PREFIXBUTTON "\dots \~{}B" IS apply ForwardSubstHiding "rewrite \~{} $\gg$" "rewrite \~{} $\ll$"


The tactic ForwardSubstHiding is rather subtle, because it allows the user to rewrite


{\textbullet}\tab either a hypothesis or a conclusion;\\
{\textbullet}\tab after text-selecting a number of instances of a subformula, just those instances;\\
{\textbullet}\tab without text-selecting, the whole hypothesis or conclusion.


In fact it is only forward rewriting without text selection that is more subtle than what we have already seen.

TACTIC ForwardSubstHiding (ruleLR, ruleRL, thm) IS\\
\tab WHEN\tab (LETHYPSUBSTSEL \_P cut (LAYOUT () (1) ruleRL thm (WITHSUBSTSEL hyp)))\\
\tab \tab (LETCONCSUBSTSEL \_P (LAYOUT () (1) (WITHSUBSTSEL ruleLR) thm))\\
\tab \tab (LETHYP \_P cut (LAYOUT () (1)\tab ruleRL thm \\
\tab \tab \tab (LETGOAL (\_P'[\_v{\textbackslash}\_Q]) (WITHHYPSEL(hyp \_Q)))))\\
\tab \tab (LETGOAL \_P (LAYOUT () (1) (ruleLR \_P) thm))


The first alternative in the when is activated when the user has text-selected in a hypothesis: it cuts, uses one of the rewrite rules, closes the first antecedent with the theorem, and the second using the text-selection that the user made. The second alternative is activated when there is a text-selection in a conclusion: it uses the other rewrite rule followed by the theorem. The last alternative is activated when there is no recognisable text-selection\footnote{Actually, and unfortunately, when there is no \textit{valid} text selection.} and no hypothesis selection: it activates the same rewrite rule as the second alternative, but gives it the whole conclusion formula instead of the user's text selection: that is a particularly easy `abstraction' for the substitution-unifier to resolve, and the effect is to unify the whole consequent with the left- or the right-hand side of the theorem, depending on the particular rewrite rule that is used.\\
The third alternative is the tricky one. It calls the same rewrite rule as the first alternative, but gives it nothing to work on, so that rule will necessarily succeed by deferred unification of the consequent of the rewrite with the conclusion. Then it closes the first antecedent of the rewrite with the theorem: that alters the consequent of the rewrite, but won't introduce enough constant material to enable the deferred unification to be resolved. Somehow we have to unify the selected hypothesis with one side or other of the theorem, just as in the fourth alternative. The trick is to realise that after the theorem is applied, the second antecedent of the rewrite step will be a substitution: we take the substituting formula from that substitution and, using \textit{hyp}, unify that with the whole substitution and the originally-selected hypothesis. The effect is like magic: the whole of the selected hypothesis is unified with one side or the other of the theorem, just as in the fourth alternative\footnote{It's quite a clever bit of tactic programming, and that's the problem. In the future we hope to be able to allow \textit{either} of the formulae -- \textit{A} or \textit{B} -- in the rewrite rule to be provided as argument.}.


Each of the entries in the Definitions panel is intended to be used as a two-way rewrite rule, using the buttons above. One entry in the Definitions panel is given in BnE-Fprime\_menus.j (where also the buttons are defined):

RULE IS A\ensuremath{\neq}B \~{} ¬(A=B)


This definition makes it unnecessary to have rules for \ensuremath{\neq}\footnote{In the future we hope to be able to handle this sort of definition by `definitional equality', where you write \textit{A}\ensuremath{\neq}\textit{B} and Jape interprets it as ¬(\textit{A}=\textit{B}) but displays it as \textit{A}\ensuremath{\neq}\textit{B}; compare the treatment of ¬\textit{A} as equivalent to \textit{A}\ensuremath{->}\"{Y} in many treatments of the intuitionistic sequent calculus, which we also can't handle at the moment as transparently as we would wish.}. The others are in set\_menus.j:

RULE IS A¬/B \~{} ¬(A/B)\\
RULE IS {\O} \~{} \{\}\\
RULE (OBJECT x) IS EQ \~{} \{x{\textbar}x=x\}\\
RULE (OBJECT x) IS \{A\} \~{} \{x{\textbar}x=A\}\\
RULE (OBJECT x) IS \{A,B\} \~{} \{x{\textbar}x=A∧x=B\}\\
RULE (OBJECT x) IS \{A,B,C\} \~{} \{x{\textbar}x=A∧x=B∧x=C\}\\
RULE (OBJECT x) IS \{A,B,C,D\} \~{} \{x{\textbar}x=A∧x=B∧x=C∧x=D\}\\
RULE (OBJECT y) IS A{\ss}B \~{} (∀y.y/A→y/B)\\
RULE (OBJECT y) IS A=B \~{} (∀y.y/A$<->$y/B)\\
RULE (OBJECT y) IS A\^{O}B \~{} \{ y {\textbar} y/A∧y/B \}\\
RULE (OBJECT y) IS AflB \~{} \{ y {\textbar} y/A∧y/B \}\\
RULE (OBJECT y) IS A-B \~{} \{ y {\textbar} y/A∧y¬/B \}\\
RULE (OBJECT y) IS A\={} \~{} \{y {\textbar} y¬/A\}\\
RULE (OBJECT x, OBJECT y) IS \^{O}\^{O}(C) \~{} \{ x {\textbar} ∃y. x/y∧y/C \}\\
RULE (OBJECT x, OBJECT y) IS flfl(C) \~{} \{ x {\textbar} ∀y. y/C→x/y \}\\
RULE (OBJECT x) IS Pow(A) \~{} \{ x {\textbar} x{\ss}A \}\\
RULE (OBJECT x, OBJECT y) IS A$\times$B \~{} \{ \texttt{<}x,y\texttt{>} {\textbar} x/A∧y/B \}\\
RULE (OBJECT x, OBJECT y, OBJECT z) IS A{\textbullet}B \~{} \{ \texttt{<}x,z\texttt{>} {\textbar} ∃y.\texttt{<}x,y\texttt{>}/A∧\texttt{<}y,z\texttt{>}/B \}


\textbf{6.4\tab The non-axiomatic rules}


A proof using the axioms will typically introduce and then eliminate logical connectives. Here is the beginning of such an axiomatic proof:

\begin{figure}[htbp] \begin{center} \includegraphics[width=3.111in, height=3.792in]{oldpics/Roll_your_own_v3_2+Fig46} \caption{Fig46} \end{center} \end{figure}

It is clear that there will be lots of repetitive applications of \ensuremath{\forall}-E, \ensuremath{\forall}-I, \ensuremath{->}-E, \ensuremath{->}-I, and similar logical rules during this proof. It is clear that there could be introduction and elimination rules for each of the set operators. These are the ones relevant to the proof above:\\


\begin{tabular}{|p{1.457in}|p{1.457in}|p{1.457in}|p{0.043in}|p{0.043in}|p{0.043in}|} \hline
% ROW 1
{\raggedright $\infer[\reason{$(\operatorname{FRESH}\;c)\;\subseteq -I$}]
       {\Gamma  |- A\subseteq B}
       {\Gamma,c\in A |- c\in B}$ } & {\raggedright $\infer[\reason{$\subseteq -E$}]
       {\Gamma |- C\subseteq B}
       {\Gamma  |- C\in A\quad \Gamma  |- A\subseteq B}$ } & {\raggedright }\\
\hline
% ROW 2
{\raggedright $\infer[\reason{$=-I$}]
       {\Gamma |- A=B}
       {\Gamma  |- A\subseteq B\quad \Gamma  |- B\subseteq A}$ } & {\raggedright $\infer[\reason{$=-E(L)$}]
       {\Gamma  |- A\subseteq B}
       {\Gamma  |- A=B}$ } & {\raggedright $\infer[\reason{$=-E(R)$}]
       {\Gamma  |- B\subseteq A}
       {\Gamma  |- A=B}$ }\\
\hline \end{tabular}

and here is the proof completed using these rules, rather than the axiomatic definitions:

\begin{figure}[htbp] \begin{center} \includegraphics[width=2.292in, height=2.403in]{oldpics/Roll_your_own_v3_2+Fig47} \caption{Fig47} \end{center} \end{figure}


Somewhat simpler! The rules are encoded in the obvious way\footnote{Jape is currently unequipped to allow the user to prove derived rules from the axioms. We intend that in the near future it should permit it -- the mechanism we have for proving theorem schemata is almost all that we need.} and likewise organised into a menu.\\
Naturally we regret that Jape cannot yet deal with proofs of derived rules such as these.



\chapter{Encoding the Hindley-Milner type-assignment algorithm}


We consider a version of the algorithm for the lambda calculus with tuples and \textit{let}/\textit{letrec} bindings. \\


\begin{tabular}{lllllll} \hline
% ROW 1
\multicolumn{1}{|p{2.056in}|} {\raggedright

$\infer[\reason{$\lambda -I$}]
       {C |- \lambda x.E:T->T' }
       {C,x:T |- E:T' }$ } & \multicolumn{2}{p{2.357in}|} {\raggedright

$\infer[\reason{$application-I$}]
       {C |- F\,G:T' }
       {C |- F:T->T' \quad C |- G:T}$ }\\
\hline
% ROW 2
\multicolumn{2}{p{0.043in}|} {\raggedright

$\infer[\reason{$tuple-I$}]
       {C |- (E1,E2):(T1\times T2)}
       {C |- E1:T1\quad C |- E2:T2}$ } & \multicolumn{2}{p{0.043in}|} {\raggedright }\\
\hline
% ROW 3
\multicolumn{1}{|p{2.056in}|} {\raggedright

$\infer[\reason{$\operatorname{let}-I$}]
       {C |- \operatorname{let}\,x=E\,\operatorname{in}\,F\,\operatorname{end}:T}
       {C |- E:T1\quad C |- T1\prec S\quad C,x:S |- F:T}$ } & \multicolumn{1}{p{2.351in}|} {\raggedright

$\infer[\reason{$\operatorname{letrec}-I$}]
       {C |- \operatorname{letrec}\,x=E\,\operatorname{in}\,F\,\operatorname{end}:T}
       {C,x:T1 |- E:T1\quad C |- T1\prec S\quad C,x:S |- F:T}$ }\\
\hline
% ROW 4
\multicolumn{2}{p{0.043in}|} {\raggedright

$\infer[\reason{$identifier\;type$}]
       {C |- x:T}
       {C(x)\mapsto S\quad S\succ T}$ } & \multicolumn{3}{p{0.049in}|} {\raggedright }\\
\hline \end{tabular}


In each of these rules the context \textit{C} is a sequence of bindings of program variables to type schemes which can be read, right to left, as a mapping from variables to type schemes. The judgement

$C(x)\mapsto $ interprets the context in just that way. The judgement $C |- T\prec S$ is the \textit{generalisation step}, in which `type variables' free in the type \textit{T} but not free in the context \textit{C} are used to transform type \textit{T} into type scheme \textit{S}. The judgement

$S\succ T$ is the corresponding \textit{specialisation step}, when the schematic variables of \textit{S} are replaced by type formulae.


The difficulties of encoding the Hindley-Milner algorithm are just those of representing the schematic `type variables', representing and interpreting the type context and implementing the generalisation and specialisation steps.


\textbf{7.2\tab Syntax}


We represent \ensuremath{\lambda} formulae as a leftfix formula, and we give that formula a lower priority than the colon operator, so that we don't unnecessarily have to bracket \ensuremath{\lambda} formulae. The type-tupling operator \ensuremath{\times} is treated as an associative operator, rather like comma. We need an == operator (blechh!) because = is used in the \textit{let / letrec} syntax. We use $\ll$ for generalisation and $\gg$ for specialisation. We use a double-arrow operator rather than a colon in the contexts, for no particularly good reason that we can remember. We have included additional operators {\textbullet} and $\triangleleft$ which are used in the generalisation-step induction.


We have represented type schemes which include schematic variables-- so-called polytypes -- as $@*t.T$ or $@*t1,t2.T$ and so on, with up to four schematic variables. Those which have no schematic variables -- so-called monotypes -- as \#\textit{T}, where \textit{T} is a type formula. This is faithful to Milner's treatment in the ML description, where he describes the scheme \textit{T} as a shorthand for \ensuremath{\forall}().\textit{\ensuremath{T}}.


We have included constants \textit{hd}, \textit{tl} and \textit{nil} which are useful in describing list-processing, \textit{true} and \textit{false} which are useful in handling booleans; we have included constant type-names \textit{bool}, \textit{string} and \textit{num}.


First the program names:

CLASS VARIABLE x y z e f g map\\
CLASS FORMULA E F G\\
CLASS CONSTANT c\\
CONSTANT hd tl nil\\
CLASS NUMBER n\\
CLASS STRING s\\
CONSTANT true false


and then the type names:

CLASS VARIABLE t\\
CLASS FORMULA S T /* we use T for types, S for type schemes in the rules which follow */\\
CONSTANT bool string num


Next operators for programs:

SUBSTFIX\tab 500\tab \{ E / x \}\\
JUXTFIX\tab 400\\
INFIXC\tab 140L\tab + -\\
INFIXC\tab 120R\tab ::\\
INFIXC\tab 100L\tab == /* we need this because we also have let f =... */\\
LEFTFIX\tab 75\tab $\lambda$.\\
INFIX\tab 50L\tab =

OUTFIX [ ]\\
OUTFIX letrec in end\\
OUTFIX let in end\\
OUTFIX if then else fi


and operators for types:

INFIX\tab 150T \tab $\times$\\
INFIX\tab 100R \tab →\\
LEFTFIX\tab 75\tab ∀.\\
PREFIX\tab 75\tab \#\\
INFIX\tab 55L \tab {\textbullet} $\triangleleft$\\
INFIX\tab 50L \tab : $=>$ $\ll$ $\gg$


Now bindings:

BIND x SCOPE E IN $\lambda$ x. E

BIND t SCOPE T IN ∀ t. T\\
BIND t1 t2 SCOPE T IN ∀ t1, t2. T\\
BIND t1 t2 t3 SCOPE T IN ∀ t1, t2, t3. T\\
BIND t1 t2 t3 t4 SCOPE T IN ∀ t1, t2, t3, t4. T

BIND x \tab SCOPE F\tab IN let x = E in F end\\
BIND x1 x2 \tab SCOPE F\tab IN let x1=E1, x2=E2 in F end\\
BIND x1 x2 x3\tab SCOPE F\tab IN let x1=E1, x2=E2, x3=E3 in F end\\
BIND x1 x2 x3 x4\tab SCOPE F\tab IN let x1=E1, x2=E2, x3=E3, x4=E4 in F end\\
BIND x\tab SCOPE E F\tab IN letrec x = E in F end\\
BIND x1 x2\tab SCOPE E1 E2 F\tab IN letrec x1=E1, x2=E2 in F end\\
BIND x1 x2 x3\tab SCOPE E1 E2 E3 F\tab IN letrec x1=E1, x2=E2, x3=E3 in F end\\
BIND x1 x2 x3 x4\tab SCOPE E1 E2 E3 E4 F\tab IN letrec x1=E1, x2=E2, x3=E3, x4=E4 in F end


Finally, the definition of a judgement:

CLASS LIST C\\
SEQUENT IS LIST ⊦ FORMULA


\textbf{7.2\tab Rules}


The structural rules are very straightforwardly encoded, following the algorithm directly. Note the use of a type scheme \#\textit{T1} in the rule which deals with \ensuremath{\lambda} formulae.

RULE "F G : T"\tab FROM C ⊦ F: T1→T2 AND C ⊦ G : T1 \tab INFER C ⊦ F G : T2\\
RULE "$\lambda$x.E : T1→T2"\tab FROM C,x$=>$\#T1 ⊦ E:T2 \tab INFER C ⊦ $\lambda$x.E : T1→T2\\
RULE "(E,F) : T1$\times$T2"\tab FROM C ⊦ E: T1 AND C ⊦ F: T2\tab INFER C ⊦ (E,F) : T1$\times$T2\\
RULE "if E then ET else EF fi : T"\\
\tab FROM C ⊦ E : bool AND C ⊦ ET : T AND C ⊦ EF : T\tab INFER C ⊦ if E then ET else EF fi : T


There are some simple rules which deal with constants:

RULE "n:num"\tab INFER C ⊦ n:num\\
RULE "s:string"\tab INFER C ⊦ s:string\\
RULE "true:bool"\tab INFER C ⊦ true:bool\\
RULE "false:bool"\tab INFER C ⊦ false:bool


which we apply whenever possible -- in this case autounify seems to be the best mechanism:

AUTOUNIFY "n:num" "s:string" "true:bool" "false:bool"


Dealing with the various forms of \textit{let} and \textit{letrec} formulae is a matter of tedious listing. Here are the \textit{letrec} rules:

RULES letrecrules ARE\\
\tab FROM C,x$=>$\#T1 ⊦ E:T1 AND C ⊦ T1$\ll$S1 AND C,x$=>$S1 ⊦ F:T\\
\tab \tab INFER C ⊦ letrec x=E in F end : T\\
AND\tab FROM C,x1$=>$\#T1,x2$=>$\#T2 ⊦ E1 : T1 AND C,x1$=>$\#T1,x2$=>$\#T2 ⊦ E2 : T2 \\
\tab AND C ⊦ T1$\ll$S1 AND C ⊦ T2$\ll$S2 AND C,x1$=>$S1,x2$=>$S2 ⊦ F:T\tab \\
\tab \tab INFER C ⊦ letrec x1=E1, x2=E2 in F end : T\\
AND\tab FROM C,x1$=>$\#T1,x2$=>$\#T2,x3$=>$\#T3 ⊦ E1 : T1 AND C,x1$=>$\#T1,x2$=>$\#T2,x3$=>$\#T3 ⊦ E2 : T2\\
\tab AND C,x1$=>$\#T1,x2$=>$\#T2,x3$=>$\#T3 ⊦ E3 : T3 AND C ⊦ T1$\ll$S1 AND C ⊦ T2$\ll$S2\\
\tab AND C ⊦ T3$\ll$S3 AND C,x1$=>$S1,x2$=>$S2,x3$=>$S3 ⊦ F:T\\
\tab \tab INFER C ⊦ letrec x1=E1, x2=E2, x3=E3 in F end : T\\
AND\tab FROM C,x1$=>$\#T1,x2$=>$\#T2,x3$=>$\#T3,x4$=>$\#T4 ⊦ E1 : T1 \\
\tab AND C,x1$=>$\#T1,x2$=>$\#T2,x3$=>$\#T3,x4$=>$\#T4 ⊦ E2 : T2\\
\tab AND C,x1$=>$\#T1,x2$=>$\#T2,x3$=>$\#T3,x4$=>$\#T4 ⊦ E3 : T3 \\
\tab AND C,x1$=>$\#T1,x2$=>$\#T2,x3$=>$\#T3,x4$=>$\#T4 ⊦ E4 : T4\\
\tab AND C ⊦ T1$\ll$S1 AND C ⊦ T2$\ll$S2 AND C ⊦ T3$\ll$S3 AND C ⊦ T4$\ll$S4\\
\tab AND C,x1$=>$S1,x2$=>$S2,x3$=>$S3,x4$=>$S4 ⊦ F:T\\
\tab \tab INFER C ⊦ letrec x1=E1, x2=E2, x3=E3, x4=E4 in F end : T\\
END


\textit{Reading the context and specialising a type scheme}


Things get more interesting when we consider how to handle the context-evaluation step $C(x)\mapsto S$ : \textit{C} maps \textit{x} to scheme \textit{S}. The context is just a list of name\ensuremath{->}scheme bindings, and it should be read right-to-left, so that the most recent bindings take precedence. Because program names can't appear in types in this logic, we can use a notin proviso to help us to read the context in this way. Because variables and constants are different syntactic classes, we need two rules:

RULE "C ⊦ x$=>$S" WHERE x NOTIN C' IS INFER C,x$=>$S,C' ⊦ x$=>$S\\
RULE "C ⊦ c$=>$S" WHERE c NOTIN C' IS INFER C,c$=>$S,C' ⊦ c$=>$S


We declare these two as identity rules so that their application is hidden in a box-and-line display of a proof:

IDENTITY "C ⊦ x$=>$S"\\
IDENTITY "C ⊦ c$=>$S"


We have rules for the types of the constant function identifiers which we have used:

RULES constants ARE\\
\tab C ⊦ hd$=>$∀tt.[tt]→tt\\
AND\tab C ⊦ tl$=>$∀tt.[tt]→[tt]\\
AND\tab C ⊦ (::)$=>$∀tt.tt→[tt]→[tt]\\
AND\tab C ⊦ nil$=>$∀tt.[tt]\\
AND\tab C ⊦ (+)$=>$\#num→num→num\\
AND\tab C ⊦ (-)$=>$\#num→num→num\\
AND\tab C ⊦ (==)$=>$∀tt.tt→tt→bool\\
END


Typing a variable or a constant is a matter of finding the type scheme and then specialising to some type. Specialisation is just a matter of substituting types for schematic variables:

RULES "S$\gg$T" ARE\\
\tab INFER \#T $\gg$ T\\
AND\tab INFER ∀tt.TT $\gg$ TT\{T1/tt\}\\
AND\tab INFER ∀tt1,tt2.TT $\gg$ TT\{T1,T2/tt1,tt2\}\\
AND\tab INFER ∀tt1,tt2,tt3.TT $\gg$ TT\{T1,T2,T3/tt1,tt2,tt3\}\\
AND\tab INFER ∀tt1,tt2,tt3,tt4.TT $\gg$ TT\{T1,T2,T3,T4/tt1,tt2,tt3,tt4\}\\
END


Then two rules put these together in just the way that the algorithm does:

RULE "C ⊦ x:T" IS FROM C⊦x$=>$S AND S$\gg$T INFER C⊦x:T\\
RULE "C ⊦ c:T" IS FROM C⊦c$=>$S AND S$\gg$T INFER C⊦c:T


In the menu we use a tactic which looks in three places for a type scheme and then specialises, showing none of its working when it succeeds, but trying to give some error messages when it fails:

TACTIC "x:T" IS\\
\tab SEQ\tab (ALT\tab (LAYOUT "C(x)$=>$S; S$\gg$T" () "C ⊦ x:T" "C ⊦ x$=>$S") \\
\tab \tab \tab (LAYOUT "C(c)$=>$S; S$\gg$T" () "C ⊦ c:T" "C ⊦ c$=>$S")\\
\tab \tab \tab (LAYOUT "constant" () "C ⊦ c:T" constants)\\
\tab \tab \tab (WHEN\tab (LETGOAL\tab (\_E:\_T)\\
\tab \tab \tab \tab \tab (JAPE(fail(x:T can only be applied to either variables or\\
\tab \tab \tab \tab \tab \tab \tab constants: \_E is neither)))\\
\tab \tab \tab \tab )\\
\tab \tab \tab \tab (LETGOAL\tab \_E (JAPE(fail(conclusion \_E is not a ' name:type ' judgement))))\\
\tab \tab \tab )\\
\tab \tab ) \\
\tab \tab "S$\gg$T"


\textit{The generalisation step}


The technique used here is to perform a structural induction on the type \textit{T} in order to calculate its schematic variables. These will be unknowns, because of course we don't judiciously introduce type variables when running the algorithm (though we might): we simply introduce unknowns as necessary, as we go.


The generalisation step is run by a tactic, and all the working is normally hidden from the user. It works with a formula \textit{type} {\textbullet} $\textit{scheme}_{\textit{in}}$ $\triangleleft$ $\textit{scheme}_{\textit{out}}$, in which the operators {\textbullet} and $\triangleleft$ are no more than punctuation. The starting rule is

RULE "T$\ll$S" IS\tab FROM C ⊦ T {\textbullet} \#T $\triangleleft$ S \tab INFER C ⊦ T $\ll$ S


The induction works with rules which take a type apart, and two rules which are the base case. The structural rules are

RULE "T1→T2{\textbullet}..."\tab FROM C ⊦ T1{\textbullet} Sin $\triangleleft$ Smid AND C ⊦ T2 {\textbullet} Smid $\triangleleft$ Sout\\
\tab \tab INFER C ⊦ T1→T2 {\textbullet} Sin $\triangleleft$ Sout\\
RULE "T1$\times$T2{\textbullet}..."\tab FROM C ⊦ T1{\textbullet} Sin $\triangleleft$ Smid AND C ⊦ T2 {\textbullet} Smid $\triangleleft$ Sout\\
\tab \tab INFER C ⊦ T1$\times$T2 {\textbullet} Sin $\triangleleft$ Sout\\
RULE "[T]{\textbullet}..."\tab FROM C ⊦ T {\textbullet} Sin $\triangleleft$ Sout\\
\tab \tab INFER C ⊦ [T] {\textbullet} Sin $\triangleleft$ Sout


The tactic applies these rules, we shall see, `by matching': they aren't allowed to make any substantial unifications which alter the problem sequent to which they are applied. So if the problem sequent is \textit{unknown} {\textbullet} \textit{scheme}$_{\textit{in}}$ $\triangleleft$ \textit{scheme}$_{\textit{out}}$, none of these rules will be used.


The rules which deal with an unknown do so by unifying it with a freshly-minted variable name and making sure that it doesn't appear in the context or the original type:

RULES "new t{\textbullet}..." (OBJECT t1) WHERE t1 NOTIN C ARE\\
\tab C⊦ t1 {\textbullet} \#T$\triangleleft$ ∀t1.T \\
AND\tab C⊦ t1 {\textbullet} ∀tt1.T $\triangleleft$ ∀tt1,t1.T \\
AND\tab C⊦ t1 {\textbullet} ∀tt1,tt2.T $\triangleleft$ ∀tt1,tt2,t1.T \\
AND\tab C⊦ t1 {\textbullet} ∀tt1,tt2,tt3.T $\triangleleft$ ∀tt1,tt2,tt3,t1.T \\
END


The only formula which can possibly unify with a freshly-minted type variable is a type unknown, and these rules have a proviso that the result shouldn't be free in the context \textit{C}. The effect is to replace an unknown type by a type variable, and to include it in the context.


If none of these rules applies, then we must have an unknown which \textit{does} appear in the context: that unknown must be left alone:

RULE "same T{\textbullet}..."\tab INFER C ⊦ T {\textbullet} S $\triangleleft$ S


The whole is stitched together with a tactic which tries first the structural rules by matching, then the variable rule and finally the leave-alone rule; that tactic is used by another which starts the process, calls the induction and hides all its working:

TACTIC geninduct IS \\
\tab ALT\tab (SEQ (MATCH (ALT "T1→T2{\textbullet}..." "T1$\times$T2{\textbullet}...")) geninduct geninduct) \\
\tab \tab (SEQ (MATCH "[T]{\textbullet}...") geninduct)\\
\tab \tab "new t{\textbullet}..."\\
\tab \tab "same T{\textbullet}..."

TACTIC generalise IS LAYOUT "generalise" () "T$\ll$S" geninduct


We also provide a `single-step' tactic which carries out the same tasks, so that users can view the process as it evolves:

TACTIC genstep IS \\
\tab ALT\tab "T$\ll$S" \\
\tab \tab (MATCH "T1→T2{\textbullet}...") \\
\tab \tab (MATCH "T1$\times$T2{\textbullet}...") \\
\tab \tab (MATCH "[T]{\textbullet}...") \\
\tab \tab "new t{\textbullet}..."\\
\tab \tab "same T{\textbullet}..."


\textit{Automatic search}


In this chapter we are dealing with an encoding of an \textit{algorithm}, not simply a logic. It's possible to get strange answers by running the steps in the wrong order. On the other hand, it's easy to write a tactic which automatically runs the algorithm. That tactic is long-winded because it has to deal, case-by-case, with the various sizes of binding structures. If only Jape could handle families of rules...

TACTIC Auto IS\\
\tab WHEN\tab (LETGOAL (\_x:\_T) "x:T")\\
\tab \tab (LETGOAL (\_c:\_T) \\
\tab \tab \tab (ALT\tab "x:T" "n:num" "s:string" "true:bool" "false:bool"\\
\tab \tab \tab \tab (JAPE (fail (\_c isn't a constant from the context, \\
\tab \tab \tab \tab \tab \tab \tab or one of the fixed constants))) \\
\tab \tab \tab )\\
\tab \tab )\\
\tab \tab (LETGOAL (\_F \_G:\_T) "F G : T" Auto Auto)\\
\tab \tab (LETGOAL ((\_E,\_F):\_T) "(E,F) : T1$\times$T2" Auto Auto)\\
\tab \tab (LETGOAL (($\lambda$\_x.\_E):\_T) "$\lambda$x.E : T1→T2" Auto)\\
\tab \tab (LETGOAL (if \_E then \_ET else \_EF fi:\_T) "if E then ET else EF fi : T" Auto Auto Auto)\\
\tab \tab (LETGOAL (let \_x=\_E in \_F end:\_T) \\
\tab \tab \tab \tab letrules Auto generalise Auto)\\
\tab \tab (LETGOAL (let \_x1=\_E1, \_x2=\_E2 in \_F end:\_T) \\
\tab \tab \tab \tab letrules Auto Auto generalise generalise Auto)\\
\tab \tab ... \textit{etc...}\\
\tab \tab (LETGOAL (letrec \_x=\_E in \_F end:\_T) \\
\tab \tab \tab \tab letrecrules Auto generalise Auto)\\
\tab \tab (LETGOAL (letrec \_x1=\_E1, \_x2=\_E2 in \_F end:\_T) \\
\tab \tab \tab \tab letrecrules Auto Auto generalise generalise Auto)\\
\tab \tab ... \textit{etc...}\\
\tab \tab (LETGOAL (\_E:\_T) (JAPE (fail (\_E is not a recognisable program formula (Auto)))))\\
\tab \tab (LETGOAL \_E (JAPE (fail (\_E is not a recognisable judgement (Auto)))))


There's a similar AutoStep tactic which lets the user make just one step of the algorithm.


\textbf{{\large 7.3\tab An example}}


The algorithm will calculate, for example, the type of \textit{map} and use it correctly in an application:

\begin{figure}[htbp] \begin{center} \includegraphics[width=6.944in, height=9.333in]{oldpics/Roll_your_own_v3_2+Fig48} \caption{Fig48} \end{center} \end{figure}


This example shows that it is necessary for Jape to learn how to fold long formulae when displaying a proof (it can fold long lists of formulae -- see, for example, the BAN logic encoding).


\textbf{{\large 7.4\tab Jape's treatment of type-theoretic logics}}


In simple, `pure' logics, we can reasonably claim that Jape can transparently encode the inference rules, and all the magic is hidden in its treatment of substitutions, bindings and unification. In the case of the Hindley-Milner logic and, we surmise, other type-theoretic logics, that isn't so. We've made some creative choices and had to program an encoding of the treatment of contexts. If the treatment in this chapter is to serve as a model of how Jape can encode type-theoretic logics, there are a number of questions which have to be answered.


First, and trivially, we ought to able to deal with the monotype / polytype distinction without the ugly syntactic mechanism we have used here. That's a matter of improving our parser generator, we believe, and is simply a question of development.


More seriously, our treatment has no judgement equivalent to `C is a context', and we have pushed the question into the context-interpretation rule, treating the context as a mapping and making sure with a proviso that we aren't overlooking a later binding. Meta-theoretically it is clear that the context might easily be formed by ensuring that every name it contains is distinct; the necessary \ensuremath{\alpha}-conversion, however, makes it hard for a human prover to keep track of what is going on. It seems to us, therefore, that we are pragmatically correct to treat the context as a mapping. Also, our rules are context-validity preserving. But it is still possible to state a conjecture with a nonsense context and yet prove it in our system: $GARBAGE |- \lambda x.x:T->T$ will be a theorem. It would be absurdly inefficient to check the validity of the context at every rule application; nevertheless, we must find ways in which we can check its validity at crucial points in a proof.


We intend, in future work on type-theoretic logics, to continue to develop the approach used here. We expect to invent proviso mechanisms which allow us to state that the names in some type judgement are not rebound by the context to their right, or something similar. We dream, even, of user-defined provisos which will allow close control of the meaning of such provisos. We hope to find the right place to put `C is a context' judgements.



\chapter{Encoding Hoare logic}


This chapter has very little to say. The encoding defined in the file hoare.jt and the files that it invokes is chiefly interesting for what it \textit{doesn't} do. Jape is perfectly capable of encoding the program syntax and the rules of inference about predicates, but it falls down when it tries to handle arithmetic. You could, in principle, prove that \textit{x}\texttt{<}\textit{x}+1 by induction (really!) but induction is absolutely no help when it comes to deciding that 3\texttt{<}4. Experience with this encoding shows that Jape needs an `arithmetic oracle', and one is under construction.


The problem of arithmetic is tricky, and we realise that provision of an arithmetic oracle won't make it go away. Jape lacks a `the user is an oracle' mechanism, as for example is provided in the Imperial College proof editor Pandora. Such a mechanism would make it possible to certify certain steps in a proof and for the steps to be accepted without further ado. That makes difficult arithmetic the responsibility of the user: certainly not sound, but far more convenient than Jape's current incapacity.\\


\chapter{Encoding BAN logic}


Burroughs-Abadi-Needham (BAN) logic is a logic of authentication-protocols. It's of interest to us chiefly because it is a logic in which the rules don't fit into a tidy introduction / elimination structure, so that we have to use some ingenuity to design menus and double-clicking mechanisms to suit. Also, conjectures seem naturally to require long lists of assumptions, which makes it possible to demonstrate Jape's mechanism for folding long association lists. And its use of tuples allows us to demonstrate some new ways in which Jape can deal with families of rules.


\textbf{{\large 9.1\tab Syntax}}


The syntax of the logic is very simple, although it includes a number of novel operators which we managed to add to our Konstanz font. We've had to transform some of the notation to linearise it: for example, we have made $A<->^{K} B$ (A and B share private key K) into $\left( A,B\right) <->K$ and we've made $\left\{ X\right\} _{K} $ into $\left\{ X\right\} K$ . We've used $K^{\bot } $ rather than $K^{-1} $ . Otherwise, we believe, we have faithfully described the syntax, even if we have had to guess at the syntactic hierarchy of operators.

CLASS VARIABLE x k\\
CLASS FORMULA W X Y Z\\
CLASS CONSTANT P Q R K N T\\
CONSTANT A B S

SUBSTFIX\tab 700\\
JUXTFIX\tab 600\\
PREFIX \tab 500\tab \#\\
POSTFIX \tab 500\tab \={}\\
INFIX\tab 300L\tab \"{u} \"{y} $<->$\\
INFIX\tab 200R\tab \"{\i}\\
INFIX\tab 150R\tab \"{o}\\
LEFTFIX \tab 110\tab ∀.\\
INFIX\tab 100R\tab \"{a}\\
INFIX\tab 50L\tab $\triangleleft$

OUTFIX \{ \}\\
OUTFIX \texttt{<} \texttt{>}

BIND x SCOPE P IN ∀x. P\\
SEQUENT IS BAG ⊦ FORMULA\\
INITIALISE autoAdditiveLeft true


\textbf{{\large 9.2\tab Rules}}


The rules of the logic are depicted in [``A Logic of Authentication'', Burrows Abadi, Needham] which is available on the Web from Mart\'{\i}n Abadi's home page, or in paper form as (Proceedings of the Royal Society, Series A, 426, 1871 (December 1989), 233-271). Two of the rules have a `\textit{from} R' side-condition which we haven't reproduced (and which is discussed in the paper though not depicted there). The rules are given natural-deduction style, without mentioning a context of hypotheses:\\


%\begin{tabular}{llllllll}
%\hline
%% ROW 1
%\multicolumn{1}{|p{1.082in}|}
%{\raggedright
%
%$\frac{PQ<->^{K} P\quad P\left\{ X\right\} _{K} }{PQX} $
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%
%$\frac{P ^{K} Q\quad P\left\{ X\right\} _{K^{-1} } }{PQX} $
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%
%$\frac{PQ ^{Y} P\quad P\left\langle X\right\rangle _{Y} }{PQX} $
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%}\\
%\hline
%% ROW 2
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%
%$\infer{PQX}{P\#X\quad PQX}$
%} &
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%
%$\infer{PX}{PQX\quad PQX}$
%} &
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%} &
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%}\\
%\hline
%% ROW 3
%\multicolumn{1}{|p{1.082in}|}
%{\raggedright
%
%$\infer{P\left( X,Y\right) }{PX\quad PY}$
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%
%$\infer{PX}{P\left( X,Y\right) }$
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%
%$\infer{PQX}{PQ\left( X,Y\right) }$
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%
%$\infer{PQX}{PQ\left( X,Y\right) }$
%}\\
%\hline
%% ROW 4
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%
%$\infer{PX}{P\left( X,Y\right) }$
%} &
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%
%$\frac{P\left\langle X\right\rangle _{Y} }{PX} $
%} &
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%} &
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%}\\
%\hline
%% ROW 5
%\multicolumn{1}{|p{1.082in}|}
%{\raggedright
%
%$\frac{PQ<->^{K} P\quad P\left\{ X\right\} _{K} }{PX} $
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%
%$\frac{P ^{K} P\quad P\left\{ X\right\} _{K} }{PX} $
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%
%$\frac{P ^{K} Q\quad P\left\{ X\right\} _{K^{-1} } }{PX} $
%} &
%\multicolumn{5}{p{1.253in}|}
%{\raggedright
%}\\
%\hline
%% ROW 6
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%
%$\infer{P\#\left( X,Y\right) }{P\#X}$
%} &
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%} &
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%} &
%\multicolumn{1}{p{0.043in}|}
%{\raggedright
%}\\
%\hline
%% ROW 7
%\multicolumn{1}{|p{1.082in}|}
%{\raggedright
%
%$\frac{PR<->^{K} R' }{PR' <->^{K} R} $
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%
%$\frac{PQR<->^{K} R' }{PQR' <->^{K} R} $
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%
%$\frac{PR \^{X} R' }{PR'  \^{X} R} $
%} &
%\multicolumn{5}{p{1.253in}|}
%{\raggedright
%
%$\frac{PQR \^{X} R' }{PQR'  \^{X} R} $
%}\\
%\hline
%% ROW 8
%\multicolumn{1}{|p{1.082in}|}
%{\raggedright
%
%$\frac{P@*v_{1} ...v_{n} .\left( QX\right) }{PQX\left[ v_{1} ...v_{n}
%\backslash Y_{1} ...Y_{n} \right] } $
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%} &
%\multicolumn{1}{p{1.082in}|}
%{\raggedright
%} &
%\multicolumn{5}{p{1.253in}|}
%{\raggedright
%}\\
%\hline
%\end{tabular}


The rules which don't deal with tuples are very straightforwardly encoded:

RULE "P\"{a}(Q,P)$<->$K, P$\triangleleft$\{X\}K $=>$ P\"{a}Q\"{\i}X" IS FROM P\"{a}(Q,P)$<->$K AND P$\triangleleft$\{X\}K INFER P\"{a}Q\"{\i}X\\
RULE "P\"{a}Q\"{y}K, P$\triangleleft$\{X\}K\={} $=>$ P\"{a}Q\"{\i}X" IS FROM P\"{a}Q\"{y}K AND P$\triangleleft$\{X\}K\={} INFER P\"{a}Q\"{\i}X\\
RULE "P\"{a}(P,Q)\"{u}Y, P$\triangleleft$\texttt{<}X\texttt{>}Y $=>$ P\"{a}Q\"{\i}X" IS FROM P\"{a}(P,Q)\"{u}Y AND P$\triangleleft$\texttt{<}X\texttt{>}Y INFER P\"{a}Q\"{\i}X\\
RULE "P\"{a}\#X, P\"{a}Q\"{\i}X $=>$ P\"{a}Q\"{a}X" IS FROM P\"{a}\#X AND P\"{a}Q\"{\i}X INFER P\"{a}Q\"{a}X\\
RULE "P\"{a}Q\"{o}X, P\"{a}Q\"{a}X $=>$ P\"{a}X" IS FROM P\"{a}Q\"{o}X AND P\"{a}Q\"{a}X INFER P\"{a}X

RULE "P$\triangleleft$\texttt{<}X\texttt{>}Y $=>$ P$\triangleleft$X" IS FROM P$\triangleleft$\texttt{<}X\texttt{>}Y INFER P$\triangleleft$X\\
RULE "P\"{a}(P,Q)$<->$K, P$\triangleleft$\{X\}K $=>$ P$\triangleleft$X" IS FROM P\"{a}(P,Q)$<->$K AND P$\triangleleft$\{X\}K INFER P$\triangleleft$X\\
RULE "P\"{a}P\"{y}K, P$\triangleleft$\{X\}K $=>$ P$\triangleleft$X" IS FROM P\"{a}P\"{y}K AND P$\triangleleft$\{X\}K INFER P$\triangleleft$X\\
RULE "P\"{a}Q\"{y} K, P$\triangleleft$\{X\}K\={} $=>$ P$\triangleleft$X" IS FROM P\"{a}Q\"{y} K AND P$\triangleleft$\{X\}K\={} INFER P$\triangleleft$X\\
RULE "P\"{a}(R,R')$<->$K $=>$ P\"{a}(R',R)$<->$K" IS FROM P\"{a}(R,R')$<->$K INFER P\"{a}(R',R)$<->$K\\
RULE "P\"{a}Q\"{a}(R,R')$<->$K $=>$ P\"{a}Q\"{a}(R,R')$<->$K" IS FROM P\"{a}Q\"{a}(R,R')$<->$K INFER P\"{a}Q\"{a}(R',R)$<->$K\\
RULE "P\"{a}(R,R')\"{u}K $=>$ P\"{a}(R',R)\"{u}K" IS FROM P\"{a}(R,R')\"{u}K INFER P\"{a}(R',R)\"{u}K\\
RULE "P\"{a}Q\"{a}(R,R')\"{u}K $=>$ P\"{a}Q\"{a}(R',R)\"{u}K" IS FROM P\"{a}Q\"{a}(R,R')\"{u}K INFER P\"{a}Q\"{a}(R',R)\"{u}K

RULE "P\"{a}∀x.X(x) $=>$ P\"{a}X(Y)"(Y,ABSTRACTION X) IS FROM P\"{a}∀x.X(x) INFER P\"{a}X(Y)


We've had to include \textit{hyp} so that we can use assumptions. \textit{Cut} allows us to mimic forward proof. Left-weakening means that we can use theorems which don't match all the hypotheses:

RULE hyp IS INFER X ⊦ X\\
RULE cut(X) IS FROM X AND X ⊦ Y INFER Y\\
RULE weaken(X) IS FROM Y INFER X ⊦ Y\\
IDENTITY hyp\\
CUT cut\\
WEAKEN weaken


\textit{Putting rules into menus}


Organising these into menus is quite a problem. We've included a menu for each operator and put each rule into all the menus which seem relevant to it: for example, "P\"{a}(Q,P)$<->$K, P$\triangleleft$\{X\}K $=>$ P\"{a}Q\"{\i}X" is in the menus for $<->$, $\triangleleft$ and \"{\i}. Only \textit{hyp} and the rule dealing with \ensuremath{\forall} are in a menu labelled `Logic'.


We have implemented forward reasoning in the style of chapter 4; then, for example when "P\"{a}(Q,P)$<->$K, P$\triangleleft$\{X\}K $=>$ P\"{a}Q\"{\i}X" is included in the $<->$ menu we have

ENTRY "P\"{a}(Q,P)$<->$K, [P$\triangleleft$\{X\}K] $=>$ P\"{a}Q\"{\i}X"\\
\tab IS ForwardOrBackward ForwardCut 0 "P\"{a}(Q,P)$<->$K, P$\triangleleft$\{X\}K $=>$ P\"{a}Q\"{\i}X"


in the $\triangleleft$ menu we have

ENTRY "P$\triangleleft$\{X\}K, [P\"{a}(Q,P)$<->$K] $=>$ P\"{a}Q\"{\i}X" IS \\
\tab ForwardOrBackward ForwardCut 1 "P\"{a}(Q,P)$<->$K, P$\triangleleft$\{X\}K $=>$ P\"{a}Q\"{\i}X"


The square-bracketted antecedent in the menu entry is the one that \textit{isn't} focussed upon in that step. The whole gory details are in the file BAN\_menus.j. We may not have included the rules in enough menus or enough times (for example, we probably ought to have "P\"{a}(Q,P)$<->$K, P$\triangleleft$\{X\}K $=>$ P\"{a}Q\"{\i}X" in the \"{\i} menu twice, focussing once on each antecedent). We haven't had enough users to know if we have got this bit of user interaction right.


\textit{Dealing with tuples}


We've generalised some of the BAN rules: for example, we have implemented\\


\begin{tabular}{|p{1.082in}|p{1.082in}|p{1.082in}|p{1.082in}|p{0.043in}|p{0.043in}|p{0.043in}|p{0.043in}|} \hline
% ROW 1
{\raggedright $\frac{PX_{1} \quad ...\quad PX_{n} }{P\left( X_{1},...,X_{n} \right) } $ } & {\raggedright $\infer{PX}
       {P\left( ...,X,...\right) }$ } & {\raggedright } & {\raggedright }\\
\hline \end{tabular}


for 2-, 3- and 4-tuples. We've done it, as you ought to expect, by listing each version of the rule and combining them with the \textsc{rules} directive:

RULES "... P\"{a}X... $=>$ P\"{a}(...,X,...)" ARE\\
\tab FROM P\"{a}X AND P\"{a}Y\tab INFER P\"{a}(X,Y) \\
AND\tab FROM P\"{a}X AND P\"{a}Y AND P\"{a}Z\tab INFER P\"{a}(X,Y,Z) \\
AND\tab FROM P\"{a}W AND P\"{a}X AND P\"{a}Y AND P\"{a}Z\tab INFER P\"{a}(W,X,Y,Z)\\
END

RULES "P\"{a}(...,X,...) $=>$ P\"{a}X"(X) ARE \\
\tab FROM P\"{a}(X,Y)\tab INFER P\"{a}X \\
AND\tab FROM P\"{a}(Y,X)\tab INFER P\"{a}X \\
AND\tab FROM P\"{a}(X,Y,Z)\tab INFER P\"{a}X \\
AND\tab FROM P\"{a}(Z,X,Y)\tab INFER P\"{a}X \\
AND\tab FROM P\"{a}(Y,Z,X)\tab INFER P\"{a}X \\
AND\tab FROM P\"{a}(X,Y,Z,W)\tab INFER P\"{a}X \\
AND\tab FROM P\"{a}(W,X,Y,Z)\tab INFER P\"{a}X \\
AND\tab FROM P\"{a}(Z,W,X,Y)\tab INFER P\"{a}X \\
AND\tab FROM P\"{a}(Y,Z,W,X)\tab INFER P\"{a}X\\
END


The second group gives us an interesting forward proof problem. We would like to be able to select an item of a tuple and pick it out using one of these rules. To do so we need to be able to search the collection. Since our forward proof steps are all sequences ``\textit{cut; rule; select subgoal; hyp}'' we have to make sure on the second step that we select the right rule. We don't have a very good mechanism for that in our tactic language at present. The best we have come up with is a sort of automatic backtracking using \textsc{withcontinuation}.


\textsc{withcontinuation} \textit{tactic}$_{0}$ \textit{tactic}$_{1}$... \textit{tactic}$_{\textit{n}}$ sets the sequence \textit{tactic}$_{1}$... \textit{tactic}$_{\textit{n}}$ as a continuation, and runs \textit{tactic}$_{0}$. If \textit{tactic}$_{0}$ is an \textsc{alt}, or ends with an \textsc{alt}, it will add that continuation to each of its alternatives. The effect is that an alternative won't succeed unless the continuation \textit{tactic}$_{1}$... \textit{tactic}$_{\textit{n}}$ succeeds as well. If \textit{tactic}$_{0}$ doesn't end with an \textsc{alt}, then the effect is the same as \textsc{seq} \textit{tactic}$_{0}$ \textit{tactic}$_{1}$... \textit{tactic}$_{\textit{n}}$. We make our forward step tactics use \textsc{withcontinuation}:

TACTIC ForwardCut (n,Rule)\\
\tab SEQ cut (WITHCONTINUATION (WITHARGSEL Rule) (JAPE (SUBGOAL n)) (WITHHYPSEL hyp))\\
TACTIC ForwardUncut (n,Rule)\\
\tab WITHCONTINUATION (WITHARGSEL Rule) (JAPE (SUBGOAL n)) (WITHHYPSEL hyp)


Then we include in the \"{a} menu

ENTRY "P\"{a}Q\"{a}(...,X,...) $=>$ P\"{a}Q\"{a}X"\\
\tab IS ForwardOrBackward ForwardCut 0 "P\"{a}Q\"{a}(...,X,...) $=>$ P\"{a}Q\"{a}X"


and Bob's your uncle.


\textbf{{\large 9.3\tab Conjectures with long assumption lists}}


On educational grounds we thought it best to include lots of assumptions in each conjecture, simply because the problem for novices is to decide which assumptions are relevant and how. This makes very long conjectures. For example, one of the conjectures about the Needham-Schroeder protocol is

{\small THEOREM "Needham-Schroeder: A$\triangleleft$\{Na,(A,B)$<->$Kab,\#((A,B)$<->$Kab),\{(A,B)$<->$Kab\}Kbs\}Kas ⊦ A\"{a}(A,B)$<->$Kab" IS  \\
\tab \tab A\"{a}(A,S)$<->$Kas, S\"{a}(A,S)$<->$Kas, B\"{a}(B,S)$<->$Kbs, S\"{a}(B,S)$<->$Kbs, S\"{a}(A,B)$<->$Kab,\\
\tab \tab A\"{a}(∀k.S\"{o}(A,B)$<->$k), B\"{a}(∀k.S\"{o}(A,B)$<->$k), A\"{a}(∀k.S\"{o}\#((A,B)$<->$k)), \\
\tab \tab A\"{a}\#Na, B\"{a}\#Nb, S\"{a}\#((A,B)$<->$Kab), B\"{a}(∀k.\#((A,B)$<->$k)), \\
\tab \tab A$\triangleleft$\{Na,(A,B)$<->$Kab,\#((A,B)$<->$Kab),\{(A,B)$<->$Kab\}Kbs\}Kas \\
\tab \tab ⊦ A\"{a}(A,B)$<->$Kab}


Jape automatically folds long assumption lists in a box display to fit the proof window. The proof of this conjecture, in a moderately-sized window, is

\begin{figure}[htbp] \begin{center} \includegraphics[width=6.736in, height=2.986in]{oldpics/Roll_your_own_v3_2+Fig49} \caption{Fig49} \end{center} \end{figure}




\begin{center} -  -


\end{center} \textbf{{\huge Appendix A\\
The paragraph and formula languages}}


The paragraph language is the one in which logics, their syntax, their rules, the tactics you intend to use and the menus of commands you intend to display are all defined. It uses a lot of reserved words: we add to the list as the need arises but all are multi-letter upper-case words, so it is a good idea to avoid use of that kind of word in your encodings.


At the time of writing the complete list of reserved words is


\textsc{abstraction, and, are, automatch, autounify, bag, bind, button, checkbox, class, concfresh, conchit, conjecturepanel, constant, currentproof, cut, end, entry, fonts, formula, fresh, from, hypfresh, hyphit, identity, in, infer, infix, infixc, initially, initialise, is, judgement, juxtfix, leftfix, leftweaken, list, menu, menukey, notin, number, object, outfix, postfix, prefix, prefixbutton, proof, radiobutton, rightweaken, rule, rules, scope, separator, sequent, string, structurerule, substfix, tactic, tacticpanel, theorem, theorems, theory, unifieswith, use, variable, view, weaken, where}


\textbf{{\large A.1\tab Directives}}


In this description I use [... {\textbar}... ] to describe alternatives, \{... \} to describe optional components and ellipsis to denote optional repetition.


\textsc{abstraction}: decorates a parameter in a \textsc{rule} or \textsc{theorem} directive. When the rule is instantiated, applications of this parameter to arguments are translated into substitutions, with a substitution variable which is made an \textsc{object} parameter of the rule. The effect is to simulate predicate notation with that parameter.


\textsc{and}: separator\\
\textsc{are}: separator


\textsc{automatch} \textit{tacticname,..., tacticname}: at the end of each proof step, run the tactics (usually they are rules) specified over each open tip of the tree, but only allow them to work by `matching' -- that is, don't allow any unknowns in the tree to change as a result of running the tactic (see also \textsc{match} in the tactic language).


\textsc{autounify} \textit{tacticname,..., tacticname}: same as \textsc{automatch} but without the restriction on working by `matching'. This directive is less used than \textsc{automatch}, chiefly because it is easy to make automatic steps which make large and/or unexpected and/or unhelpful changes to a proof. But sometimes it is the right thing: see for example the way that the Hindley-Milner algorithm encodings use \textsc{autounify} to determine the type of constants.


\textsc{bag \{} \texttt{<}kind\texttt{>} \textsc{\}} \textit{names}: see the discussion of flexible syntax below.


\textsc{bind} \textit{variable... variable} \textsc{scope} \textit{name... name} \textsc{in} \textit{formula}: see the discussion of flexible syntax below.\\
\textsc{button:} this allows you to attach a command to a label in a menu or a button on a panel. See appendix C for information on the command language.


\textsc{checkbox} \textit{variable label} \{ \textsc{initially [} true {\textbar} false ] \}: a checkbox is created associated with the named variable. If the variable doesn't exist in Jape's default environment this directive declares it, and its range of values will be true and false; if it exists, those must already be its range. The initial value, if included, is immediately assigned to the variable.


\tab In a menu, \textit{label} appears ticked or unticked according to whether or not the value of \textit{variable} is true or false; in a panel you see a proper user-interface checkbox with that label.


\textsc{class}  \texttt{<}kind\texttt{>} \textit{names}: see the discussion of flexible syntax below.


\textsc{concfresh} \textit{variable}: proviso that \textit{variable} doesn't occur free in any right-hand-side formula of the consequent of a proof step. See \textsc{fresh}.


\textsc{conchit} \{ \{ \textit{formula1} \} \texttt{<}entails\texttt{>} \} \textit{formula2} \textsc{is} \textit{tactic}: if the user double-clicks on a right-hand-side formula matching \textit{formula2} then run \textit{tactic}. If \textit{formula1} also appears, then either the sequent must have a single left-hand-side formula matching it, or the user must also have selected a left-hand-side formula matching it. See also \textsc{hyphit} below.


\textsc{conjecturepanel} \textit{name} \{ \textsc{is} \} [ \textit{entry} {\textbar} \textit{button} ]* \textsc{end}: build a panel of conjectures. Each \textit{entry} is one of \textsc{entry}, \textsc{theorem, theorems, proof, currentproof}; each \textit{button} is one of \textsc{button, prefixbutton, radiobutton, checkbox}. \textsc{entry}, \textsc{theorem} and \textsc{theorems} add entries to the list of conjectures which forms part of the panel; \textsc{proof} and \textsc{currentproof} are used in the proof save and reload mechanism. \\
\tab In addition to the buttons explicitly described, every conjecture panel always has ``New\dots '', ``Prove'' and ``Show{\nobreakspace}Proof'' buttons, and if there isn't a description of an ``Apply'' button then one is added as if you had written ``\textsc{prefixbutton} Apply \textsc{is} apply''. Like \textsc{menu} (q.v.), a panel description can be divided into sections, and the complete description is just the concatenation of the various parts.


\textsc{constant} \textit{name... name}: the \textit{name}s are defined to have the syntactic class \textsc{constant}. See the discussion of flexible syntax below.


\textsc{currentproof} \textit{name sequent} \{ \textsc{where} \textit{proviso} \textsc{and... and} \textit{proviso} \textsc{\} is} \textit{tactic}: same as \textsc{proof} (q.v. below), except that the proof of \textit{sequent} built by \textit{tactic} need not be complete, is not recorded in the proof store, and is displayed on the screen.


\textsc{cut} \textit{rulename}: synonym for \textsc{structurerule} \textsc{cut}; declares that the rule called \textit{rulename} is a `cut' rule, provided that it meets certain conditions (see below). Applications of the rule will normally be hidden in the box display mode of Jape. This directive is required before Jape will properly interpret the `tryresolution' variable (see appendix C).


\textsc{end:} closer in lots of directives.


\textsc{entry} \textit{name} \{ \{ \textsc{is} \} \textit{tactic} \} \{ \textsc{menukey} \textit{letter} \}: used to describe an entry in a menu or in the list of a panel. May only appear as part of a \textsc{menu} or \textsc{panel} directive; \textsc{menukey} is permitted only when part of a \textsc{menu} directive. The label is \textit{name}; if the \textit{tactic} component is omitted then the tactic expression \textit{name} is used; if the \textsc{menukey} component is included then \textit{letter} is used as the `command key' of that label. When the label is selected in a menu, the command ``apply \textit{tactic}'' is transmitted to the proof engine; when the label is selected in a panel, there is no effect until a \textsc{prefixbutton} (q.v.) is pressed.


\textsc{fonts} \textit{name}: the font-encoding name \textit{name} is transmitted to the graphical interface. At the time of writing our interfaces only recognise ``Konstanz'', but watch this space...\\
\textsc{formula} \textit{name... name}: the \textit{name}s are declared to be in the syntactic class \textsc{formula}. See discussion of flexible syntax below.


\textsc{fresh} \textit{variable}: proviso in a rule or theorem. \textit{Variable} mustn't appear free in any hypothesis or conclusion of the sequent to which the rule or theorem is applied; is translated into \textsc{notin} provisos for each of the formulae of that sequent.


\textsc{from}: separator in \textsc{rule} directive.\\
\textsc{hypfresh} \textit{variable}: \textit{variable} doesn't occur free in any hypothesis of the problem sequent. See \textsc{fresh.}


\textsc{hyphit} \textit{formula}1 \texttt{<}entails\texttt{>} \{ \textit{formula}2 \} \textsc{is} \textit{tactic}: if the user double-clicks on a left-hand-side \textit{formula}1 then run \textit{tactic}. If \textit{formula}2 appears then either the sequent must have a single right-hand side which matches \textit{formula}2, or the user must also select a right-hand-side formula matching \textit{formula}2 in order for the directive to fire.


\textsc{identity} \textit{rulename}: synonym for \textsc{structurerule} \textsc{identity}; the rule named \textit{rulename} is declared to be a `identity' rule. Instances of the application of this rule are normally hidden in box display mode.


\textsc{in}: connective in binding directive.\\
\textsc{infer}: connective in \textsc{rule} directive.


\textsc{infix} \textit{precedence} [ L {\textbar} R {\textbar} T ] \textit{operatorname... operatorname}: the names are declared to be infix binary operators with the given precedence; L means left-associative, R right-associative, T tupling. Instances of formulae such as \textit{A} \textit{op} \textit{B} are then treated internally as if they were `uncurried' function applications -- that is, as if you had written (\textit{op})(\textit{A},\textit{B}). See discussion of flexible syntax below.


\textsc{infixc} \textit{precedence} [ L {\textbar} R {\textbar} T ] \textit{operatorname... operatorname}: very similar to \textsc{infix} (q.v. above), but parsed `curried' so that \textit{A} \textit{op} \textit{B} is then treated internally as if you had written (\textit{op}) \textit{A} \textit{B}.


\textsc{initially}: part of the \textsc{radiobutton} and \textsc{checkbox} directives.


\textsc{initialise} \textit{variablename} \textit{value}: the variable named is assigned the value given. See the discussion of variables in appendix C.


\textsc{is}: connective, often omitted.


\textsc{judgement is} [ \textsc{bag} {\textbar} \textsc{list} {\textbar} \textsc{formula} ] \textit{turnstile} [ \textsc{bag} {\textbar} \textsc{list} {\textbar} \textsc{formula} ]: same as \textsc{sequent} directive (see below), except that in box display a \textsc{judgement} form is always displayed complete, on a conclusion line. That is, the left-hand side is not treated as a collection of hypotheses in box display.


\textsc{juxtfix} \textit{precedence}: defines syntactic precedence of juxtaposition: see discussion of flexible syntax below.\\
\textsc{leftfix} \textit{precedence leftbra punct}1\textit{... punctN}: defines syntactic precedence and form of bracketed form which misses a closing bracket. See discussion of flexible syntax below.


\textsc{leftweaken} \textit{rulename}: synonym for \textsc{structurerule} \textsc{leftweaken}; declares that the rule called \textit{rulename} is a `left weakening' rule. Essential if Jape is to be able to apply theorems which don't have enough hypotheses to match the whole of the problem sequent.


\textsc{list \texttt{<}}kind\textsc{\texttt{>}} \textit{names}: see the discussion of flexible syntax below.


\textsc{menu} \textit{name} \textsc{is} \textit{entry.... entry} \textsc{end}: the effect of the entries (which can be \textsc{rule, rules, tactic, theorem, theorems, theory, proof, currentproof, entry, button, radiobutton, checkbox} or \textsc{separator)} are added to the menu named \textit{name}. \textsc{menu} directives for the same menu are accumulated in sequence, and need not be given all in one place.


\textsc{menukey} \textit{letter}: part of the \textsc{entry} directive when used inside a \textsc{menu} description.


\textit{name} \textsc{notin} \textit{formula}: a proviso that \textit{name} must not occur free in \textit{formula}. Often generated as the result of a \textsc{fresh, hypfresh} or \textsc{concfresh} proviso; sometimes included in its own right.\\
\textsc{number} \textit{name... name}: the \textit{name}s are declared to be in the syntactic class \textsc{number}. See the discussion of flexible syntax below.


\textsc{object} \textit{name}: decorates a parameter in a \textsc{rule} or \textsc{theorem} directive. When the rule is instantiated, the parameter is replaced by a newly-minted object variable rather than an unknown, unless this default assignment is overridden by provision of an argument formula.


\textsc{outfix} \textit{leftbra punct}1\textit{... punctN rightbra}: see the discussion of flexible syntax below.\\
\textsc{postfix} \textit{precedence operator... operator}: see discussion of synctactic directives below\\
\textsc{prefix} \textit{precedence operator... operator}: see discussion of synctactic directives below.


\textsc{prefixbutton} \textit{label} \{ \textsc{is} \} \textit{command}: in a panel, a button with label \textit{label} is added. When the button is pressed and an entry which indexes \textit{text} is selected, then the string ``\textit{command text}'' is passed to the proof engine.


\textsc{proof} \textit{name sequent} \{ \textsc{where} \textit{proviso} \textsc{and... and} \textit{proviso} \textsc{\} is} \textit{tactic}: both \textsc{proof} and \textsc{currentproof} are generated when you save proofs. You will probably never want to write one yourself, but this is what \textsc{proof} means: \textit{sequent} is a statement of the conjecture named \textit{name}, and \textit{tactic}, when run, will produce a proof of that conjecture with the given provisos. If it all works out: if \textit{sequent} unifies with the statement of conjecture \textit{name}, if \textit{tactic} produces a completed proof without introducing any additional unifications or inventing more or less provisos, then the resulting proof is stored under \textit{name} in the proof store.


\textsc{radiobutton} \textit{variablename} \{ \textsc{is} \} \textit{label} \{ \textsc{is} \} \textit{value} \{ \textsc{and} \textit{label} \{ \textsc{is} \} \textit{value} \}* \{ \textsc{initially} \textit{value} \} \textsc{end}: a radio button with the list of labels given is associated with the named variable. If that variable doesn't exist it is declared by this directive, and its range of possible values is those given here; if it does exist the values given here must be in its range. If an initial value is given, the variable is assigned that value immediately.


\tab In a menu a radio button is shown as a sequence of labels, one of which is ticked according to the value of the variable; in a panel it is a proper Macintosh-style radio button.\\
\textsc{rightweaken}: same as \textsc{structurerule} \textsc{rightweaken}{\large .} Similar to \textsc{leftweaken} above, and plays a similar r\^{o}le in theorem application.


\textsc{rule{\nobreakspace}}\textit{rule}: definition of a rule. Puts a rule with name \textit{name} into the tactic store; if it appears inside a \textsc{menu} definition then the effect is also of \textsc{entry} \textit{name} \textsc{is} \textit{name}. See `rules, tactics and conjectures' below for more explanation.


\textsc{rules} \textit{name} \{ ( \textit{params} ) \} \{ \textsc{where} \textit{provisos} \} \textsc{are} \textit{rule}1 \textsc{and... and} \textit{ruleN} \textsc{end}: definition of a number of rules, organised automatically into an \textsc{alt} tactic.


\tab Each \textit{rule} is an unnamed rule definition (see `rules, tactics and conjectures below); each is considered to be qualified by \textit{params} and \textit{provisos} from the head of the directive, filtered according to the names that occur in each rule (that is, if a particular parameter doesn't occur in a rule, you don't get that parameter declaration with that rule, and you don't get any provisos that mention it). The rules are entered into the tactic store under the names \textit{name'1... name'N}; at the same time a tactic \textsc{alt} \textit{name'1... name'N} is entered under \textit{name}.


\tab If it occurs in a menu or a panel, \textsc{rules} \textit{name...} has the effect also of \textsc{entry} \textit{name}: that is, only one entry appears in the menu.


\textsc{scope}: part of the \textsc{bind} directive.


\textsc{separator}: used in the definition of a \textsc{menu}, gives a division between entries. On a panel, probably has no effect.\\
\textsc{sequent is}  \textsc{bag} {\textbar} \textsc{list} {\textbar} \textsc{formula} ] \texttt{<}entails\texttt{>} \textsc{bag} {\textbar} \textsc{list} {\textbar} \textsc{formula} ]: see discussion of flexible syntax below.


\textsc{string} \textit{name,..., name}: see the discussion of flexible syntax below.


\textsc{structurerule} \textit{kind} \textsc{is} \textit{name}: \textit{kind} must be \textsc{cut}, \textsc{identity}, \textsc{leftweaken, rightweaken} or \textsc{weaken}; \textit{name} must be the name of a rule in the tactic store. See `structural rules' below, and see the discussion of each of the \textit{kind}s in this list.


\textsc{substfix} \textit{precedence} \{ \textit{bra fst sep snd ket} \}: defines the syntactic precedence of substitution forms and, optionally, their appearance as well. See the discussion of flexible syntax below.


\textsc{tactic} \textit{name} \{ ( \textit{name}1\textit{,..., nameN} ) \} \{ \textsc{is \}} \textit{tactic}: puts a tactic with name \textit{name} and parameters \textit{name}1\textit{,..., nameN} into the tactic store. If it appears inside a \textsc{menu} or \textsc{panel} definition then the effect is also of \textsc{entry} \textit{name}; in a \textsc{tacticpanel} it has the effect of \textsc{entry} \textit{name} \textsc{is} apply \textit{name}. See `rules, tactics and conjectures' below for more explanation.


\textsc{tacticpanel} \textit{name} \{ \textsc{is} \} [ \textit{entry} {\textbar} \textit{button} ]* \textsc{end}: very like \textsc{conjecturepanel} above, except that there are no extra buttons and no default buttons and each entry labels a command rather than a conjecture. Tactics, rules and conjectures included in a \textsc{tacticpanel} description are associated with the command ``apply \textit{name}'' where \textit{name} is the name of the tactic, rule or conjecture.


\textsc{theorem} \textit{conjecture}: puts a conjecture into the tactic store. Jape's conjectures are always `theorem schemata', in the sense that they stand for any substitution-instance of \textit{sequent}. See `rules, tactics and conjectures' below for more explanation.


\textsc{theorems} \textit{name} \{ \textit{params} \} \{ \textsc{where} \textit{provisos} \} \textsc{are} \textit{theorem1} \textsc{and}... \textsc{and} \textit{theoremN} \textsc{end}: define a collection of conjectures which are organised into an \textsc{alt} tactic.


\tab Each \textit{theorem} is an unnamed conjecture (see `rules, tactics and conjectures' below); each theorem is added to the tactic store prefixed by \textit{params} and \textit{provisos} in the same way as in the \textsc{rules} directive (q.v. above); at the same time a tactic \textsc{alt} \textit{theorem1... theoremN} is added to the tactic store under \textit{name}. If included in a menu or panel description, an \textsc{entry} is created for each conjecture. The effect is to define a number of conjectures with evocative names, and to allow searching of the collection if desired. See also \textsc{theorem} above.


\textsc{theory} \textit{name} \{ \textsc{is} \} \textit{directive... directive} \textsc{end}: the directives may be \textsc{rule, rules, tactic, theorem, theorems} or \textsc{theory}; an \textsc{alt} tactic is made of the various directives and added to the tactic store under \textit{name}. If \textsc{theory} occurs in a menu or panel description, the effect is as if the directives occurred separately (that is, Jape does not add an entry corresponding to the overall \textsc{alt} tactic).


\textit{formula} \textsc{unifieswith} \textit{formula}: a proviso which requires that the two formulae should unify. Used to delay unification when difficult substitutions get in the way.


\textit{collection} \textsc{unifieswith} \textit{collection}: a proviso which helps when contexts are split. See chapter 3.\\
\textsc{use} ``\textit{filename}'': same effect as C's \#include ``\textit{filename}''.\\
\textsc{variable} \textit{name... name}: see the discussion of identifier classes below.\\
\textsc{weaken}: synonym for \textsc{leftweaken} (q.v. above).\\
\textsc{where}: prefixes a list of proviso declarations.


\textbf{{\large A.2\tab Rules, tactics and conjectures}}


The syntax of rules and conjectures can take various forms. The syntax is:


\{ \textit{name} \} \{ ( \textit{param},..., \textit{param} ) \} \{ \textsc{where} \textit{proviso} \textsc{and... and} \textit{proviso} \} \{ \textsc{is} \} \textit{body}


Note that almost every part is optional, apart from the body of the rule or conjecture. Note also that, for obvious reasons, if parameters or provisos are included then either the \textsc{is} word must be included, or else \textit{body} must start with \textsc{from} or \textsc{infer}.


In a conjecture, \textit{body} is


\{ \textsc{infer \}} \textit{sequent}


In a rule, \textit{body} is


\{ \textsc{from} \textit{antecedent} \textsc{and... and} \textit{antecedent} \} \{ \textsc{infer \}} \textit{consequent}


If the conjecture is un-named, its name is taken to be \textit{sequent}; if a rule is un-named, its name is taken to be \textit{consequent}\\
Each \textit{param} is either a name, \textsc{object} followed by a name or \textsc{abstraction} followed by a name: in every case the name must have been declared in a \textsc{class} directive. Each proviso is either

\textsc{concfresh} \textit{name},..., \textit{name}\\
\textsc{hypfresh} \textit{name},..., \textit{name}\\
\textsc{fresh} \textit{name},..., \textit{name}\\
\textit{name} \textsc{notin} \textit{formula}\\
\textit{formula} \textsc{unifieswith} \textit{formula}


where the names used must be parameters of the rule or conjecture.


\textit{The meaning of a \textsc{rule} directive}


Ignoring parameters for the moment, the rule


$\infer[\reason{$(prov1,...,provN)\;rule$}]
       {conse}
       {ante1\quad ...\quad anteM}$

with name \textit{rule}, antecedent sequents \textit{ante1}... \textit{anteM}, consequent \textit{conse} and provisos) \textit{prov1}... \textit{provN} is stated as the rule directive


\textsc{rule} \textit{rule} \textsc{where} \textit{prov1} \textsc{and... and} \textit{provN} \textsc{is from} \textit{ante}1 \textsc{and.... and} \textit{anteM} \textsc{infer} \textit{conse}


A rule is schematic in all names appearing in the antecedents, consequents or provisos which are declared in a \textsc{class} directive. When the rule is applied to a problem sequent, a version of the rule is produced in which all the schematic names have been replaced by new unknowns, and then the consequent of that version is unified with the problem sequent.


Rule matching is linear -- formulae that are matched in the consequent are used up, and aren't copied to the antecedent unless you write them there. For example the sequent calculus `\ensuremath{->} on the left' rule


$\infer[\reason{$->|- $}]
       {\Gamma,A->B |- \Delta }
       {\Gamma  |- A,\Delta \quad \Gamma,B |- \Delta }$

is stated as


\textsc{rule} ``\ensuremath{->}⊦'' \textsc{is from} \textsc{\ensuremath{\Gamma}} \textsc{⊦} \textit{A}, Δ \textsc{and} \textsc{\ensuremath{\Gamma}}\textsc{,} \textit{B} ⊦ Δ \textsc{infer} \textsc{\ensuremath{\Gamma}}, \textit{A}\ensuremath{->}\textit{B} ⊦ Δ


and the `multiplicative' or `context-splitting' version of that rule


$\infer[\reason{$->|- $}]
       {\Gamma 1,\Gamma 2,A->B |- \Delta 1,\Delta 2}
       {\Gamma 1 |- A,\Delta 1\quad \Gamma 2,B |- \Delta 2}$

as


\textsc{rule} ``\ensuremath{->}⊦'' \textsc{is from} \textsc{\ensuremath{\Gamma}1} \textsc{⊦} \textit{A}, Δ2 \textsc{and} \textsc{\ensuremath{\Gamma}2}\textsc{,} \textit{B} ⊦ Δ2 \textsc{infer} \textsc{\ensuremath{\Gamma}1, \ensuremath{\Gamma}2}, \textit{A}\ensuremath{->}\textit{B} ⊦ Δ1, Δ2


If you want a version in which the implication formula is not used up


$\infer[\reason{$->|- $}]
       {\Gamma,A->B |- \Delta }
       {\Gamma,A->B |- A,\Delta \quad \Gamma,B |- \Delta }$

then you can have it:


\textsc{rule} ``\ensuremath{->}⊦'' \textsc{is from} \textsc{\ensuremath{\Gamma}}, \textit{A}\ensuremath{->}\textit{B} \textsc{⊦} \textit{A}, Δ \textsc{and} \textsc{\ensuremath{\Gamma}}\textsc{,} \textit{B} ⊦ Δ \textsc{infer} \textsc{\ensuremath{\Gamma}}, \textit{A}\ensuremath{->}\textit{B} ⊦ Δ


If either of the \textit{autoAdditive} variables is set to \textit{true} (see appendix C) then some of these rules can be defined as rules often are in natural deduction presentation, without mentioning unmatched hypotheses and/or conclusions. For example, if \textit{autoAdditiveLeft} is \textit{true}, the rule


$\infer[\reason{$->|- $}]
       {\Gamma,A->B |- C}
       {\Gamma  |- A\quad \Gamma,B |- C}$

can be stated as


\textsc{rule} ``\ensuremath{->}⊦'' \textsc{is from} \textit{A} \textsc{and} \textit{B} ⊦ \textit{C} \textsc{infer} \textit{A}\ensuremath{->}\textit{B} ⊦ \textit{C}


\textit{Parameters in \textsc{rule} directives}


Rule parameters are used for a number of reasons:


{\textbullet}\tab On instantiation the first parameter is replaced by the user's text selection, rather than an unknown. This is useful when that parameter doesn't appear in the consequent or is the replacing formula in a substitution form in the consequent (see the discussions of substitution matching below and in various chapters above);


{\textbullet}\tab A parameter which is decorated with \textsc{object} is replaced with a freshly-minted name, rather than a new unknown.\\
{\textbullet}\tab a parameter which is decorated with \textsc{abstraction} is treated as a predicate, and juxtapositions involving that parameter are translated into substitution forms -- see below.


{\textbullet}\tab parameters are used to drive the `proof reload' mechanism.


\textit{Instantiating a rule, including interpretation of predicate notation}


When a rule is instantiated, each of its schematic names is replaced by a freshly-minted unknown, whose name is based on the schematic name itself. This instantiation is modified in case the name is a parameter (see above), if an \textit{autoAdditive} parameter is set to true, or if \textit{interpretpredicates} is true.\\
When an \textit{autoAdditive} parameter is true, a rule is automatically extended so that all the hypotheses (\textit{autoAdditiveLeft}) and/or the conclusions (\textit{autoAdditiveRight}) are extended with a freshly-minted segment variable, and all the antecedents likewise; then the augmented rule is instantiated normally.


When \textit{interpretpredicates} is true, juxtapositions in the rule are interpreted as predicate formulae and replaced by substitution forms; at the same time the parameter list is extended with \textsc{object} parameters as appropriate and the rule is augmented with invisible provisos. For example, a juxtaposition \textit{P}(\textit{x},\textit{y}) will be replaced by $P\left[ u,v\backslash x,y\right] $ ; the parameter list will be extended with \textsc{object} \textit{u}, \textsc{object} \textit{v}, and an invisible proviso \textit{x,y} \textsc{notin} \textit{P} will be added to the rule; every other `predicate' application of \textit{P} in the rule then has to have exactly two `arguments' and the same variables \textit{u} and \textit{v} will be used in those cases as well. Jape avoids substitution forms wherever possible by noting the context: for example, it will translate $@*x.@*y.P\left( x,y\right) $ as $@*x.@*y.P$ and then would translate $P\left( E,F\right) $ as $P\left[ x,y\backslash E,F\right] $ and in such an example there is no need for extra \textsc{object} parameters. For example, it will translate $\infer{|*x.P\left( x\right) }
       {P\left( E\right) }$ into $\infer{|*x.P}
       {P\left[ x\backslash E\right] }$ .


The latter form of rule is well-suited to backwards reasoning. The effect is to allow a kind of predicate notation while preserving Jape's existing unification mechanisms.


\textit{The meaning of provisos in \textsc{rule} and \textsc{theorem} directives}


Provisos are side conditions. At present we have a small number of built-in provisos, listed above. All the forms of \textsc{fresh} provisos are automatically translated into a collection of \textsc{notin} provisos -- one for each unmatched hypothesis and/or conclusion as appropriate.


Each time a rule is applied, its provisos are added to the set which is displayed in the bottom pane of the proof window. At the end of each proof step, that set of provisos is checked, and if any proviso is violated, the proof step is cancelled (memo to implementers: change the proof engine so that this is more obviously the way that things happen...). At the same time provisos which are satisfied are deleted from the set. The ones that are left are those whose status can't be decided, because of the presence of unknowns, substitution forms or names over which the conjecture being proved is quantified.


\textit{The meaning of conjectures (stated in \textsc{theorem} directives)}


A conjecture is stated as a rule without antecedents. Normally the first thing you do with a conjecture is to try to prove it. If that proof is successful, you can store it in the proof store and it will appear in the conjecture panel as a proved theorem. The provisos of a proved theorem are those given in the statement of the conjecture, plus any which arise and aren't satisfied during the proof.


Jape will normally refuse to apply a conjecture until it is proved, but you can tell it not to be so cautious if you wish by setting the variable \textit{applyconjectures} (see appendix C).


If the consequent of a theorem matches a problem sequent, but in so doing it doesn't use up all the hypotheses and conclusion formulae of the problem, then Jape is cautious. If the logic you are using has a declared \textsc{leftweaken} rule and there are too many hypotheses, then you could have first eliminated the extra hypotheses by applications of that rule, and then the theorem would have exactly used up all the remaining ones; similarly if it has a declared \textsc{rightweaken} rule and there are too many conclusions. But unless all that applies, the theorem will be said to be inapplicable.


\textit{Proof by resolution}


There is a facility to use a sort of resolution step when applying a theorem. If a theorem's conclusion(s) match but its hypotheses don't, and if there is a declared \textsc{cut} rule, then it would be possible to use a sequence of cuts to introduce the necessary extra hypotheses. In those circumstances Jape can introduce an antecedent for each of the hypotheses, and label the step with the name of the theorem. This feature is turned on and off by assigning to the \textit{tryresolution} variable (see appendix C). The effect is that if you have both right-weakening and cut, we treat a theorem $H_{1},...,H_{n}  |- C$ as equivalent to the rule $\frac{\Gamma  |- H_{1} \quad ...\quad \Gamma  |- H_{n} }{\Gamma  |- C} $ provided that $\Gamma,H_{1},...,H_{n}  |- C$ is a theorem; if you have cut but not right-weakening, we treat it as equivalent to $\frac{\Gamma  |- H_{1} \quad \Gamma,H_{1}  |- H_{2} \quad ...\quad \Gamma,H_{1},...,H_{n-1}  |- H_{n} }{\Gamma  |- C} $ with the same proviso.


\textit{The meaning of \textsc{structurerule} directives}


It is necessary for the application of conjectures as rules (see above), and for the proper operation of the box display mechanism, for Jape to be informed of the presence of certain kinds of structural rules in the logic. The rules we cater for are the various kinds of identity (hypothesis, axiom), cut and weakening rules.


At present Jape will recognise a rule as of the right form if it is in one of the following patterns (\ensuremath{\Gamma} is a bag of formulae, Δ a list of formulae, B and C are formulae).


\textsc{cut\tab (B) from} \textsc{{\large \ensuremath{\Gamma}}} \textsc{⊦} \textsc{B and} \textsc{{\large \ensuremath{\Gamma}}}\textsc{, B} \textsc{⊦} \textsc{{\large c}} \textsc{infer} \textsc{{\large \ensuremath{\Gamma}}} \textsc{⊦} \textsc{{\large c}}\\
\textsc{(B) from} \textsc{{\large \ensuremath{\Gamma}}} \textsc{⊦} \textsc{B,}\textsc{{\large \ensuremath{\Gamma}}}\textsc{'} \textsc{and} \textsc{{\large \ensuremath{\Gamma}}}\textsc{, B} \textsc{⊦} \textsc{{\large \ensuremath{\Gamma}}}\textsc{'} \textsc{infer} \textsc{{\large \ensuremath{\Gamma}}} \textsc{⊦} \textsc{{\large \ensuremath{\Gamma}}}\textsc{'}\\
\textsc{(B) from} \textsc{{\large \ensuremath{\Gamma}}} \textsc{⊦} \textsc{B,}\textsc{{\large \ensuremath{\Gamma}}}\textsc{'} \textsc{and} \textsc{{\large \ensuremath{\Gamma}}}\textsc{''}\textsc{, B} \textsc{⊦} \textsc{{\large \ensuremath{\Gamma}}}\textsc{'''} \textsc{infer} \textsc{{\large \ensuremath{\Gamma},\ensuremath{\Gamma}}}\textsc{''} \textsc{⊦} \textsc{{\large \ensuremath{\Gamma}}}\textsc{',}\textsc{\ensuremath{\Gamma}}\textsc{'''}\\
\textsc{weaken, leftweaken\\
(B) from} \textsc{\ensuremath{\Gamma}} \textsc{⊦} \textsc{C infer} \textsc{\ensuremath{\Gamma}}\textsc{,B} \textsc{⊦} \textsc{C \\
(B) from} \textsc{\ensuremath{\Gamma}} \textsc{⊦} \textsc{\ensuremath{\Gamma}}\textsc{'} \textsc{infer} \textsc{\ensuremath{\Gamma}}\textsc{,B} \textsc{⊦} \textsc{\ensuremath{\Gamma}}\textsc{'}

\textsc{rightweaken\\
(B) from} \textsc{\ensuremath{\Gamma}} \textsc{⊦} \textsc{\ensuremath{\Gamma}}\textsc{'} \textsc{infer} \textsc{\ensuremath{\Gamma}} \textsc{⊦} \textsc{B,}\textsc{\ensuremath{\Gamma}}\textsc{'}

\textsc{identity\tab }\\
\textsc{\ensuremath{\Gamma}}\textsc{,B} \textsc{⊦} \textsc{B}\\
\textsc{\ensuremath{\Gamma}}\textsc{,B} \textsc{⊦} \textsc{B,}\textsc{\ensuremath{\Gamma}}\textsc{'}\\
\textsc{Δ}\textsc{,B,}\textsc{Δ}\textsc{'} \textsc{⊦} \textsc{B}


\textit{Substitution matching}


Substitution forms are used in Jape to describe the operation of rules. They aren't intended to be interpreted as themselves -- that is, they are not a special sort of formula with associated introduction and elimination rules. There are instead mechanisms inside the proof engine designed to eliminate substitution forms whenever they arise by carrying out the substitutions they describe, and the intention is that substitution forms should normally be read as naming the formula to which they simplify. For example, consider Dijkstra's weakest precondition calculus assignment rule $\operatorname{wp}(x:=e,R)=R_{x}^{e} $, expressed in the notation of Hoare logic:


$\infer[\reason{$:=$}]
       {\left\{ R^{x}_{e} \right\} x:=e{R}}
       {}$

This can be expressed in Japeish as follows (see the file hoare\_rules.j):

{\small RULE ``:='' IS INFER \texttt{<}\{R[x{\textbackslash}E]\} x:=E \{R\}\texttt{>}}


Now suppose that we apply this rule to the problem sequent {\small \texttt{<}\{\_Q\} x:=1 \{x=1\}\texttt{>}}. If we apply the asignment rule then a version will be generated expressed in terms of new unknowns, which will be {\small \texttt{<}\{\_R[\_x1{\textbackslash}\_E]\} \_x1:=\_E \{\_R\}\texttt{>}}. However the unification proceeds, it will eventually have unified {\small (x=1)[x{\textbackslash}1]} with {\small \_Q}. Before that formula is displayed to the user it will be simplified to {\small 1=1}, and the rule will have done its job.\\
If the problem sequent had been {\small \texttt{<}\{1=1\} x:=1 \{x=1\}\texttt{>}}, then the unification process might first come across the problem of unifying {\small \_R[\_x1{\textbackslash}\_e]} with {\small 1=1}. Since that involves a substitution which won't simplify, it is deferred until later on. Unification of {\small x:=1} with {\small \_x1:=\_e} and of {\small x=1} with {\small \_R} mean that when the deferred problem must finally be considered, it has been transformed into that of unifying {\small (x=1)[x{\textbackslash}1]} with {\small 1=1}: the substitution form simplifies to {\small 1=1} and the unification is trivial.


But not every use of substitution forms in rules gives so little difficulty. When you define a rule with a substitution form in the consequent, and there aren't other occurrences of the components of the substitution form which will help to simplify it, matching becomes a problem. For example, consider the natural deduction \ensuremath{\forall} elimination rule:


$\infer[\reason{$@*\operatorname{elim}$}]
       {\Gamma  |- P[x\backslash E]}
       {\Gamma  |- @*x.P}$

If the problem sequent is, say, $a=b,b=c |- (a+b)+c=a+(b+c)$, then there are fourteen significantly different ways in which the consequent of the rule can match the problem:

1.\tab \textit{P} : (\textit{a}+\textit{b})+\textit{c}\ensuremath{=}\textit{a}+(\textit{b}+\textit{c}); \textit{x} : \textit{x}; \textit{E} : \textit{E}\\
2.\tab \textit{P} : (\textit{x}+\textit{b})+\textit{c}\ensuremath{=}\textit{a}+(\textit{b}+\textit{c}); \textit{x} : \textit{x}; \textit{E} : \textit{a}\\
3.\tab \textit{P} : (\textit{a}+\textit{b})+\textit{c}\ensuremath{=}\textit{x}+(\textit{b}+\textit{c}); \textit{x} : \textit{x}; \textit{E} : \textit{a}\\
4.\tab \textit{P} : (\textit{x}+\textit{b})+\textit{c}\ensuremath{=}\textit{x}+(\textit{b}+\textit{c}); \textit{x} : \textit{x}; \textit{E} : \textit{a}\\
5.\tab \textit{P} : (\textit{a}+\textit{x})+\textit{c}\ensuremath{=}\textit{a}+(\textit{b}+\textit{c}); \textit{x} : \textit{x}; \textit{E} : \textit{b}\\
6.\tab \textit{P} : (\textit{a}+\textit{b})+\textit{c}\ensuremath{=}\textit{a}+(\textit{x}+\textit{c}); \textit{x} : \textit{x}; \textit{E} : \textit{b}\\
7.\tab \textit{P} : (\textit{a}+\textit{x})+\textit{c}\ensuremath{=}\textit{a}+(\textit{x}+\textit{c}); \textit{x} : \textit{x}; \textit{E} : \textit{b}\\
8.\tab \textit{P} : (\textit{a}+\textit{b})+\textit{x}\ensuremath{=}\textit{a}+(\textit{b}+\textit{c}); \textit{x} : \textit{x}; \textit{E} : \textit{c}\\
9.\tab \textit{P} : (\textit{a}+\textit{b})+\textit{c}\ensuremath{=}\textit{a}+(\textit{b}+\textit{x}); \textit{x} : \textit{x}; \textit{E} : \textit{c}\\
10.\tab \textit{P} : (\textit{a}+\textit{b})+\textit{x}\ensuremath{=}\textit{a}+(\textit{b}+\textit{x}); \textit{x} : \textit{x}; \textit{E} : \textit{c}\\
11.\tab \textit{P} : \textit{x}+\textit{c}\ensuremath{=}\textit{a}+(\textit{b}+\textit{c}); \textit{x} : \textit{x}; \textit{E} : \textit{a}+\textit{b}\\
12.\tab \textit{P} : \textit{x}\ensuremath{=}\textit{a}+(\textit{b}+\textit{c}); \textit{x} : \textit{x}; \textit{E} : (\textit{a}+\textit{b})+\textit{c}\\
13.\tab \textit{P} : (\textit{a}+\textit{b})+\textit{c}\ensuremath{=}\textit{a}+\textit{x}; \textit{x} : \textit{x}; \textit{E} : \textit{b}+\textit{c}\\
14.\tab \textit{P} : (\textit{a}+\textit{b})+\textit{c}\ensuremath{=}\textit{x}; \textit{x} : \textit{x}; \textit{E} : \textit{a}+(\textit{b}+\textit{c})


It's clearly necessary to say in just which way the formula should match. Jape has two mechanisms which help. A statement of the rule which can make use of either mechanism is


\textsc{rule ``}\ensuremath{\forall} elim''(\textit{E}, \textsc{object} \textit{x}) \textsc{is from} \ensuremath{\Gamma} ⊦ \ensuremath{\forall}\textit{x}.\textit{P} \textsc{infer} \ensuremath{\Gamma} ⊦ \textit{P}[\textit{x{\textbackslash}E}]


The first mechanism, called `abstraction', finds matches in which every instance of a particular subformula is replaced by the substitution variable: for example, numbers 4, 7, 10, 11, 12, 13 and 14 in the lists of matches above. The abstraction mechanism is a kind of higher-order unification.


The first parameter of the rule, \textit{E}, can be replaced by an argument which is provided by text-selection (if you provide no argument then an unknown will silently be used): if you text-select \textit{a}, for example, then \textit{E} must be replaced by \textit{a} in the version of the rule that is generated. The second parameter, \textit{x}, is declared to be an \textsc{object}. This means that instead of generating an unknown, a freshly-minted identifier will be used in place of \textit{x} in the version of the rule that is generated. The parameter declarations say nothing about the name \textit{P}: it will always be replaced by an unknown.


Suppose, now, that you text-select \textit{a} and apply the rule. The generated consequent will be \ensuremath{\Gamma} ⊦\_\textit{P}[\textit{x{\textbackslash}a}], and the problem sequent $a=b,b=c |- (a+b)+c=a+(b+c)$ . Jape will try to unify \_\textit{P}[\textit{x{\textbackslash}a}] with (\textit{a}+\textit{b})+\textit{c}\ensuremath{=}\textit{a}+(\textit{b}+\textit{c}) and, by default, will try to turn the problem formula into a substitution by finding every occurrence of \textit{a} (the replacement formula in the substitution form) in the problem formula and replacing each of them by \textit{x} (the replacement variable in the substitution form). It succeeds, producing the formula (\textit{x}+\textit{b})+\textit{c}\ensuremath{=}\textit{x}+(\textit{b}+\textit{c}), which it unifies with \_\textit{P}. That is, of course, does \textit{not} generate a most general unifier of the original pair of formulae, but pragmatically it is often the one which you want.


If Jape can't find every instance of the replacement formula in the problem formula -- for example, if there are unknowns in either or both of them, or if either or both of them contain names over which the theorem being proved is quantified -- then it will generate a `deferred unification' proviso. That's a proviso \textit{formula} \textsc{unifieswith} \textit{formula}. When those appear it is often because you have done something silly: either you are going through the proof in an unhelpful order, or there is some additional information which could help to clarify the situation and avoid the deferred unifications.


The second mechanism is called user-defined substitution matching. The mechanism works together with the \textsc{withsubstsel} tactic (see appendix B and chapter 5). The user must text-select all the subformulas in the problem sequent which they want to be considered -- both the \textit{a}s, for example, or one of the \textit{bs}. Then the tactic \textsc{withsubstsel}(``\ensuremath{\forall} elim'') firsts constructs a `stable substitution form' based on those selections: if both the \textit{a}s it would build ((\_\textit{v}+\textit{b})+\textit{c}\ensuremath{=}\_\textit{v}+(\textit{b}+\textit{c}))[\_\textit{v}{\textbackslash}\textit{a}]; if the first \textit{b} it would build ((\textit{a}+\_\textit{v})+\textit{c}\ensuremath{=}\textit{a}+(\textit{b}+\textit{c}))[\_\textit{v}{\textbackslash}\textit{b}]. Then it applies the rule ``\ensuremath{\forall} elim'', which causes it to unify the new substitution form with \_\textit{P}[\textit{x}{\textbackslash}\_\textit{E}] from the rule: the unification process recognises the stable substitution form as something special, and pattern-matches the two, unifying \_\textit{P} with its body, \textit{x} with \textit{v} and \_\textit{E} with its replacement formula (\textit{a} in the first example, \textit{b} in the second). Jape hasn't constructed the most general unifier this time either, but it has justification, because it constructs the one which you asked for.


\textit{The tactic store}


Theorems are a kind of rule; rules are a kind of tactic. Tactics are programs whose primitive proof steps are the application of rules and/or theorems to problem sequents. The tactic store therefore contains all three in a single soup, indexed by name.


\textbf{{\large A.3\tab Fonts}}


Presentations of logics in textbooks and technical papers make use of special logical symbols, sometimes invented specially for the purposes of that particular logic, which can't easily be represented in the \textsc{ascii} character set. In polished presentations of logics in Jape we use special fonts -- but it is perfectly possible to use, and in the first instance you may want to use, combinations of \textsc{ascii} characters to approximate the special characters. Whatever font you use, it will need at least to include the normal \textsc{ascii} characters for identifiers, numbers, round and square brackets, quotation marks, backslash and comma as well as the special characters you need for your logical connectives and operators.


A description of a logic will therefore often begin by describing the font in which the logic is intended to be viewed. This will necessarily also be the font in which the logic description itself is written, and therefore you will need an 8-bit \textsc{ascii} text editor to create and modify the logic description\footnote{Under MacOS, we've found BBEdit Lite (freeware) very useful in preparing Jape logic descriptions, and thank its authors for their skill and philanthropy. Under X, Bernard has produced an 8-bit editor of his own called jed; it's part of the standard UNIX distribution of Jape.}. In practice the graphical interface part of Jape may use more than one font and more than one character size to handle proof display, menus and buttons. You therefore use the name of a `font encoding' to describe the whole scheme to Jape. The graphical examples in this manual are taken from the current implementation of Jape on MacOS, and they use Roy Dyckhoff's Konstanz and Detroit fonts in various sizes\footnote{Konstanz and Detroit fonts were produced by Roy Dyckhoff as part of the MALT project at the University of St Andrews. We are grateful to Roy for permission to use them and to distribute them with MacOS Jape.}. The name of the encoding is Konstanz, and there is a similar encoding in X Jape. The directive used in this and the other encodings in this manual is therefore

FONTS "Konstanz"


Other encodings are in preparation.


\textbf{{\large A.4\tab Flexible syntax}}


There are various ways in which you control what formulae can be written down and how they will be interpreted by Jape.


\textit{Symbols}


The rules of a logic are written in terms of various symbols -- logical operators and connectives as well as identifiers like \textit{A}, \textit{B} or \textit{x}. Jape reserves a few special characters -- they are double-quote, underscore, opening or closing parenthesis (round bracket), space, newline or tab -- which can't be used in symbols.


Jape recognises four distinct kinds of symbol:


{\textbullet}\tab \textit{identifiers}, which are rather like programming language identifiers or mathematical variable names: sequences of characters which start with an alphabetic character and optionally continue with any sequence of alphabetic and/or numeric characters and/or primes (\textsc{ascii} single quotes). Actually Jape's identifiers can start with any defined sequence of characters, given in a \textsc{class} directive, though some choices -- like using commas or arithmetic operator characters -- may be more confusing than useful.


{\textbullet}\tab \textit{unknowns}, which are are written as an underscore followed by an identifier.\\
{\textbullet}\tab \textit{numbers}, which are sequences of numeric characters.


{\textbullet}\tab \textit{strings}, which start with an \textsc{ascii} double-quote, continue with any sequence of characters not including newline or double-quote, and end with an \textsc{ascii} double-quote.


{\textbullet}\tab \textit{special symbols}, which are user-defined sequences of characters containing anything other than Jape's reserved characters. Everything else goes, though some choices -- like using primes or commas inside a special symbol -- may be more confusing than useful. Special symbols are defined in \textsc{infix, prefix, postfix, leftfix} and \textsc{outfix} directives.


Special symbols are always used as constants, and usually as operators or some kind of brackets, and they are defined implicitly by including them in various kinds of syntactic definitions. Identifiers can also be used as operators or brackets, by using them in just the same kind of syntactic definition.


Numbers, strings and special symbols are always constants of a logic -- they stand for themselves and not for anything else. Identifiers can be constants or they can stand for classes of things, like formulae, variables, or whatever\footnote{We haven't done the `whatever' bit, or not very much of it. But we know what we want to do, and we know how to do it...}.


\textit{Juxtaposition may need care}


Jape's syntax allows juxtaposition of formulae. You may have to use white space (blanks, spaces, newlines) to separate juxtaposed identifiers in some way -- \textit{xy}, without spacing, is usually a single identifier, whereas \textit{x y} is usually two juxtaposed identifiers and is equivalent to \textit{x}(\textit{y}), (\textit{x)y} or (\textit{x})(\textit{y}). Similarly, \textit{x}1 is usually a single identifier, whereas \textit{x} 1 is an identifier followed by a number. The syntactic priority of juxtaposition is user-defined.


Usually you can juxtapose special symbols without separation. If you define ¬ to be a special symbol, for example, and you don't also define ¬¬, then ¬¬\textit{x} is read as two ¬ symbols followed by an identifier.


\textit{Identifier classes}


Typically, you start the definition of a logic by saying what the various identifiers you are going to use `stand for' or `range over'. You can say that an identifier ranges over formulae, variables, numbers, strings, or constants; you can say that any identifier which starts with a particular prefix ranges over one of those categories. The directives are

\texttt{<}kind\texttt{>} \textit{names}\\
\textsc{class} \texttt{<}kind\texttt{>} \textit{names}


where \texttt{<}kind\texttt{>} is \textsc{formula, variable}, \textsc{constant, string}, \textsc{number}, \textsc{bag} \texttt{<}kind\texttt{>} or \textsc{list} \texttt{<}kind\texttt{>} and \textit{names} is a comma-separated list of identifiers or identifier prefixes.


The unprefixed directives -- such as, for example, \textsc{constant} \textit{map}, \textit{fold}, \textit{filter} -- define particular identifiers which are of a particular class. They are `object language' names and when they appear in rules or theorems, they won't be instantiated with anything. But they will unify with unknowns of the same kind.\\
The prefixed directives -- such as, for example, \textsc{class variable} \textit{x}, \textit{y}, \textit{z} -- define identifier prefixes which are of a particular kind. Every identifier or unknown which starts with one of those prefixes is of the specified kind and they are all `general' or `schematic' or `meta-language' names: when they appear in rules they are always instantiated with an unknown or an argument of the same kind.


Unknowns follow the same rules as identifiers: given the directives above, \_\textit{map} would be an unknown that would only unify with constants, \_\textit{x33} would be one that unified only with variables.\\
There isn't, at present, any way of defining a name that is of a kind which is a mixture of primitive kinds (\textsc{variable} and \textsc{constant}, for example), but \textsc{formula} includes all the other kinds.


\textit{Syntactic hierarchy}


Jape has a built-in notion of certain syntactic forms:


{\textbullet}\tab identifiers -- like \textit{A, ABC, A1, x, y, y37f,...} \\
{\textbullet}\tab strings -- ``\textit{anything at all}'' \\
{\textbullet}\tab numbers -- 1, 2, 46 \\
{\textbullet}\tab fully-bracketed formulae -- (\textit{formula})


{\textbullet}\tab substitutions -- by default \textit{formula} [ \textit{variable list} {\textbackslash} \textit{formula list} ], but the order of \textit{variable list} and \textit{formula list} can be reversed if you wish, and you can choose different symbols in place of `[`, `{\textbackslash}' and `];


{\textbullet}\tab juxtaposition (like function application in functional languages) -- \textit{formula formula};\\
{\textbullet}\tab prefix operators -- \textit{op formula};\\
{\textbullet}\tab postfix operators -- \textit{formula op};\\
{\textbullet}\tab infix operators -- \textit{formula op formula};


{\textbullet}\tab \textsc{leftfix} bracketing -- $bra\;f_{1} \;sep_{1} \;f_{2} \;sep_{2} ...sep_{n-1} \;f_{n} $



{\textbullet}\tab \textsc{outfix} bracketing -- $bra\;f_{1} \;sep_{1} \;f_{2} \;sep_{2} ...sep_{n-1} \;f_{n} ket$



In addition, comma (`,') is always a zero-precedence tupling operator, so that tuples -- \textit{formula}, \textit{formula},..., \textit{formula} -- are automatically available, with or without brackets.


Both substitution and juxtaposition associate to the left\footnote{Substitution \textit{has} to associate to the left, but we can imagine right-associative juxtaposition. Another enhancement for the fugure (sigh).}; you define the associativity of infix operators as well as their precedence. Prefix operators, postfix operators, substitution forms, juxtaposition and \textsc{leftfix} bracketed forms all have user-defined precedence.


There are well-known pitfalls in the definition of flexible precedence grammars (but probably no deeper than the holes beneath other forms of grammar). If your definition falls into a hole, Jape may not give much assistance, nor even provide readable parsing diagnostics.


\textit{Bracketed formulae}


Jape recognises bracketed formulae which use round brackets (parentheses). You can define other kinds of brackets for yourself in \textsc{leftfix} and \textsc{outfix} directives.


\textsc{Outfix} directives allow you to define new kinds of opening and closing brackets together with internal punctuation as well. You list the opening bracket, the internal separators and the closing bracket. For example you might write


\textsc{outfix} if then else fi


and then Jape will recognise


if \textit{formula} then \textit{formula} else \textit{formula} fi


At present the parser allows you to bring in the closing bracket early, before the list of internal punctuation symbols is exhausted, so that given the \textsc{outfix} directive above any of the following will be recognised as a formula:

if fi\\
if \textit{formula} fi\\
if \textit{formula} then \textit{formula} fi\\
if \textit{formula} then \textit{formula} else \textit{formula} fi


This is a temporary hack, pending a more flexible parser-generator.


\textsc{Leftfix} directives allow you to define opening brackets which have no corresponding closing bracket: you list the syntactic precedence, the opening bracket and the separating symbols. For example you might write


\textsc{leftfix 100} letrec be in


and then Jape will recognise formulae of the form


letrec \textit{formula} be \textit{formula} in \textit{formula}


\textsc{Leftfix} formulae are notoriously ambiguous -- experts will recognise this as the `dangling else' problem. In effect the final separator has the priority given in the declaration, and Jape will not allow the opening bracket to be preceded by an operator which is of higher priority than that given in the declaration. For example, if you have

\textsc{infix 120} \textsc{∧}\\
\textsc{leftfix 100} ∀.


then you could write \ensuremath{\forall}\textit{x}.\textit{A}\textsc{∧}\textit{B}, but not \textit{C}\textsc{∧}\ensuremath{\forall}\textit{x}.\textit{A}\textsc{∧}\textit{B}. That restriction, we hope, eliminates visual ambiguity in the use of bracketed forms without a closing bracket. If you want to write a formula which breaks these rules, you can always use brackets, as for example in \textit{C}\textsc{∧}(\ensuremath{\forall}\textit{x}.\textit{A}\textsc{∧}\textit{B}).


\textit{Substitution forms}


You can define the relative priority of substitution and juxtaposition as well as that of operators. Normally substitution is the highest priority form, and juxtaposition is either the next or follows some prefix/postfix operators, but the choice is yours. You write

\textsc{juxtfix} \textit{precedence}\\
\textsc{substfix} \textit{precedence}\\
\textsc{substfix} \textit{precedence bra id1 sep id2 ket}


The second form of \textsc{substfix} allows you to define the syntax of a substitution form, choosing opening bracket (by default `['), separator (by default `/') and closing bracket (by default `]'). At the same time you choose whether the variable list or the formula list comes first, by putting a variable identifier and a formula identifier in place of \textit{id1} and \textit{id2}. Because Jape uses this directive as a definition of some of the symbols, there must always be white space between its various components.


\textit{Operator syntax}


You define connectives and other such symbols in your logic by defining (unary) \textsc{prefix}, (unary) \textsc{postfix} operators and (binary) \textsc{infix} operators together with their syntactic precedence; in addition infix operators need an associativity. You write

\textsc{prefix} \textit{precedence op op...}\\
\textsc{postfix} \textit{precedence op op...}\\
\textsc{infix} \textit{precedence} \texttt{<}associativity\texttt{>} \textit{op op...}\\
\textsc{infixc} \textit{precedence} \texttt{<}associativity\texttt{>} \textit{op op...}


The \textit{op}s are special symbols, but they may be made up of any characters that you wish -- they don't have to be made up of non-alphanumeric characters. \texttt{<}Associativity\texttt{>} is a single character: L means left-associative, so that \textit{A op B op C} means (\textit{A op B}) \textit{op C}; R means right-associative, so that \textit{A op B op C} means \textit{A op} (\textit{B op C}); T means tupling or non-associative, so that \textit{A op B op C} means \textit{A op B op C}. Mixing operators of the same precedence and different associativity may cause confusion, but Jape doesn't prohibit it. The difference between \textsc{infix} and \textsc{infixc} is to do with the way that formulae are parsed.


As in many modern programming languages, we permit a bracketed operator as a formula, so you can write formulae like (+), (\ensuremath{@}), (++) once those symbols have been defined as operators. Operation formulae are parsed as juxtapositions, so that \textit{prefixop formula} is parsed as the juxtaposition (\textit{prefixop) formula}, \textit{formula postfixop} is parsed as (\textit{postfixop}) \textit{formula}, \textit{f1 infixop f2} is parsed as (\textit{infixop}) (\textit{f1,f2}) and \textit{f1 infixCop f2} is parsed as (\textit{infixCop}) \textit{f1 f2}; the reverse transcription is made when the formulae are printed out.


\textit{Binding structure}


Binding structure is defined by pattern: you give some variable names and some formula names and then give a pattern using those names. Any formula or subformula which matches the pattern is automatically a binding formula. Because substitution or unification mustn't be allowed to change the structure of a formula, Jape checks for `near miss' patterns and complains if it finds them.


The sort of thing you write is

BIND x SCOPE P IN ∃x. P\\
BIND y SCOPE P IN \{ y {\textbar} P \}\\
BIND x, y SCOPE P IN ∀x,y. P


It's normal to use \textsc{leftfix} or \textsc{outfix} patterns, as in these examples, but it isn't obligatory.


The last of the three examples above defines a parallel binding: one that at the same time binds two variable names. At present Jape has no means of defining families of parallel binding formula structures except by exhaustively listing each alternative. And it has no way of defining serial bindings at all.


\textit{Sequent structure}


At present sequents are always double-sided, and each side is one of


{\textbullet}\tab an optionally-empty comma-separated bag/multiset of formulae -- say \textsc{bag} or \textsc{bag formula};\\
{\textbullet}\tab an optionally-empty comma-separated list/sequence of formulae -- say \textsc{list} or \textsc{list formula};\\
{\textbullet}\tab a single formula -- say \textsc{formula}


The \textsc{sequent} directive gives you the opportunity to say what can appear on either side, and what the entailment symbol is. You write


\textsc{sequent} \textit{lhs entailment rhs} \{ \textsc{and} \textit{lhs entailment rhs...} \}


You can have as many different kinds of sequent as you wish, provided that their entailment symbols are unique.


In version 3.2 we have introduced a \textsc{judgement} directive. This works in just the same way as \textsc{sequent}, except that in box display a \textsc{judgement} is always written on a single line -- that is, its lhs is not interpreted as a collection of hypotheses and its rhs a conclusion. We are fairly sure we have chosen the wrong word for this directive (and indeed for \textsc{sequent}). Watch this space or send us a suggestion.


\textit{Future work}


In the future we intend to provide a more powerful form of syntax definition for Jape's users, providing in particular a more efficient means of defining binding forms and ways of making finer distinctions between syntactic categories. More structure in sequent forms would be a step still further, and we don't yet envisage it.




\begin{center} -  -


\end{center} \textbf{{\huge Appendix B\\
The tactic language}}


There are no reserved words in the tactic language. It is written in a very restricted sub-dialect of the formula language, without the restriction that the class of every identifier must be pre-declared. When it comes to the application of a rule -- the simplest kind of tactic -- then the arguments must be stated in the formula language.


Although there aren't any reserved words, there are a lot of tactic language verbs. As in the paragraph language, these are all in upper case. You don't have to avoid these names in the statement of rules and theorems, but if you start using them as tactic parameter names you might confuse things.


Since version 3.0, tactic applications are written in `curried' style: \textit{verb} \textit{arg1}... \textit{argN}, where each argument is bracketed if necessary\footnote{The older `uncurried' style, with arguments provided as a bracketed tuple, is now withdrawn. That means we have curried applications and uncurried definitions. One day...}. If a tactic starts with a verb which isn't one of those listed below, it is treated as an application of a named tactic, rule or conjecture. The verb and arguments of a tactic application are evaluated in the current environment -- that means that any names they contain which are parameters of the current tactic, or parameters of the current \textsc{let...} tactical, are replaced by the corresponding formulae.


When a named tactic is applied to arguments, a new environment is created by zipping together tactic parameters and supplied arguments. If there are too few arguments, the remaining parameters are ignored. When a name is evaluated which doesn't have a value in the current environment, the name itself is taken as the result.


\textbf{{\large B.1\tab Tactic verbs}}


\textsc{alt} \textit{tactic}... \textit{tactic}: try each of the tactics in turn, until one is found that succeeds. If none succeeds, \textsc{alt} fails.


\textsc{applyorresolve} \textit{tactic}: rules applied by \textit{tactic} will be tried first normally, where both hypotheses and conclusions must match, and then `by resolution' where only conclusions need match and extra antecedents are inserted to prove each of the hypotheses. The `resolution' step requires that the logic have a \textsc{cut} structure rule.


\textsc{assign} \textit{variable} \textit{value}: the named variable, which must be part of the global enviroment (see appendix C) is assigned the given value. Some variables can't be altered once anything has been loaded into the tactic/rule/conjecture store\footnote{Those variables are properly parameters and for clarity we ought to have a syntax for handling them. Patience, patience.}.


\textsc{do} \textit{tactic}: apply \textit{tactic} repeatedly until it fails, then \textsc{do} succeeds.


\textsc{evaluate} \textit{formula} : evaluate one of a fixed number of built-in judgements. Where used, this tactic is explained in one of the distributed encodings; at the time of writing it is used only in the functional programming encoding to evaluate \textsc{assoceq}(\textit{f1}, \textit{f2}), a judgement that two formulae are identical when rewritten with maximal use of associativity laws. \textsc{evaluate} is intended to be the basis, one day, for a mechanism of communication with oracle programs.


\textsc{explicit} \textit{name},..., \textit{name}: succeeds if every \textit{name} is a parameter for which an argument has been supplied. I think. Opposite of \textsc{implicit} below. I think.


\textsc{flatten} \textit{formula}: `flattens out' all subformulae of \textit{formula} in the conclusion of the current problem sequent by rewriting according to the rules of associativity. It's based on the same machinery as \textsc{assoceq}; see \textsc{evaluate} above and chapter 5.


\textsc{fold} \textit{rulename} \textit{tactic}: Automatically `folds' collections of rules. See chapter 5 above.\\
\textsc{foldhyp} \textit{pattern tactic}: Automatically `folds' hypotheses. See chapter 5 above.\\
\textsc{if} \textit{tactic}: run \textit{tactic}, but succeed even if it fails.


\textsc{implicit} \textit{name}... \textit{nameN}: succeeds if none of of \textit{name}1... \textit{nameN} is a parameter for which an argument has been supplied. I think. Opposite of \textsc{explicit} above. I think.


\textsc{jape} \textit{stuff} : probably deserves a section on its own. Was originally called the `AdHoc' tactic, and it shows. Usually \textit{stuff} is nothing more than ``fail \textit{message}'', but can also be ``showalert \textit{message}'' and ``write \textit{message}'' and lots more which it would be tedious and embarrassing to list. Likely to change soon and without notice.


\textsc{layout} \textit{pattern} \textit{numbers} \textit{tactic} ... \textit{tactic}: the way in which a tactic can hide part of a proof. \textit{Pattern} is either () or \textit{string1} or (\textit{string1}, \textit{string2}); \textit{numbers} is a tuple of integers. Run \textit{tactic} ... \textit{tactic} as a sequence and if that succeeds, mark the subtree it produces so that it is displayed in a special way determined by \textit{pattern} and \textit{numbers}. The tree is displayed either in `hidden' or `full' form: by double-clicking on the justfication at the root of the tree the user can force Jape to switch between forms. In `hidden' form only the antecedents selected by \textit{numbers} are shown, and all others are hidden: antecedents are numbered from left to right, starting with 0, so that if \textit{numbers} is (1,3), for example, only the second and fourth antecedents will be shown. In `full' form all antecedents are shown. In `hidden' form the justification shown at the root of the subtree is controlled by \textit{string1}, if included, or by the variable `hiddenfmt' otherwise; in `full' form that justificaiton is controlled by \textit{string2}, if included, or by the variable `unhiddenfmt' otherwise. In either form the controlling string is used as a format string rather as in a very simple kind of C printf, and occurrences of \%s in that string are replaced by a summary of the justifications on hidden parts of the subtree; in `full' format occurrences of \%s in the controlling string are replaced by the justification of the node at the root of the subtree.


\textsc{letargsel} \textit{pattern tactic... tactic}: One of the `guarded tactics' for use in \textsc{when}; also a `binding tactic' (see below). If the user has made a \textit{single} text selection, parse that text and unify it with \textit{pattern}; then proceed as normal for a binding tactic.\\
\textsc{letconc} \textit{pattern tactic... tactic}: One of the `guarded tactics' for use in \textsc{when}; also a `binding tactic' (see below). If the user has formula-selected a conclusion, unify it with \textit{pattern}; then proceed as normal for a binding tactic.


\textsc{letconcfind} \textit{pattern tactic... tactic}: One of the `guarded tactics' for use in \textsc{when}; also a `binding tactic' (see below). If the user has made a single text selection \textit{fs} in a conclusion formula \textit{C} so that \textit{C} consists of \textit{f1} followed by \textit{fs} followed by \textit{f2}, if the text \textit{f1} (\textit{fs}) \textit{f2} is a parseable formula, and if the formula (\textit{C}, \textit{f1} (\textit{fs}) \textit{f2}) unifies with \textit{pattern}, then: if \textit{C} is not structurally the same formula as \textit{f1} (\textit{fs}) \textit{f2} proceed as normal for a binding tactic; if they are the same formula, succeed silently, without running the sequence \textit{tactic... tactic}.


\textsc{letconcsubstsel} \textit{pattern tactic... tactic}: like \textsc{letsubstsel} (q.v. below) except that the text-selection must be made in a conclusion (right-hand side) formula.


\textsc{letgoal} \textit{pattern tactic... tactic}: One of the `guarded tactics' for use in \textsc{when}; also a `binding tactic' (see below). If the current problem sequent has a single conclusion formula, unify it with \textit{pattern}; then proceed as normal for a binding tactic.\\
\textsc{lethyp} \textit{pattern tactic... tactic}: One of the `guarded tactics' for use in \textsc{when}; also a `binding tactic' (see below). If the user has formula-selected a hypothesis formula, unify it with \textit{pattern}; then proceed as normal for a binding tactic.


\textsc{lethypfind} \textit{pattern tactic... tactic}: just like \textsc{letconcfind} (q.v. above), except that the single text-selection must be made in a hypothesis formula\\
\textsc{lethypsubstsel} \textit{pattern tactic... tactic}: like \textsc{letsubstsel} (q.v. below) except that the text-selection must be made in a hypothesis formula of the current problem sequent.\\
\textsc{letmatch} \textit{pat1 pat2} \textit{tactic... tactic}: One of the `guarded tactics' for use in \textsc{when}; also a `binding tactic' (see below). If \textit{pat1} unifies with \textit{pat2}, proceed as normal for a binding tactic.


\textsc{letmultisel} \textit{pattern tactic... tactic}: One of the `guarded tactics' for use in \textsc{when}; also a `binding tactic' (see below). Unify all the user's text-selections, expressed as a tuple of formulae, with \textit{pattern}; then proceed as normal for a binding tactic.


\textsc{letsubstsel} \textit{pattern tactic... tactic}: One of the `guarded tactics' for use in \textsc{when}; also a `binding tactic' (see below). If the user has made a number of text selections within a single formula, each an instance of an identical sub-formula, convert that to a substitution (see chapter 1) and unify it with \textit{pattern}; then proceed as normal for a binding tactic.


\textsc{mapterms} \textit{tactic}: if the current problem sequent has a conclusion which is a single formula, try to apply \textit{tactic} (which is probably some sort of rewrite rule) to each of the structural subformulae of that conclusion formula.\\
\textsc{match} \textit{tactic}: runs \textit{tactic} so that any rules which it applies are required to succeed without visibly changing the unification context -- that is, without changing the interpretation of any unknowns in the problem sequent.\\
\textsc{prove} \textit{tactic}: detaches the current goal from the proof tree; tries to prove it; and then plugs in the proof if it's complete, otherwise fails. A way of ensuring that a tactic builds a subtree with no open tips.\\
\textsc{replay} \textit{tactic}: run \textit{tactic} but use term equality (up to \ensuremath{\alpha}-conversion and elimination of substitutions) instead of unification. Used in proof loading, because it seems to be a bit faster than the normal mechanism.\\
\textsc{resolve} \textit{tactic}: rules and theorems applied by \textit{tactic} will all be applied `by resolution' in which only the conclusions need match and extra antecedents are inserted for each hypothesis. See \textsc{simpleapply} below and \textsc{applyorresolve} above.


\textsc{sameprovisos} \textit{tactic}: rules applied by \textit{tactic} mustn't add or delete any provisos from the current unification context. Used to be used in proof reloading; may now be obsolete.


\textsc{seq} \textit{tactic}... \textit{tacticN}: run the tactics in sequence. Fail if any of them fails.


\textsc{simpleapply} \textit{tactic}: each of the rules applied by \textit{tactic} will be applied in `normal' style, without using the `by resolution' mechanism.


\textsc{skip}: succeed.


\textsc{theoryalt} : generated internally, and used when a particular mechanism, used only in the functional programming encoding, is searching for and caching rules. It's all rather horrid and extremely \textit{ad hoc}, and no further details will ever be released.


\textsc{unfold} \textit{rulename tactic}: see \textsc{fold} above.\\
\textsc{unfoldhyp} \textit{formula tactic}: see \textsc{foldhyp} above.


\textsc{unique} \textit{tactic}: run \textit{tactic} so that any rules it applies are required to succeed in only one way (i.e. prevents application of those rules from offering the user a choice of alternative matches). Used in proof reloading.


\textsc{when} \textit{guardedtactic}.... \textit{guardedtactic tactic}: try each of the guarded tactics in turn until one is found whose guard unifies, then run the tactics it guards; if none of the guards succeeds, run the final alternative \textit{tactic}. The guarded tactics must each be one of the \textsc{let...} variety: see `guarded and binding tactics' below.


\textsc{withargsel} \textit{tactic}: run \textit{tactic}, giving it as argument the current text-selection, provided that there is only a single text selection and it parses properly as a formula. Fails if there is a single text selection but it can't be parsed.


\textsc{withconcsel} \textit{tactic}: if the user has formula-selected a conclusion formula, rules applied by \textit{tactic} must consume it (that is, explicitly match it).


\textsc{withcontinuation} \textit{tactic1 tactic tactic...}: \textit{tactic1} is run so that its continuation is the sequence \textit{tactic tactic...}. Has no effect unless \textit{tactic1} ends with an \textsc{alt/theoryalt}; then it will ensure that no alternative of that \textsc{alt} succeeds unless the sequence \textit{tactic tactic...} succeeds afterwards. Makes alternative choice a little more lazy.


\textsc{withformsel} \textit{tactic}: a combination of \textsc{withconcsel} above and \textsc{withhypsel} below.


\textsc{withhypsel} \textit{tactic}: if the user has formula-selected a hypothesis formula, rules applied by \textit{tactic} must consume it (that is, explicitly match it).


\textsc{withselections} \textit{tactic}: a combination of \textsc{withargsel}, \textsc{withconcsel} and \textsc{withhypsel}.


\textsc{withsubstsel} \textit{tactic}: normally used inside a \textsc{letsubstsel} tactical. The user's text selections have to be entirely within one of the hypotheses or conclusions of the current problem sequent: rewrite that hypothesis or conclusion as a substitution form, based on the text selections given, and then run \textit{tactic}. Fails noisily if the text selections don't describe a substitution in just the right way; fails normally if the substitution is described, but \textit{tactic} fails. Rules applied by \textit{tactic} must consume (i.e. explicitly match) the reconstructed formula.


In addition to all those there are two that can occur inside a \textit{formula} inside a tactic:


\textsc{antiquote} ( \textit{formula} ): everything inside \textit{formula} is liable to `evaluation' in the current tactic environment, unless it is \textsc{quote}d. Arguments in applications of tactics are treated as if they were \textsc{antiquote}d.


\textsc{quote} ( \textit{formula} ): nothing inside \textit{formula} is liable to `evaluation' unless it is \textsc{antiquote}d.


\textbf{{\large B.2\tab The `current problem sequent', the `goal' and the `target'}}


When you start a proof there is only one problem sequent. When you apply a rule with two antecedents, there are two to choose from. When you are well into a proof, there may be many.


Each time Jape makes a proof step (by application of a rule or in a small number of other ways, mostly to do with the more exotic of the tactics like \textsc{find} or \textsc{flatten}, and sometimes caused by the dialogue language) it selects a new problem sequent if the current one is closed, or replaced by a subtree. It always finds the `next rightmost unclosed tip' and makes that the current problem sequent. The `next rightmost unclosed tip' is the first one in the fringe of the tree to the right of the current one, or the first one in the fringe if there isn't one to the right of the current one.


The current problem sequent is called the `goal'; the problem sequent from which we moved to the current one because application of a rule succeeded is called the `target' (not a very good name, `target', but that's the way it is).


\textbf{{\large B.3\tab Guarded and binding tactics}}


Jape's tactic language is `eager' -- whether it should be so continues to be a matter of debate -- with backtracking on failure. If a tactic fails, then the enclosing tactic either fails, or if it is an \textsc{alt}, tries another alternative starting from the state in which it first applied the sub-tactic that failed. That sort of backtracking search is fine sometimes, but not always. It can be modified -- slightly -- by \textsc{withcontinuation}.


The \textsc{when} tactical takes `guarded tactics' and applies them carefully, accepting the result of the first one of them whose guard matches. Note that the whole guarded tactic may fail after its guard has matched, and in that case \textsc{when} won't backtrack, it will simply fail.


Each of the guarded tacticals -- they are all called \textsc{let...} -- takes a \textit{pattern} and a \textit{tactic} sequence. The \textit{pattern} is matched against something by unification: if the unification succeeds then the environment is updated to reflect that unification. Roughly speaking you can assume that unknowns in \textit{pattern} will be added to the environment as parameters corresponding to the stuff they unified with, and if they are used again in the tactic sequence, they will be replaced by that same stuff. You don't have to worry that the unknowns you use might already appear in the unification context: Jape invents new ones, based on the ones you use, so that the effects of a successful binding tactic never leak into the unification context used in proof steps.




\begin{center} -  -


\end{center} \textbf{{\huge Appendix C\\
The command language, environment variables and the default environment}}


\textbf{{\large C.1\tab The command language}}


Jape communicates with its graphical interface in a language of `words', space separated unless they are enquoted "...". You may want to attach commands to buttons, you may want to include commands as entries in \textsc{tacticpanel}s, and you can type commands into the system -- on the Mac into the Text Command box, on X into the command window -- so here goes with a description. I've divided it into two: the ones you might want to use, and the arcana.


Note that the language described here is \textit{ad hoc} and subject to change without notice or any sign of visible regret on the part of the implementors. Be warned.


\textit{Commands you might want to use}


addnewconjecture \textit{panelname} \textit{conjecture}: this command is sent by the New\dots  button in a conjecture panel, after the user has typed the conjecture into a dialogue box.\\
apply \textit{tacticexpression}: this command is used a lot: it is the way that menus and panels apply tactics. Don't forget that a rule name is a tactic expression.


assign \textit{name} \textit{value}: the way that Jape's environment variables (q.v. below) are given values.\\
backtrack: command sent by the Backtrack button in the Edit menu.


closedbugfile: close the top dbug file on the stack of such files (see createdbugfile below); redirect diagnostic output to the file below, or to the console if the stack is empty.


collapse: the way that the Hide/Show detail entry in the Edit menu does its work.


createdbugfile: create a file, using the normal file selection dialogue, and redirect diagnostic input into it. There's a stack of these dbug files.


layout: has the same effect as double-clicking on the justification of the selected sequent.\\
lemma \textit{panelname} \textit{conjecture}: synonym for addnewconjecture above.


print \textit{filename}: generates a listing of the currently-focussed proof in \textit{filename}, in a form suitable for LaTeX processing.\\
proof finished: (two words) how the Done entry (on the Mac) and the proof finished entry (on UNIX) in the Edit menu does its work.


prove \textit{conjecturename}: how the Prove button in a conjecture panel does its work.\\
prune: how the Prune entry in the Edit menu does its work.\\
QUIT: kill the proof engine, after asking whether the user wants to save any proofs.\\
redo: how the Redo entry in the Edit menu does its work.\\
refreshdisplay: clear the currently-focussed proof window and redraw the proof it contains.


reset: how the Reset entry (on the Mac) and the ?? entry (on UNIX) in the Edit menu do their work. On the Mac the Reset entry can be greyed-out even though some syntax definitions have been accepted: in that case typing the reset command to a Text Command window can be helpful.


reset;reload: (no spaces, all one `word' with a semicolon in the middle!) how the Load New Theory entry in the File menu does its work.\\
showproof \textit{conjecturename}: how the Show Proof button on a conjecture panel does its work; opens a window with a proof of \textit{conjecturename} in it, if there is one in the proof store.\\
saveengine \textit{filename}: saves the current proof engine, with all its settings, in a file. Useful for creating pre-initialised engines\\
steps: display the value of the internal variable `timestotry' in an alert dialogue. See steps \textit{n} below.


steps \textit{n}: set the value of the internal variable `timestotry' to the integer \textit{n}. This variable will, in the near future, be part of the default environment (q.v. below). The value of the variable controls the number of steps that Jape will allow in a single tactic application before failing with the message ``Time ran out''.


tellinterface \textit{variablename word word....}: send the current value of the variable \textit{variablename} to the interface, prefixed by the command \textit{word....}.


undo: the way that the Undo entry in the Edit menu and/or the Undo key do their work.


unify \textit{formulae}: Unify the given formulae and all of the user's text-selections. The way that the Unify button does its work.


use \textit{filenames}: open each of the files named, read and execute the Japeish text they contain. The way that proof files are loaded and a new encodings or a modification to the current encoding is interpreted


version: display the current version information of the Jape engine in an alert dialogue.


\textit{Arcana}


cd \textit{path}: changes the default directory used by the proof engine. Only works in the UNIX implementations; don't use if you don't know what it does.


closeproof \textit{n}: absolutely not to be used.\\
DRAGQUERY: part of the drag-and-drop interface; don't use it.\\
DROPCOMMAND: part of the drag-and-drop interface; don't use it.


fonts\_reset: command sent by the graphics interface when its fonts are altered. Triggers all sorts of cache mangling, but otherwise harmless.


HITCOMMAND \textit{comm}: absolutely not to be used.\\
NOHITCOMMAND \textit{comm}: absolutely not to be used.


profile [ on {\textbar} off {\textbar} reset {\textbar} report \textit{filename} ]: one of the mechanisms with which we debug the proof engine. Only works in specially-instrumented proof engines under \textsc{unix}.


quit: kill the proof engine without asking any questions.\\
saveproofs \textit{word}: absolutely not to be used.\\
setfocus \textit{n}: absolutely not to be used.\\
showfile \textit{filename}: possibly obsolete.\\
\textit{emptyword}: ignored.


\textbf{{\large C.2\tab Variables and the default environment}}


Jape has a number of `environment variables' which can be used to modify its behaviour, and can currently be set by the \textsc{assign} tactic, by the assign command and by \textsc{initialise, radiobutton} and \textsc{checkbox} directives in the paragraph language. Some of them are of general use; some are horrid debugging switches of interest only to the implementors. Variables can be set from menus and panels: see the various files like `autoselect\_entry' which are distributed with Jape and put entries in the Edit menu.


\textit{Useful variables}


Variables whose default value is marked with an asterisk are parameters: their value can be altered only if the rule/tactic/conjecture store is empty.\\


\begin{tabular}{|p{1.034in}|p{0.635in}|p{0.717in}|p{2.114in}|} \hline
% ROW 1
{\raggedright \textit{name}} & {\raggedright \textit{values}} & {\raggedright \textit{default value}} & {\raggedright \textit{effect}}\\
\hline
% ROW 2
{\raggedright applyconjectures} & {\raggedright true, false} & {\raggedright false} & {\raggedright when true, allow conjectures (unproved theorems) to be applied as rules.}\\
\hline
% ROW 3
{\raggedright autoAdditiveLeft} & {\raggedright true, false} & {\raggedright false*} & {\raggedright when true, any rule whose consequent and antecedents all have a bag on their left-hand sides is augmented by the addition of a bag variable (e.g. \ensuremath{\Gamma}) to the left-hand side of every consequent and antecedent which doesn't already have one.}\\
\hline
% ROW 4
{\raggedright autoAdditiveRight} & {\raggedright true, false} & {\raggedright false*} & {\raggedright as autoAdditiveLeft, except that it applies to right-hand sides}\\
\hline
% ROW 5
{\raggedright autoselect} & {\raggedright true, false} & {\raggedright false} & {\raggedright when true, select the conclusion of the current problem sequent each time a proof is displayed.}\\
\hline
% ROW 6
{\raggedright collapsedfmt} & {\raggedright any string} & {\raggedright "[\%s...]"} & {\raggedright the string used to control the way that a justification is displayed for a subtree shown in `collapsed' form -- for example, after using Hide/Show Subproof on an uncollapsed subtree.}\\
\hline
% ROW 7
{\raggedright displaystyle} & {\raggedright box, tree} & {\raggedright tree} & {\raggedright selects the display mechanism used to show a proof. Each proof may have an individual setting of this variable. When a new proof is started, its displaystyle is taken from the currently-focussed proof.}\\
\hline
% ROW 8
{\raggedright hiddenfmt} & {\raggedright any string} & {\raggedright "\{\%s\}"} & {\raggedright the string used to control the way that a justification is displayed for a subtree produced by the layout tactical in `hidden' form. This string is over-ridden if \textit{string1} is provided in the layout tactical.}\\
\hline
% ROW 9
{\raggedright hidecut} & {\raggedright true, false} & {\raggedright true} & {\raggedright hide the application of cut rules in box display.}\\
\hline
% ROW 10
{\raggedright hidehyp} & {\raggedright true, false} & {\raggedright true} & {\raggedright hide the application of identity rules in box display.}\\
\hline
% ROW 11
{\raggedright interpretpredicates} & {\raggedright true, false} & {\raggedright false*} & {\raggedright on instantiating a rule, interpret juxtapositions as predicate applications; translate them into substitution forms, add new object parameters and invisible provisos.}\\
\hline
% ROW 12
{\raggedright outermostbox} & {\raggedright true, false} & {\raggedright true} & {\raggedright when true, draw an outermost box in box display when proving a conjecture which has hypothesis formulae.}\\
\hline
% ROW 13
{\raggedright showallproofsteps} & {\raggedright true, false} & {\raggedright true} & {\raggedright (misnamed -- should be showhiddenproofsteps) when true, show proof steps hidden by layout tacticals.}\\
\hline
% ROW 14
{\raggedright showallprovisos} & {\raggedright true, false} & {\raggedright false} & {\raggedright (misnamed -- should be showhiddenprovisos) when true, show hidden provisos, marked as \texttt{<}proviso\texttt{>}.}\\
\hline
% ROW 15
{\raggedright tryresolution} & {\raggedright true, false} & {\raggedright true} & {\raggedright apply theorems and antecedent-free rules in `resolution' style if the conclusions of the consequent match but the hypotheses don't.}\\
\hline
% ROW 16
{\raggedright uncollapsedfmt} & {\raggedright any string} & {\raggedright "\%s"} & {\raggedright string that controls the display of a subtree that was once collapsed and is now reinflated.}\\
\hline
% ROW 17
{\raggedright unhiddenfmt} & {\raggedright any string} & {\raggedright "[\%s]"} & {\raggedright string that controls the display of a subtree produced by the layout tactical and displayed in `normal' form. This string is over-ridden if \textit{string2} is provided in the layout tactical.}\\
\hline \end{tabular}


\textit{Adding your own variables}


You can invent your own environment variables and assign them values. In particular you can define a variable in a \textsc{radiobutton} or \textsc{checkbox} directive, give the range of possible values that it can take, and allow the user to control that variable. See, for example, the way that the functional programming encoding controls searching by using variables whose values are the names of tactics.


There are at present few ways in which the value of a variable can be used, once set. But watch this space for developments, including at least a form of case-expression value analysis in the tactic language.


\textit{Debugging variables}


Jape has a number of debugging variables. Setting any of them to true makes it print lots of stuff on the console (which on the Mac is hidden, and needs secret knowledge to find). The variables currently used are


applydebug, bindingdebug, factsdebug, FINDdebug, FOLDdebug, matchdebug, prooftreedebug, rewritedebug, substdebug, symboldebug, tactictracing, thingdebug, unifydebug, eqalphadebug, varbindingsdebug


In this manual we don't explain or admit what these variables do or don't do or how best to use them. Good luck to you if you try to find out.

\end{document}
